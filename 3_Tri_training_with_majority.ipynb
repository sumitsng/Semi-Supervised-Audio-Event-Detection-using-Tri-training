{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3. Tri-training with majority.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExEY_BDD8HbR"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48Go_0JSTCZT"
      },
      "source": [
        "# importing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "pd.plotting.register_matplotlib_converters()\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.models import clone_model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import librosa\n",
        "import keras\n",
        "from keras.layers import LSTM, Dense, Dropout, Flatten\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import keras\n",
        "from keras.layers import LSTM, Dense, Dropout, Flatten\n",
        "from keras.layers import Bidirectional, TimeDistributed, Conv2D, MaxPooling2D, Input, GRU, Dense, Activation, Dropout, Reshape, Permute, MaxPooling1D, Flatten\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.models import Model\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3BPGQfLTP1b",
        "outputId": "3d6b31bc-1fd4-4819-8a16-a3a9757f257a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\",force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFER48S1i-jE"
      },
      "source": [
        "batch=[]\n",
        "batch.append(500)\n",
        "batch.append(500)\n",
        "batch.append(32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-h7_8_U8MY7"
      },
      "source": [
        "### Define Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMM7K0RYTSUw",
        "outputId": "23fc90b4-e2ff-4070-da6f-ec685716a8fc"
      },
      "source": [
        "# defining models as functions\n",
        "\n",
        "clf=[[],[],[]]\n",
        "callbacks=[]\n",
        "opt=[]\n",
        "### MODEL1: CRNN ###\n",
        "print(\"Model 1: Convolution Recurrent Neural Network (CRNN)\")\n",
        "opt.append(keras.optimizers.Adam(learning_rate=0.001))\n",
        "def clf0():\n",
        "  seq = keras.Sequential(\n",
        "      [\n",
        "          layers.Conv2D(64, (3, 3), padding = \"same\", activation = \"tanh\", input_shape=(16,8,1) ),\n",
        "          layers.MaxPool2D(pool_size=(2, 2)),\n",
        "          layers.Conv2D(128, (3, 3), padding = \"same\", activation = \"tanh\"),\n",
        "          layers.MaxPool2D(pool_size=(2, 2)),\n",
        "          layers.Reshape((8, 128)),\n",
        "          layers.LSTM(32),\n",
        "          layers.Flatten(),\n",
        "          layers.Dense(32),\n",
        "          layers.Dropout(0.2),\n",
        "          layers.Dense(10, activation='softmax'),\n",
        "      ]\n",
        "  )\n",
        "  seq.compile(loss=\"categorical_crossentropy\", optimizer=opt[0], metrics=['accuracy'])\n",
        "  return seq\n",
        "callbacks.append([ModelCheckpoint('/content/drive/MyDrive/ML_A/Tri train/3. Tri-S/CRNN_80.h5', monitor='val_loss', mode='min', save_best_only=True),EarlyStopping(monitor = 'val_loss',min_delta = 0,patience = 40,restore_best_weights = True)])\n",
        "print(clf0().summary())\n",
        "\n",
        "### MODEL2: LSTM ###\n",
        "print('Model 2: Long Short Term Memory (LSTM)')\n",
        "opt.append(Adam(lr=0.001))\n",
        "def clf1():\n",
        "  input_dim = (16, 8)\n",
        "  dropout=0.1\n",
        "  n_classes=10\n",
        "  learning_rate = 0.001\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(256, return_sequences=True, input_shape=input_dim,dropout=dropout))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  model.add(Dropout(dropout))\n",
        "  model.add(Dense(n_classes, activation='softmax'))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer=opt[1],metrics=['accuracy'])\n",
        "  return model\n",
        "callbacks.append([ModelCheckpoint('/content/drive/MyDrive/ML_A/Tri train/3. Tri-S/LSTM_80.h5', monitor='val_loss', mode='min', save_best_only=True),EarlyStopping(monitor = 'val_loss',min_delta = 0,patience = 40,restore_best_weights = True)])\n",
        "print(clf1().summary())\n",
        "\n",
        "### Model3 MLP ###\n",
        "print('Model 3:Multi-Layer Perceptron (MLP)')\n",
        "opt.append(Adam(lr=0.001))\n",
        "def clf2():\n",
        "  input_dim = (128,)\n",
        "  dropout=0.1\n",
        "  n_classes=10\n",
        "  learning_rate = 0.001\n",
        "  num_classes = 10\n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Dense(256, input_shape=input_dim ))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.3))\n",
        "\n",
        "  model.add(Dense(512))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.3))\n",
        "\n",
        "  model.add(Dense(256))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.3))\n",
        "\n",
        "  model.add(Dense(num_classes))\n",
        "  model.add(Activation('softmax'))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer=opt[2],metrics=['accuracy'])\n",
        "  return model\n",
        "callbacks.append([ModelCheckpoint('/content/drive/MyDrive/ML_A/Tri train/3. Tri-S/MLP_80.h5', monitor='val_loss', mode='min', save_best_only=True),EarlyStopping(monitor = 'val_loss',min_delta = 0,patience = 40,restore_best_weights = True)])\n",
        "print(clf2().summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model 1: Convolution Recurrent Neural Network (CRNN)\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 16, 8, 64)         640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 8, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 8, 4, 128)         73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 4, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "reshape_3 (Reshape)          (None, 8, 128)            0         \n",
            "_________________________________________________________________\n",
            "lstm_6 (LSTM)                (None, 32)                20608     \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 96,490\n",
            "Trainable params: 96,490\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model 2: Long Short Term Memory (LSTM)\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_7 (LSTM)                (None, 16, 256)           271360    \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 128)               524416    \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 797,066\n",
            "Trainable params: 797,066\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model 3:Multi-Layer Perceptron (MLP)\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_24 (Dense)             (None, 256)               33024     \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 10)                2570      \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 298,506\n",
            "Trainable params: 298,506\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qj6fC8Wp8TJ7"
      },
      "source": [
        "### Load extracted features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbqCZcsEVGhx"
      },
      "source": [
        "# importing data\n",
        "X=np.load('/content/drive/MyDrive/ML_A/Tri train/X_normalized.npy')\n",
        "y=np.load('/content/drive/MyDrive/ML_A/Tri train/y_normalized.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaAcf0D9VNf1"
      },
      "source": [
        "## Splitting the data into 60% unlabeled 10% testing and 30% training\n",
        "X__train, X_un, y__train, y_un = train_test_split(X, y, test_size=0.6,random_state=1)\n",
        "X_label, X_test, y_label, y_test = train_test_split(X__train, y__train, test_size=0.25,random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pn_5jKjHZwD5"
      },
      "source": [
        "# converting shape of data for each model\n",
        "X_label_data = [X_label.reshape(len(X_label), 16, 8, 1), X_label.reshape(len(X_label), 16, 8), X_label.reshape(len(X_label), 128)]\n",
        "X_un_data = [X_un.reshape(len(X_un), 16, 8, 1), X_un.reshape(len(X_un), 16, 8), X_un.reshape(len(X_un), 128)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92l3J53e8Wdp"
      },
      "source": [
        "### Tri training with majority"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glJyWxsKVO1y"
      },
      "source": [
        "iteration = 0\n",
        "val_acc = [[], [], []]\n",
        "train_acc = [[], [], []]\n",
        "num_labled = []\n",
        "num_unlabled = []\n",
        "test_acc = []\n",
        "pseudo_labels_acc=[]  # percentage correct of pseudo labels\n",
        "labels_added=[]\n",
        "threshold = 0.95"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mER3qIAMXt4d",
        "outputId": "14215009-3363-48e3-d2c6-c822ed3cd1e1"
      },
      "source": [
        "# tri training\n",
        "\n",
        "while iteration<6:\n",
        "  print(iteration)\n",
        "  y_pred = []\n",
        "  # Step 1: Create the model and fit for newly labeled data at each iteration\n",
        "  for i in range(3):                          # training models\n",
        "    if iteration == 0:\n",
        "      X_resample, y_resample = sklearn.utils.resample(X_label_data[i], y_label) # Bootstrap sample to give different data to each model in first iteration \n",
        "    else:\n",
        "      X_resample = X_label_data[i]\n",
        "      y_resample = y_label\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_resample, y_resample, test_size=0.25)\n",
        "\n",
        "    # Create the model\n",
        "    if i==0:\n",
        "      clf[i]=clf0()\n",
        "    elif i==1:\n",
        "      clf[i]=clf1()\n",
        "    else: clf[i]=clf2()\n",
        "    print('model', i)\n",
        "    \n",
        "    # Fit on newly labeled data\n",
        "    clf[i].fit(X_train, y_train, validation_data = (X_val, y_val), epochs = 300, batch_size = batch[i], shuffle=True, callbacks=callbacks[i])\n",
        "    \n",
        "    # Predict on unlabeled data\n",
        "    y_pred.append(clf[i].predict(X_un_data[i]))\n",
        "\n",
        "    # Calculate traning accuracy\n",
        "    y_predict = np.argmax(clf[i].predict(X_train), axis=1)\n",
        "    p = 0\n",
        "    for j in range(len(y_predict)):\n",
        "      if y_predict[j]==np.argmax(y_train[j]): p+=1\n",
        "    train_acc[i].append(p/len(y_predict))\n",
        "\n",
        "    # Calculate validation accuracy\n",
        "    y_predict = np.argmax(clf[i].predict(X_val), axis=1)\n",
        "    p = 0\n",
        "    for j in range(len(y_predict)):\n",
        "      if y_predict[j]==np.argmax(y_val[j]): p+=1\n",
        "    val_acc[i].append(p/len(y_predict))\n",
        "  \n",
        "  # Step 2: Calculate Testing  Accuracy\n",
        "  y_pred0 = clf[0].predict(X_test.reshape(len(X_test), 16, 8, 1))\n",
        "  y_pred1 = clf[1].predict(X_test.reshape(len(X_test), 16, 8))\n",
        "  y_pred2 = clf[2].predict(X_test.reshape(len(X_test),128))\n",
        "  \n",
        "  # Use mean probabilty to decide class\n",
        "  y_sum = y_pred0 + y_pred1 + y_pred2\n",
        "  y_sum = np.argmax(y_sum, axis=1)\n",
        "  p = 0\n",
        "  for i in range(len(y_sum)):\n",
        "    if y_sum[i]==np.argmax(y_test[i]): p+=1\n",
        "  test_acc.append(p/len(y_sum))\n",
        "\n",
        "  # Initial labeled and unlabeled data\n",
        "  index_to_be_added = []\n",
        "  num_labled.append(len(X_label_data[0]))\n",
        "  num_unlabled.append(len(X_un_data[0]))\n",
        "\n",
        "  # Step 3: Create pseudo labeled data\n",
        "  pseudo_acc = 0\n",
        "  # Iterate on each example of unlabeled data\n",
        "  for i in range(len(y_pred[0])):           \n",
        "    yes = 0                                               # yes: 1 if example comsidered as pseudo label otherwise 0\n",
        "    y_pred_new = -1                                       # y_pred_new: holds the label of pseudo label data\n",
        "    y_m0 = np.argmax(y_pred[0][i])                        # y_m0,y_m1,y_m2: holds the classes predicted for ith example by 0th,1st,and 2md model respectively\n",
        "    y_m1 = np.argmax(y_pred[1][i])\n",
        "    y_m2 = np.argmax(y_pred[2][i])\n",
        "    p_m0 = y_pred[0][i][y_m0]/np.sum(y_pred[0][i])        # p_m0,p_m1,p_m2: hold the class proba\n",
        "    p_m1 = y_pred[1][i][y_m1]/np.sum(y_pred[1][i])\n",
        "    p_m2 = y_pred[2][i][y_m2]/np.sum(y_pred[2][i])\n",
        "    p_max = max(max(p_m1, p_m2), p_m0)\n",
        "\n",
        "    # Necessary Conditions for pseudo label to be added through majority voting: Any two of three models prediction must be greater than threshold\n",
        "    if y_m0==y_m1 and p_m0>=threshold and p_m1>=threshold:\n",
        "      yes = 1\n",
        "      y_pred_new = y_m0\n",
        "      index_to_be_added.append(i)\n",
        "\n",
        "    elif y_m2==y_m1 and p_m2>=threshold and p_m1>=threshold:\n",
        "      yes = 1\n",
        "      y_pred_new = y_m1\n",
        "      index_to_be_added.append(i)\n",
        "\n",
        "    elif y_m0==y_m2 and p_m0>=threshold and p_m1>=threshold:\n",
        "      yes = 1\n",
        "      y_pred_new = y_m0\n",
        "      index_to_be_added.append(i)\n",
        "    \n",
        "      \n",
        "     # Update the labeled data\n",
        "    if yes==1:            \n",
        "      for j in range(3):\n",
        "        X_label_data[j] = np.append(X_label_data[j],np.array([X_un_data[j][i]]),axis=0)\n",
        "      y_label = np.append(y_label, np.array(to_categorical([y_pred_new], num_classes=10)), axis=0)\n",
        "      if y_pred_new == np.argmax(y_un[i]): pseudo_acc+=1   # calculate the percentage of correct pseudo label\n",
        "\n",
        "  if len(index_to_be_added)==0: break\n",
        "\n",
        "  # delete the pseudo labels from unlabeled\n",
        "  for i in range(3):\n",
        "    X_un_data[i] = np.delete(X_un_data[i], index_to_be_added, 0)\n",
        "\n",
        "  y_un = np.delete(y_un, index_to_be_added, 0)\n",
        "  labels_added.append(len(index_to_be_added))\n",
        "  pseudo_labels_acc.append(pseudo_acc*100/len(index_to_be_added))\n",
        "  iteration+=1\n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "model 0\n",
            "Epoch 1/300\n",
            "4/4 [==============================] - 3s 357ms/step - loss: 2.2854 - accuracy: 0.1028 - val_loss: 2.2248 - val_accuracy: 0.1313\n",
            "Epoch 2/300\n",
            "4/4 [==============================] - 1s 204ms/step - loss: 2.2104 - accuracy: 0.1364 - val_loss: 2.1240 - val_accuracy: 0.1893\n",
            "Epoch 3/300\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 2.1146 - accuracy: 0.2099 - val_loss: 2.0836 - val_accuracy: 0.2290\n",
            "Epoch 4/300\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 2.1333 - accuracy: 0.2007 - val_loss: 2.0511 - val_accuracy: 0.2580\n",
            "Epoch 5/300\n",
            "4/4 [==============================] - 1s 200ms/step - loss: 2.0479 - accuracy: 0.2403 - val_loss: 2.0147 - val_accuracy: 0.2397\n",
            "Epoch 6/300\n",
            "4/4 [==============================] - 1s 200ms/step - loss: 2.0239 - accuracy: 0.2476 - val_loss: 2.0024 - val_accuracy: 0.2382\n",
            "Epoch 7/300\n",
            "4/4 [==============================] - 1s 201ms/step - loss: 1.9818 - accuracy: 0.2665 - val_loss: 1.9302 - val_accuracy: 0.2748\n",
            "Epoch 8/300\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 1.9459 - accuracy: 0.2865 - val_loss: 1.8913 - val_accuracy: 0.2870\n",
            "Epoch 9/300\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 1.9121 - accuracy: 0.3038 - val_loss: 1.8309 - val_accuracy: 0.3084\n",
            "Epoch 10/300\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 1.8278 - accuracy: 0.3540 - val_loss: 1.7510 - val_accuracy: 0.3588\n",
            "Epoch 11/300\n",
            "4/4 [==============================] - 1s 197ms/step - loss: 1.7980 - accuracy: 0.3560 - val_loss: 1.7487 - val_accuracy: 0.3542\n",
            "Epoch 12/300\n",
            "4/4 [==============================] - 1s 201ms/step - loss: 1.7201 - accuracy: 0.3853 - val_loss: 1.6355 - val_accuracy: 0.4168\n",
            "Epoch 13/300\n",
            "4/4 [==============================] - 1s 201ms/step - loss: 1.6325 - accuracy: 0.4250 - val_loss: 1.7141 - val_accuracy: 0.3863\n",
            "Epoch 14/300\n",
            "4/4 [==============================] - 1s 199ms/step - loss: 1.6250 - accuracy: 0.4195 - val_loss: 1.6040 - val_accuracy: 0.4183\n",
            "Epoch 15/300\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 1.5419 - accuracy: 0.4429 - val_loss: 1.5728 - val_accuracy: 0.4229\n",
            "Epoch 16/300\n",
            "4/4 [==============================] - 1s 203ms/step - loss: 1.4724 - accuracy: 0.4869 - val_loss: 1.4499 - val_accuracy: 0.5008\n",
            "Epoch 17/300\n",
            "4/4 [==============================] - 1s 201ms/step - loss: 1.4028 - accuracy: 0.5018 - val_loss: 1.3834 - val_accuracy: 0.5328\n",
            "Epoch 18/300\n",
            "4/4 [==============================] - 1s 200ms/step - loss: 1.3296 - accuracy: 0.5357 - val_loss: 1.4020 - val_accuracy: 0.5221\n",
            "Epoch 19/300\n",
            "4/4 [==============================] - 1s 198ms/step - loss: 1.2944 - accuracy: 0.5502 - val_loss: 1.3222 - val_accuracy: 0.5618\n",
            "Epoch 20/300\n",
            "4/4 [==============================] - 1s 201ms/step - loss: 1.2127 - accuracy: 0.5828 - val_loss: 1.2499 - val_accuracy: 0.5817\n",
            "Epoch 21/300\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 1.1423 - accuracy: 0.6089 - val_loss: 1.2229 - val_accuracy: 0.5863\n",
            "Epoch 22/300\n",
            "4/4 [==============================] - 1s 206ms/step - loss: 1.1202 - accuracy: 0.6093 - val_loss: 1.2810 - val_accuracy: 0.5527\n",
            "Epoch 23/300\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 1.1184 - accuracy: 0.6128 - val_loss: 1.2002 - val_accuracy: 0.6137\n",
            "Epoch 24/300\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 1.0118 - accuracy: 0.6521 - val_loss: 1.1500 - val_accuracy: 0.6046\n",
            "Epoch 25/300\n",
            "4/4 [==============================] - 1s 200ms/step - loss: 0.9619 - accuracy: 0.6742 - val_loss: 1.1088 - val_accuracy: 0.6321\n",
            "Epoch 26/300\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 0.8923 - accuracy: 0.7055 - val_loss: 1.2246 - val_accuracy: 0.5863\n",
            "Epoch 27/300\n",
            "4/4 [==============================] - 1s 200ms/step - loss: 0.9165 - accuracy: 0.6874 - val_loss: 1.1911 - val_accuracy: 0.5924\n",
            "Epoch 28/300\n",
            "4/4 [==============================] - 1s 201ms/step - loss: 0.8653 - accuracy: 0.6943 - val_loss: 1.1748 - val_accuracy: 0.6382\n",
            "Epoch 29/300\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 0.8781 - accuracy: 0.7070 - val_loss: 1.1091 - val_accuracy: 0.6443\n",
            "Epoch 30/300\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 0.7795 - accuracy: 0.7464 - val_loss: 1.1014 - val_accuracy: 0.6458\n",
            "Epoch 31/300\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 0.7535 - accuracy: 0.7367 - val_loss: 1.1650 - val_accuracy: 0.6305\n",
            "Epoch 32/300\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 0.7834 - accuracy: 0.7227 - val_loss: 1.0569 - val_accuracy: 0.6504\n",
            "Epoch 33/300\n",
            "4/4 [==============================] - 1s 203ms/step - loss: 0.7465 - accuracy: 0.7291 - val_loss: 1.0245 - val_accuracy: 0.6901\n",
            "Epoch 34/300\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 0.7156 - accuracy: 0.7711 - val_loss: 1.0445 - val_accuracy: 0.6977\n",
            "Epoch 35/300\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 0.6484 - accuracy: 0.7852 - val_loss: 0.9907 - val_accuracy: 0.7084\n",
            "Epoch 36/300\n",
            "4/4 [==============================] - 1s 200ms/step - loss: 0.5684 - accuracy: 0.8192 - val_loss: 0.9875 - val_accuracy: 0.6992\n",
            "Epoch 37/300\n",
            "4/4 [==============================] - 1s 203ms/step - loss: 0.5388 - accuracy: 0.8365 - val_loss: 0.9758 - val_accuracy: 0.7221\n",
            "Epoch 38/300\n",
            "4/4 [==============================] - 1s 199ms/step - loss: 0.4858 - accuracy: 0.8551 - val_loss: 0.9285 - val_accuracy: 0.7450\n",
            "Epoch 39/300\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 0.4411 - accuracy: 0.8664 - val_loss: 0.9622 - val_accuracy: 0.7237\n",
            "Epoch 40/300\n",
            "4/4 [==============================] - 1s 207ms/step - loss: 0.4388 - accuracy: 0.8725 - val_loss: 1.0099 - val_accuracy: 0.7191\n",
            "Epoch 41/300\n",
            "4/4 [==============================] - 1s 201ms/step - loss: 0.4038 - accuracy: 0.8777 - val_loss: 0.9768 - val_accuracy: 0.7359\n",
            "Epoch 42/300\n",
            "4/4 [==============================] - 1s 203ms/step - loss: 0.3861 - accuracy: 0.8732 - val_loss: 0.9567 - val_accuracy: 0.7634\n",
            "Epoch 43/300\n",
            "4/4 [==============================] - 1s 204ms/step - loss: 0.3593 - accuracy: 0.8911 - val_loss: 0.9741 - val_accuracy: 0.7679\n",
            "Epoch 44/300\n",
            "4/4 [==============================] - 1s 203ms/step - loss: 0.3271 - accuracy: 0.9043 - val_loss: 0.9732 - val_accuracy: 0.7466\n",
            "Epoch 45/300\n",
            "4/4 [==============================] - 1s 201ms/step - loss: 0.2924 - accuracy: 0.9245 - val_loss: 1.0493 - val_accuracy: 0.7420\n",
            "Epoch 46/300\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 0.3200 - accuracy: 0.9054 - val_loss: 0.9689 - val_accuracy: 0.7511\n",
            "Epoch 47/300\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 0.2298 - accuracy: 0.9387 - val_loss: 0.9883 - val_accuracy: 0.7603\n",
            "Epoch 48/300\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 0.2459 - accuracy: 0.9309 - val_loss: 0.9326 - val_accuracy: 0.7786\n",
            "Epoch 49/300\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 0.2137 - accuracy: 0.9470 - val_loss: 0.9646 - val_accuracy: 0.7756\n",
            "Epoch 50/300\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 0.2026 - accuracy: 0.9410 - val_loss: 0.9434 - val_accuracy: 0.7786\n",
            "Epoch 51/300\n",
            "4/4 [==============================] - 1s 204ms/step - loss: 0.1912 - accuracy: 0.9434 - val_loss: 0.9360 - val_accuracy: 0.8046\n",
            "Epoch 52/300\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 0.1548 - accuracy: 0.9553 - val_loss: 0.9747 - val_accuracy: 0.8000\n",
            "Epoch 53/300\n",
            "4/4 [==============================] - 1s 206ms/step - loss: 0.1546 - accuracy: 0.9620 - val_loss: 0.9801 - val_accuracy: 0.8031\n",
            "Epoch 54/300\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 0.1561 - accuracy: 0.9577 - val_loss: 1.0032 - val_accuracy: 0.7832\n",
            "Epoch 55/300\n",
            "4/4 [==============================] - 1s 203ms/step - loss: 0.1746 - accuracy: 0.9483 - val_loss: 1.0299 - val_accuracy: 0.7863\n",
            "Epoch 56/300\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 0.1545 - accuracy: 0.9575 - val_loss: 1.0315 - val_accuracy: 0.7924\n",
            "Epoch 57/300\n",
            "4/4 [==============================] - 1s 204ms/step - loss: 0.1355 - accuracy: 0.9611 - val_loss: 1.0092 - val_accuracy: 0.8046\n",
            "Epoch 58/300\n",
            "4/4 [==============================] - 1s 206ms/step - loss: 0.1307 - accuracy: 0.9580 - val_loss: 1.0457 - val_accuracy: 0.7924\n",
            "Epoch 59/300\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 0.1420 - accuracy: 0.9559 - val_loss: 1.0282 - val_accuracy: 0.8046\n",
            "Epoch 60/300\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 0.1385 - accuracy: 0.9548 - val_loss: 1.0638 - val_accuracy: 0.7817\n",
            "Epoch 61/300\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 0.1246 - accuracy: 0.9666 - val_loss: 1.0998 - val_accuracy: 0.7832\n",
            "Epoch 62/300\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 0.1035 - accuracy: 0.9723 - val_loss: 1.0258 - val_accuracy: 0.8031\n",
            "Epoch 63/300\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 0.0955 - accuracy: 0.9751 - val_loss: 1.0288 - val_accuracy: 0.8137\n",
            "Epoch 64/300\n",
            "4/4 [==============================] - 1s 206ms/step - loss: 0.0913 - accuracy: 0.9761 - val_loss: 1.0121 - val_accuracy: 0.8168\n",
            "Epoch 65/300\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 0.0737 - accuracy: 0.9823 - val_loss: 1.0979 - val_accuracy: 0.7985\n",
            "Epoch 66/300\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 0.0734 - accuracy: 0.9816 - val_loss: 1.1009 - val_accuracy: 0.7969\n",
            "Epoch 67/300\n",
            "4/4 [==============================] - 1s 211ms/step - loss: 0.0777 - accuracy: 0.9794 - val_loss: 1.0503 - val_accuracy: 0.8153\n",
            "Epoch 68/300\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 0.0912 - accuracy: 0.9736 - val_loss: 1.1335 - val_accuracy: 0.8015\n",
            "Epoch 69/300\n",
            "4/4 [==============================] - 1s 204ms/step - loss: 0.0909 - accuracy: 0.9760 - val_loss: 1.0700 - val_accuracy: 0.8092\n",
            "Epoch 70/300\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 0.0689 - accuracy: 0.9823 - val_loss: 1.0545 - val_accuracy: 0.8092\n",
            "Epoch 71/300\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 0.0702 - accuracy: 0.9842 - val_loss: 1.1049 - val_accuracy: 0.8046\n",
            "Epoch 72/300\n",
            "4/4 [==============================] - 1s 214ms/step - loss: 0.0554 - accuracy: 0.9891 - val_loss: 1.0475 - val_accuracy: 0.8168\n",
            "Epoch 73/300\n",
            "4/4 [==============================] - 1s 206ms/step - loss: 0.0485 - accuracy: 0.9897 - val_loss: 1.1122 - val_accuracy: 0.8122\n",
            "Epoch 74/300\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 0.0391 - accuracy: 0.9938 - val_loss: 1.1043 - val_accuracy: 0.8092\n",
            "Epoch 75/300\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 0.0387 - accuracy: 0.9901 - val_loss: 1.1219 - val_accuracy: 0.8076\n",
            "Epoch 76/300\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 0.0280 - accuracy: 0.9976 - val_loss: 1.0691 - val_accuracy: 0.8168\n",
            "Epoch 77/300\n",
            "4/4 [==============================] - 1s 209ms/step - loss: 0.0299 - accuracy: 0.9963 - val_loss: 1.1305 - val_accuracy: 0.8137\n",
            "Epoch 78/300\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 0.0295 - accuracy: 0.9945 - val_loss: 1.1222 - val_accuracy: 0.8229\n",
            "model 1\n",
            "Epoch 1/300\n",
            "4/4 [==============================] - 3s 470ms/step - loss: 2.3042 - accuracy: 0.1386 - val_loss: 2.2002 - val_accuracy: 0.3053\n",
            "Epoch 2/300\n",
            "4/4 [==============================] - 1s 347ms/step - loss: 2.1774 - accuracy: 0.2427 - val_loss: 2.0963 - val_accuracy: 0.2076\n",
            "Epoch 3/300\n",
            "4/4 [==============================] - 1s 339ms/step - loss: 2.0890 - accuracy: 0.2445 - val_loss: 1.9626 - val_accuracy: 0.3191\n",
            "Epoch 4/300\n",
            "4/4 [==============================] - 1s 344ms/step - loss: 1.9316 - accuracy: 0.3154 - val_loss: 1.9020 - val_accuracy: 0.2962\n",
            "Epoch 5/300\n",
            "4/4 [==============================] - 1s 337ms/step - loss: 1.8445 - accuracy: 0.3418 - val_loss: 1.8058 - val_accuracy: 0.3771\n",
            "Epoch 6/300\n",
            "4/4 [==============================] - 1s 352ms/step - loss: 1.7841 - accuracy: 0.3676 - val_loss: 1.7046 - val_accuracy: 0.4412\n",
            "Epoch 7/300\n",
            "4/4 [==============================] - 1s 393ms/step - loss: 1.6902 - accuracy: 0.4122 - val_loss: 1.6554 - val_accuracy: 0.4840\n",
            "Epoch 8/300\n",
            "4/4 [==============================] - 1s 370ms/step - loss: 1.6527 - accuracy: 0.4410 - val_loss: 1.6504 - val_accuracy: 0.4641\n",
            "Epoch 9/300\n",
            "4/4 [==============================] - 1s 371ms/step - loss: 1.6027 - accuracy: 0.4469 - val_loss: 1.5529 - val_accuracy: 0.4962\n",
            "Epoch 10/300\n",
            "4/4 [==============================] - 1s 347ms/step - loss: 1.5348 - accuracy: 0.4629 - val_loss: 1.5395 - val_accuracy: 0.5252\n",
            "Epoch 11/300\n",
            "4/4 [==============================] - 1s 372ms/step - loss: 1.4637 - accuracy: 0.5100 - val_loss: 1.4535 - val_accuracy: 0.5817\n",
            "Epoch 12/300\n",
            "4/4 [==============================] - 1s 370ms/step - loss: 1.4531 - accuracy: 0.5073 - val_loss: 1.4195 - val_accuracy: 0.5649\n",
            "Epoch 13/300\n",
            "4/4 [==============================] - 1s 355ms/step - loss: 1.3986 - accuracy: 0.5298 - val_loss: 1.3529 - val_accuracy: 0.5832\n",
            "Epoch 14/300\n",
            "4/4 [==============================] - 1s 365ms/step - loss: 1.3891 - accuracy: 0.5256 - val_loss: 1.3092 - val_accuracy: 0.6183\n",
            "Epoch 15/300\n",
            "4/4 [==============================] - 1s 390ms/step - loss: 1.3296 - accuracy: 0.5495 - val_loss: 1.2993 - val_accuracy: 0.5924\n",
            "Epoch 16/300\n",
            "4/4 [==============================] - 2s 417ms/step - loss: 1.2866 - accuracy: 0.5793 - val_loss: 1.2981 - val_accuracy: 0.5969\n",
            "Epoch 17/300\n",
            "4/4 [==============================] - 2s 404ms/step - loss: 1.2732 - accuracy: 0.5845 - val_loss: 1.2545 - val_accuracy: 0.6183\n",
            "Epoch 18/300\n",
            "4/4 [==============================] - 1s 385ms/step - loss: 1.2362 - accuracy: 0.5923 - val_loss: 1.2102 - val_accuracy: 0.6244\n",
            "Epoch 19/300\n",
            "4/4 [==============================] - 2s 397ms/step - loss: 1.1455 - accuracy: 0.6109 - val_loss: 1.1670 - val_accuracy: 0.6458\n",
            "Epoch 20/300\n",
            "4/4 [==============================] - 2s 401ms/step - loss: 1.1655 - accuracy: 0.6112 - val_loss: 1.1447 - val_accuracy: 0.6519\n",
            "Epoch 21/300\n",
            "4/4 [==============================] - 2s 394ms/step - loss: 1.1525 - accuracy: 0.6106 - val_loss: 1.1398 - val_accuracy: 0.6580\n",
            "Epoch 22/300\n",
            "4/4 [==============================] - 2s 400ms/step - loss: 1.1118 - accuracy: 0.6220 - val_loss: 1.1102 - val_accuracy: 0.6611\n",
            "Epoch 23/300\n",
            "4/4 [==============================] - 2s 414ms/step - loss: 1.0763 - accuracy: 0.6529 - val_loss: 1.0800 - val_accuracy: 0.6702\n",
            "Epoch 24/300\n",
            "4/4 [==============================] - 2s 395ms/step - loss: 1.0557 - accuracy: 0.6577 - val_loss: 1.0697 - val_accuracy: 0.6611\n",
            "Epoch 25/300\n",
            "4/4 [==============================] - 2s 430ms/step - loss: 1.0607 - accuracy: 0.6652 - val_loss: 1.0179 - val_accuracy: 0.6855\n",
            "Epoch 26/300\n",
            "4/4 [==============================] - 2s 419ms/step - loss: 0.9909 - accuracy: 0.6785 - val_loss: 1.0530 - val_accuracy: 0.6718\n",
            "Epoch 27/300\n",
            "4/4 [==============================] - 1s 389ms/step - loss: 0.9741 - accuracy: 0.6677 - val_loss: 0.9945 - val_accuracy: 0.6947\n",
            "Epoch 28/300\n",
            "4/4 [==============================] - 2s 417ms/step - loss: 0.9460 - accuracy: 0.6828 - val_loss: 0.9668 - val_accuracy: 0.7069\n",
            "Epoch 29/300\n",
            "4/4 [==============================] - 2s 408ms/step - loss: 0.9625 - accuracy: 0.6830 - val_loss: 0.9158 - val_accuracy: 0.7374\n",
            "Epoch 30/300\n",
            "4/4 [==============================] - 2s 446ms/step - loss: 0.9310 - accuracy: 0.6900 - val_loss: 0.9345 - val_accuracy: 0.7145\n",
            "Epoch 31/300\n",
            "4/4 [==============================] - 2s 396ms/step - loss: 0.8979 - accuracy: 0.6913 - val_loss: 0.9490 - val_accuracy: 0.7145\n",
            "Epoch 32/300\n",
            "4/4 [==============================] - 2s 403ms/step - loss: 0.8557 - accuracy: 0.7168 - val_loss: 0.8713 - val_accuracy: 0.7450\n",
            "Epoch 33/300\n",
            "4/4 [==============================] - 2s 397ms/step - loss: 0.8491 - accuracy: 0.7311 - val_loss: 0.8969 - val_accuracy: 0.7191\n",
            "Epoch 34/300\n",
            "4/4 [==============================] - 1s 390ms/step - loss: 0.8221 - accuracy: 0.7143 - val_loss: 0.8539 - val_accuracy: 0.7466\n",
            "Epoch 35/300\n",
            "4/4 [==============================] - 1s 366ms/step - loss: 0.7894 - accuracy: 0.7281 - val_loss: 0.8643 - val_accuracy: 0.7344\n",
            "Epoch 36/300\n",
            "4/4 [==============================] - 1s 365ms/step - loss: 0.7665 - accuracy: 0.7545 - val_loss: 0.8132 - val_accuracy: 0.7450\n",
            "Epoch 37/300\n",
            "4/4 [==============================] - 1s 353ms/step - loss: 0.7716 - accuracy: 0.7451 - val_loss: 0.8260 - val_accuracy: 0.7481\n",
            "Epoch 38/300\n",
            "4/4 [==============================] - 1s 359ms/step - loss: 0.7440 - accuracy: 0.7730 - val_loss: 0.8043 - val_accuracy: 0.7603\n",
            "Epoch 39/300\n",
            "4/4 [==============================] - 1s 341ms/step - loss: 0.6860 - accuracy: 0.7672 - val_loss: 0.7968 - val_accuracy: 0.7496\n",
            "Epoch 40/300\n",
            "4/4 [==============================] - 1s 334ms/step - loss: 0.6956 - accuracy: 0.7701 - val_loss: 0.7520 - val_accuracy: 0.7771\n",
            "Epoch 41/300\n",
            "4/4 [==============================] - 1s 348ms/step - loss: 0.6933 - accuracy: 0.7738 - val_loss: 0.7800 - val_accuracy: 0.7603\n",
            "Epoch 42/300\n",
            "4/4 [==============================] - 1s 339ms/step - loss: 0.6412 - accuracy: 0.7801 - val_loss: 0.7465 - val_accuracy: 0.7740\n",
            "Epoch 43/300\n",
            "4/4 [==============================] - 1s 346ms/step - loss: 0.6317 - accuracy: 0.7948 - val_loss: 0.7283 - val_accuracy: 0.7832\n",
            "Epoch 44/300\n",
            "4/4 [==============================] - 1s 340ms/step - loss: 0.6232 - accuracy: 0.7978 - val_loss: 0.7440 - val_accuracy: 0.7710\n",
            "Epoch 45/300\n",
            "4/4 [==============================] - 1s 341ms/step - loss: 0.5834 - accuracy: 0.8059 - val_loss: 0.7376 - val_accuracy: 0.7740\n",
            "Epoch 46/300\n",
            "4/4 [==============================] - 1s 327ms/step - loss: 0.5697 - accuracy: 0.8067 - val_loss: 0.7007 - val_accuracy: 0.7725\n",
            "Epoch 47/300\n",
            "4/4 [==============================] - 1s 355ms/step - loss: 0.5709 - accuracy: 0.8092 - val_loss: 0.7223 - val_accuracy: 0.7817\n",
            "Epoch 48/300\n",
            "4/4 [==============================] - 1s 332ms/step - loss: 0.5546 - accuracy: 0.8105 - val_loss: 0.6625 - val_accuracy: 0.8198\n",
            "Epoch 49/300\n",
            "4/4 [==============================] - 1s 335ms/step - loss: 0.5617 - accuracy: 0.8271 - val_loss: 0.6594 - val_accuracy: 0.8031\n",
            "Epoch 50/300\n",
            "4/4 [==============================] - 1s 330ms/step - loss: 0.4987 - accuracy: 0.8439 - val_loss: 0.6524 - val_accuracy: 0.8061\n",
            "Epoch 51/300\n",
            "4/4 [==============================] - 1s 330ms/step - loss: 0.5620 - accuracy: 0.8171 - val_loss: 0.6125 - val_accuracy: 0.8137\n",
            "Epoch 52/300\n",
            "4/4 [==============================] - 1s 331ms/step - loss: 0.4577 - accuracy: 0.8545 - val_loss: 0.6508 - val_accuracy: 0.8122\n",
            "Epoch 53/300\n",
            "4/4 [==============================] - 1s 327ms/step - loss: 0.5112 - accuracy: 0.8327 - val_loss: 0.6381 - val_accuracy: 0.8275\n",
            "Epoch 54/300\n",
            "4/4 [==============================] - 1s 327ms/step - loss: 0.4635 - accuracy: 0.8393 - val_loss: 0.5985 - val_accuracy: 0.8427\n",
            "Epoch 55/300\n",
            "4/4 [==============================] - 1s 347ms/step - loss: 0.4606 - accuracy: 0.8502 - val_loss: 0.6295 - val_accuracy: 0.8153\n",
            "Epoch 56/300\n",
            "4/4 [==============================] - 1s 340ms/step - loss: 0.4403 - accuracy: 0.8545 - val_loss: 0.5925 - val_accuracy: 0.8244\n",
            "Epoch 57/300\n",
            "4/4 [==============================] - 1s 330ms/step - loss: 0.4460 - accuracy: 0.8460 - val_loss: 0.6142 - val_accuracy: 0.8229\n",
            "Epoch 58/300\n",
            "4/4 [==============================] - 1s 319ms/step - loss: 0.4407 - accuracy: 0.8463 - val_loss: 0.5677 - val_accuracy: 0.8305\n",
            "Epoch 59/300\n",
            "4/4 [==============================] - 1s 345ms/step - loss: 0.4363 - accuracy: 0.8484 - val_loss: 0.6013 - val_accuracy: 0.8366\n",
            "Epoch 60/300\n",
            "4/4 [==============================] - 1s 345ms/step - loss: 0.4120 - accuracy: 0.8597 - val_loss: 0.5791 - val_accuracy: 0.8321\n",
            "Epoch 61/300\n",
            "4/4 [==============================] - 1s 319ms/step - loss: 0.4329 - accuracy: 0.8624 - val_loss: 0.5710 - val_accuracy: 0.8427\n",
            "Epoch 62/300\n",
            "4/4 [==============================] - 1s 324ms/step - loss: 0.3899 - accuracy: 0.8746 - val_loss: 0.5659 - val_accuracy: 0.8473\n",
            "Epoch 63/300\n",
            "4/4 [==============================] - 1s 333ms/step - loss: 0.3643 - accuracy: 0.8684 - val_loss: 0.5813 - val_accuracy: 0.8412\n",
            "Epoch 64/300\n",
            "4/4 [==============================] - 1s 378ms/step - loss: 0.3743 - accuracy: 0.8740 - val_loss: 0.5466 - val_accuracy: 0.8443\n",
            "Epoch 65/300\n",
            "4/4 [==============================] - 1s 379ms/step - loss: 0.3920 - accuracy: 0.8687 - val_loss: 0.5751 - val_accuracy: 0.8443\n",
            "Epoch 66/300\n",
            "4/4 [==============================] - 1s 338ms/step - loss: 0.3730 - accuracy: 0.8773 - val_loss: 0.5649 - val_accuracy: 0.8489\n",
            "Epoch 67/300\n",
            "4/4 [==============================] - 1s 340ms/step - loss: 0.3266 - accuracy: 0.8990 - val_loss: 0.5804 - val_accuracy: 0.8382\n",
            "Epoch 68/300\n",
            "4/4 [==============================] - 1s 326ms/step - loss: 0.3449 - accuracy: 0.8784 - val_loss: 0.5292 - val_accuracy: 0.8534\n",
            "Epoch 69/300\n",
            "4/4 [==============================] - 1s 333ms/step - loss: 0.3333 - accuracy: 0.8900 - val_loss: 0.5627 - val_accuracy: 0.8412\n",
            "Epoch 70/300\n",
            "4/4 [==============================] - 1s 338ms/step - loss: 0.2942 - accuracy: 0.8953 - val_loss: 0.5409 - val_accuracy: 0.8595\n",
            "Epoch 71/300\n",
            "4/4 [==============================] - 1s 346ms/step - loss: 0.3423 - accuracy: 0.8780 - val_loss: 0.5657 - val_accuracy: 0.8489\n",
            "Epoch 72/300\n",
            "4/4 [==============================] - 1s 324ms/step - loss: 0.3434 - accuracy: 0.8849 - val_loss: 0.5707 - val_accuracy: 0.8534\n",
            "Epoch 73/300\n",
            "4/4 [==============================] - 1s 323ms/step - loss: 0.3157 - accuracy: 0.8943 - val_loss: 0.5450 - val_accuracy: 0.8595\n",
            "Epoch 74/300\n",
            "4/4 [==============================] - 1s 327ms/step - loss: 0.3025 - accuracy: 0.8996 - val_loss: 0.5836 - val_accuracy: 0.8351\n",
            "Epoch 75/300\n",
            "4/4 [==============================] - 1s 330ms/step - loss: 0.2786 - accuracy: 0.9011 - val_loss: 0.5494 - val_accuracy: 0.8489\n",
            "Epoch 76/300\n",
            "4/4 [==============================] - 1s 349ms/step - loss: 0.2924 - accuracy: 0.9031 - val_loss: 0.5552 - val_accuracy: 0.8489\n",
            "Epoch 77/300\n",
            "4/4 [==============================] - 1s 322ms/step - loss: 0.2727 - accuracy: 0.9093 - val_loss: 0.5635 - val_accuracy: 0.8565\n",
            "Epoch 78/300\n",
            "4/4 [==============================] - 1s 326ms/step - loss: 0.2712 - accuracy: 0.9116 - val_loss: 0.5472 - val_accuracy: 0.8504\n",
            "Epoch 79/300\n",
            "4/4 [==============================] - 1s 346ms/step - loss: 0.2698 - accuracy: 0.9162 - val_loss: 0.5553 - val_accuracy: 0.8473\n",
            "Epoch 80/300\n",
            "4/4 [==============================] - 1s 329ms/step - loss: 0.2764 - accuracy: 0.9074 - val_loss: 0.5631 - val_accuracy: 0.8412\n",
            "Epoch 81/300\n",
            "4/4 [==============================] - 1s 320ms/step - loss: 0.3034 - accuracy: 0.8957 - val_loss: 0.5878 - val_accuracy: 0.8366\n",
            "Epoch 82/300\n",
            "4/4 [==============================] - 1s 324ms/step - loss: 0.2623 - accuracy: 0.9214 - val_loss: 0.5810 - val_accuracy: 0.8458\n",
            "Epoch 83/300\n",
            "4/4 [==============================] - 1s 330ms/step - loss: 0.2558 - accuracy: 0.9126 - val_loss: 0.5475 - val_accuracy: 0.8473\n",
            "Epoch 84/300\n",
            "4/4 [==============================] - 1s 320ms/step - loss: 0.2555 - accuracy: 0.9038 - val_loss: 0.6042 - val_accuracy: 0.8412\n",
            "Epoch 85/300\n",
            "4/4 [==============================] - 1s 320ms/step - loss: 0.2456 - accuracy: 0.9193 - val_loss: 0.5304 - val_accuracy: 0.8550\n",
            "Epoch 86/300\n",
            "4/4 [==============================] - 1s 328ms/step - loss: 0.2578 - accuracy: 0.9100 - val_loss: 0.5544 - val_accuracy: 0.8534\n",
            "Epoch 87/300\n",
            "4/4 [==============================] - 1s 361ms/step - loss: 0.2497 - accuracy: 0.9194 - val_loss: 0.5052 - val_accuracy: 0.8550\n",
            "Epoch 88/300\n",
            "4/4 [==============================] - 1s 322ms/step - loss: 0.2249 - accuracy: 0.9307 - val_loss: 0.5606 - val_accuracy: 0.8519\n",
            "Epoch 89/300\n",
            "4/4 [==============================] - 1s 316ms/step - loss: 0.2411 - accuracy: 0.9196 - val_loss: 0.5563 - val_accuracy: 0.8519\n",
            "Epoch 90/300\n",
            "4/4 [==============================] - 1s 328ms/step - loss: 0.2344 - accuracy: 0.9276 - val_loss: 0.5939 - val_accuracy: 0.8504\n",
            "Epoch 91/300\n",
            "4/4 [==============================] - 1s 328ms/step - loss: 0.2508 - accuracy: 0.9179 - val_loss: 0.5389 - val_accuracy: 0.8656\n",
            "Epoch 92/300\n",
            "4/4 [==============================] - 1s 319ms/step - loss: 0.2082 - accuracy: 0.9250 - val_loss: 0.5522 - val_accuracy: 0.8595\n",
            "Epoch 93/300\n",
            "4/4 [==============================] - 1s 316ms/step - loss: 0.1926 - accuracy: 0.9347 - val_loss: 0.5617 - val_accuracy: 0.8565\n",
            "Epoch 94/300\n",
            "4/4 [==============================] - 1s 322ms/step - loss: 0.2054 - accuracy: 0.9325 - val_loss: 0.5644 - val_accuracy: 0.8626\n",
            "Epoch 95/300\n",
            "4/4 [==============================] - 1s 365ms/step - loss: 0.1846 - accuracy: 0.9382 - val_loss: 0.5721 - val_accuracy: 0.8672\n",
            "Epoch 96/300\n",
            "4/4 [==============================] - 1s 318ms/step - loss: 0.1935 - accuracy: 0.9344 - val_loss: 0.5646 - val_accuracy: 0.8687\n",
            "Epoch 97/300\n",
            "4/4 [==============================] - 1s 321ms/step - loss: 0.1914 - accuracy: 0.9381 - val_loss: 0.5389 - val_accuracy: 0.8550\n",
            "Epoch 98/300\n",
            "4/4 [==============================] - 1s 319ms/step - loss: 0.2065 - accuracy: 0.9377 - val_loss: 0.5057 - val_accuracy: 0.8626\n",
            "Epoch 99/300\n",
            "4/4 [==============================] - 1s 319ms/step - loss: 0.1798 - accuracy: 0.9452 - val_loss: 0.5439 - val_accuracy: 0.8443\n",
            "Epoch 100/300\n",
            "4/4 [==============================] - 1s 320ms/step - loss: 0.1789 - accuracy: 0.9525 - val_loss: 0.5582 - val_accuracy: 0.8519\n",
            "Epoch 101/300\n",
            "4/4 [==============================] - 1s 318ms/step - loss: 0.1819 - accuracy: 0.9443 - val_loss: 0.5384 - val_accuracy: 0.8580\n",
            "Epoch 102/300\n",
            "4/4 [==============================] - 1s 321ms/step - loss: 0.1796 - accuracy: 0.9389 - val_loss: 0.5329 - val_accuracy: 0.8580\n",
            "Epoch 103/300\n",
            "4/4 [==============================] - 1s 324ms/step - loss: 0.1963 - accuracy: 0.9311 - val_loss: 0.5494 - val_accuracy: 0.8473\n",
            "Epoch 104/300\n",
            "4/4 [==============================] - 1s 329ms/step - loss: 0.1705 - accuracy: 0.9467 - val_loss: 0.5777 - val_accuracy: 0.8427\n",
            "Epoch 105/300\n",
            "4/4 [==============================] - 1s 321ms/step - loss: 0.1683 - accuracy: 0.9497 - val_loss: 0.5548 - val_accuracy: 0.8565\n",
            "Epoch 106/300\n",
            "4/4 [==============================] - 1s 318ms/step - loss: 0.1916 - accuracy: 0.9352 - val_loss: 0.5217 - val_accuracy: 0.8687\n",
            "Epoch 107/300\n",
            "4/4 [==============================] - 1s 326ms/step - loss: 0.1538 - accuracy: 0.9496 - val_loss: 0.5925 - val_accuracy: 0.8504\n",
            "Epoch 108/300\n",
            "4/4 [==============================] - 1s 331ms/step - loss: 0.1553 - accuracy: 0.9472 - val_loss: 0.5611 - val_accuracy: 0.8550\n",
            "Epoch 109/300\n",
            "4/4 [==============================] - 1s 319ms/step - loss: 0.1847 - accuracy: 0.9334 - val_loss: 0.5032 - val_accuracy: 0.8611\n",
            "Epoch 110/300\n",
            "4/4 [==============================] - 1s 330ms/step - loss: 0.1706 - accuracy: 0.9443 - val_loss: 0.5454 - val_accuracy: 0.8443\n",
            "Epoch 111/300\n",
            "4/4 [==============================] - 1s 324ms/step - loss: 0.1678 - accuracy: 0.9446 - val_loss: 0.5701 - val_accuracy: 0.8504\n",
            "Epoch 112/300\n",
            "4/4 [==============================] - 1s 318ms/step - loss: 0.1910 - accuracy: 0.9417 - val_loss: 0.4970 - val_accuracy: 0.8626\n",
            "Epoch 113/300\n",
            "4/4 [==============================] - 1s 321ms/step - loss: 0.1403 - accuracy: 0.9589 - val_loss: 0.5066 - val_accuracy: 0.8550\n",
            "Epoch 114/300\n",
            "4/4 [==============================] - 1s 313ms/step - loss: 0.1556 - accuracy: 0.9561 - val_loss: 0.5153 - val_accuracy: 0.8611\n",
            "Epoch 115/300\n",
            "4/4 [==============================] - 1s 330ms/step - loss: 0.1599 - accuracy: 0.9468 - val_loss: 0.5070 - val_accuracy: 0.8733\n",
            "Epoch 116/300\n",
            "4/4 [==============================] - 1s 325ms/step - loss: 0.1493 - accuracy: 0.9495 - val_loss: 0.5685 - val_accuracy: 0.8656\n",
            "Epoch 117/300\n",
            "4/4 [==============================] - 1s 325ms/step - loss: 0.1504 - accuracy: 0.9519 - val_loss: 0.5697 - val_accuracy: 0.8534\n",
            "Epoch 118/300\n",
            "4/4 [==============================] - 1s 315ms/step - loss: 0.1455 - accuracy: 0.9531 - val_loss: 0.5512 - val_accuracy: 0.8580\n",
            "Epoch 119/300\n",
            "4/4 [==============================] - 1s 312ms/step - loss: 0.1612 - accuracy: 0.9413 - val_loss: 0.6001 - val_accuracy: 0.8458\n",
            "Epoch 120/300\n",
            "4/4 [==============================] - 1s 321ms/step - loss: 0.1552 - accuracy: 0.9508 - val_loss: 0.5750 - val_accuracy: 0.8504\n",
            "Epoch 121/300\n",
            "4/4 [==============================] - 1s 311ms/step - loss: 0.1558 - accuracy: 0.9511 - val_loss: 0.5531 - val_accuracy: 0.8519\n",
            "Epoch 122/300\n",
            "4/4 [==============================] - 1s 317ms/step - loss: 0.1526 - accuracy: 0.9504 - val_loss: 0.5579 - val_accuracy: 0.8611\n",
            "Epoch 123/300\n",
            "4/4 [==============================] - 1s 328ms/step - loss: 0.1480 - accuracy: 0.9527 - val_loss: 0.5335 - val_accuracy: 0.8565\n",
            "Epoch 124/300\n",
            "4/4 [==============================] - 1s 317ms/step - loss: 0.1382 - accuracy: 0.9557 - val_loss: 0.5294 - val_accuracy: 0.8611\n",
            "Epoch 125/300\n",
            "4/4 [==============================] - 1s 313ms/step - loss: 0.1440 - accuracy: 0.9495 - val_loss: 0.5611 - val_accuracy: 0.8519\n",
            "Epoch 126/300\n",
            "4/4 [==============================] - 1s 317ms/step - loss: 0.1418 - accuracy: 0.9622 - val_loss: 0.5705 - val_accuracy: 0.8550\n",
            "Epoch 127/300\n",
            "4/4 [==============================] - 1s 309ms/step - loss: 0.1255 - accuracy: 0.9620 - val_loss: 0.5743 - val_accuracy: 0.8611\n",
            "Epoch 128/300\n",
            "4/4 [==============================] - 1s 313ms/step - loss: 0.1183 - accuracy: 0.9604 - val_loss: 0.5739 - val_accuracy: 0.8656\n",
            "Epoch 129/300\n",
            "4/4 [==============================] - 1s 314ms/step - loss: 0.1334 - accuracy: 0.9533 - val_loss: 0.5715 - val_accuracy: 0.8626\n",
            "Epoch 130/300\n",
            "4/4 [==============================] - 1s 309ms/step - loss: 0.1401 - accuracy: 0.9544 - val_loss: 0.5610 - val_accuracy: 0.8550\n",
            "Epoch 131/300\n",
            "4/4 [==============================] - 1s 307ms/step - loss: 0.1341 - accuracy: 0.9556 - val_loss: 0.5671 - val_accuracy: 0.8580\n",
            "Epoch 132/300\n",
            "4/4 [==============================] - 1s 312ms/step - loss: 0.1138 - accuracy: 0.9654 - val_loss: 0.5982 - val_accuracy: 0.8580\n",
            "Epoch 133/300\n",
            "4/4 [==============================] - 1s 312ms/step - loss: 0.1177 - accuracy: 0.9586 - val_loss: 0.5261 - val_accuracy: 0.8656\n",
            "Epoch 134/300\n",
            "4/4 [==============================] - 1s 310ms/step - loss: 0.1595 - accuracy: 0.9478 - val_loss: 0.5379 - val_accuracy: 0.8672\n",
            "Epoch 135/300\n",
            "4/4 [==============================] - 1s 313ms/step - loss: 0.1284 - accuracy: 0.9591 - val_loss: 0.5515 - val_accuracy: 0.8672\n",
            "Epoch 136/300\n",
            "4/4 [==============================] - 1s 308ms/step - loss: 0.1205 - accuracy: 0.9626 - val_loss: 0.5539 - val_accuracy: 0.8611\n",
            "Epoch 137/300\n",
            "4/4 [==============================] - 1s 313ms/step - loss: 0.1312 - accuracy: 0.9544 - val_loss: 0.5346 - val_accuracy: 0.8580\n",
            "Epoch 138/300\n",
            "4/4 [==============================] - 1s 322ms/step - loss: 0.1064 - accuracy: 0.9675 - val_loss: 0.5731 - val_accuracy: 0.8580\n",
            "Epoch 139/300\n",
            "4/4 [==============================] - 1s 311ms/step - loss: 0.1104 - accuracy: 0.9645 - val_loss: 0.5717 - val_accuracy: 0.8565\n",
            "Epoch 140/300\n",
            "4/4 [==============================] - 1s 318ms/step - loss: 0.1320 - accuracy: 0.9536 - val_loss: 0.5710 - val_accuracy: 0.8626\n",
            "Epoch 141/300\n",
            "4/4 [==============================] - 1s 310ms/step - loss: 0.1212 - accuracy: 0.9620 - val_loss: 0.5699 - val_accuracy: 0.8534\n",
            "Epoch 142/300\n",
            "4/4 [==============================] - 1s 310ms/step - loss: 0.1196 - accuracy: 0.9605 - val_loss: 0.5880 - val_accuracy: 0.8550\n",
            "Epoch 143/300\n",
            "4/4 [==============================] - 1s 312ms/step - loss: 0.1224 - accuracy: 0.9559 - val_loss: 0.5970 - val_accuracy: 0.8626\n",
            "Epoch 144/300\n",
            "4/4 [==============================] - 1s 305ms/step - loss: 0.1176 - accuracy: 0.9617 - val_loss: 0.5785 - val_accuracy: 0.8550\n",
            "Epoch 145/300\n",
            "4/4 [==============================] - 1s 314ms/step - loss: 0.1086 - accuracy: 0.9681 - val_loss: 0.5538 - val_accuracy: 0.8565\n",
            "Epoch 146/300\n",
            "4/4 [==============================] - 1s 310ms/step - loss: 0.1190 - accuracy: 0.9544 - val_loss: 0.5755 - val_accuracy: 0.8550\n",
            "Epoch 147/300\n",
            "4/4 [==============================] - 1s 312ms/step - loss: 0.1085 - accuracy: 0.9650 - val_loss: 0.5962 - val_accuracy: 0.8626\n",
            "Epoch 148/300\n",
            "4/4 [==============================] - 1s 309ms/step - loss: 0.1217 - accuracy: 0.9602 - val_loss: 0.6204 - val_accuracy: 0.8641\n",
            "Epoch 149/300\n",
            "4/4 [==============================] - 1s 313ms/step - loss: 0.1273 - accuracy: 0.9548 - val_loss: 0.5972 - val_accuracy: 0.8580\n",
            "Epoch 150/300\n",
            "4/4 [==============================] - 1s 309ms/step - loss: 0.1096 - accuracy: 0.9655 - val_loss: 0.5855 - val_accuracy: 0.8656\n",
            "Epoch 151/300\n",
            "4/4 [==============================] - 1s 304ms/step - loss: 0.1266 - accuracy: 0.9573 - val_loss: 0.5927 - val_accuracy: 0.8534\n",
            "Epoch 152/300\n",
            "4/4 [==============================] - 1s 309ms/step - loss: 0.1026 - accuracy: 0.9670 - val_loss: 0.6022 - val_accuracy: 0.8519\n",
            "model 2\n",
            "Epoch 1/300\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 2.2946 - accuracy: 0.1462 - val_loss: 2.0309 - val_accuracy: 0.2076\n",
            "Epoch 2/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 2.0440 - accuracy: 0.2545 - val_loss: 1.8098 - val_accuracy: 0.3603\n",
            "Epoch 3/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.8238 - accuracy: 0.3614 - val_loss: 1.6339 - val_accuracy: 0.4153\n",
            "Epoch 4/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.7122 - accuracy: 0.3951 - val_loss: 1.5569 - val_accuracy: 0.4901\n",
            "Epoch 5/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.5908 - accuracy: 0.4518 - val_loss: 1.5971 - val_accuracy: 0.4779\n",
            "Epoch 6/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.4918 - accuracy: 0.4813 - val_loss: 1.4805 - val_accuracy: 0.4733\n",
            "Epoch 7/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.4509 - accuracy: 0.4886 - val_loss: 1.3412 - val_accuracy: 0.5573\n",
            "Epoch 8/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.3133 - accuracy: 0.5344 - val_loss: 1.3077 - val_accuracy: 0.5603\n",
            "Epoch 9/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.2709 - accuracy: 0.5551 - val_loss: 1.3253 - val_accuracy: 0.5374\n",
            "Epoch 10/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.2770 - accuracy: 0.5587 - val_loss: 1.2411 - val_accuracy: 0.5725\n",
            "Epoch 11/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.2290 - accuracy: 0.5813 - val_loss: 1.2286 - val_accuracy: 0.5847\n",
            "Epoch 12/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.2093 - accuracy: 0.5822 - val_loss: 1.1998 - val_accuracy: 0.6046\n",
            "Epoch 13/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.1906 - accuracy: 0.5838 - val_loss: 1.1612 - val_accuracy: 0.6198\n",
            "Epoch 14/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.0971 - accuracy: 0.6189 - val_loss: 1.0880 - val_accuracy: 0.6473\n",
            "Epoch 15/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.1069 - accuracy: 0.6040 - val_loss: 1.0974 - val_accuracy: 0.6473\n",
            "Epoch 16/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.0767 - accuracy: 0.6384 - val_loss: 1.0666 - val_accuracy: 0.6534\n",
            "Epoch 17/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.0276 - accuracy: 0.6426 - val_loss: 1.0085 - val_accuracy: 0.6626\n",
            "Epoch 18/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.0392 - accuracy: 0.6346 - val_loss: 0.9967 - val_accuracy: 0.6763\n",
            "Epoch 19/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.9427 - accuracy: 0.6821 - val_loss: 1.0356 - val_accuracy: 0.6702\n",
            "Epoch 20/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.9096 - accuracy: 0.7062 - val_loss: 0.9930 - val_accuracy: 0.6901\n",
            "Epoch 21/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.9148 - accuracy: 0.6772 - val_loss: 0.9728 - val_accuracy: 0.6809\n",
            "Epoch 22/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.9281 - accuracy: 0.6874 - val_loss: 0.9871 - val_accuracy: 0.6885\n",
            "Epoch 23/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.8710 - accuracy: 0.7001 - val_loss: 0.9397 - val_accuracy: 0.7038\n",
            "Epoch 24/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.8600 - accuracy: 0.7097 - val_loss: 0.9210 - val_accuracy: 0.7099\n",
            "Epoch 25/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.8248 - accuracy: 0.7133 - val_loss: 0.9351 - val_accuracy: 0.7099\n",
            "Epoch 26/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.8178 - accuracy: 0.7185 - val_loss: 0.9050 - val_accuracy: 0.7313\n",
            "Epoch 27/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.8169 - accuracy: 0.7300 - val_loss: 0.8866 - val_accuracy: 0.7130\n",
            "Epoch 28/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.7828 - accuracy: 0.7316 - val_loss: 0.8650 - val_accuracy: 0.7344\n",
            "Epoch 29/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.8034 - accuracy: 0.7295 - val_loss: 0.9185 - val_accuracy: 0.7038\n",
            "Epoch 30/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.7625 - accuracy: 0.7383 - val_loss: 0.8837 - val_accuracy: 0.7282\n",
            "Epoch 31/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.7725 - accuracy: 0.7211 - val_loss: 0.8761 - val_accuracy: 0.7359\n",
            "Epoch 32/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.7304 - accuracy: 0.7532 - val_loss: 0.8915 - val_accuracy: 0.7191\n",
            "Epoch 33/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.8270 - accuracy: 0.7061 - val_loss: 0.8685 - val_accuracy: 0.7420\n",
            "Epoch 34/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.6882 - accuracy: 0.7647 - val_loss: 0.8986 - val_accuracy: 0.7435\n",
            "Epoch 35/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.7408 - accuracy: 0.7459 - val_loss: 0.8667 - val_accuracy: 0.7389\n",
            "Epoch 36/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.7258 - accuracy: 0.7542 - val_loss: 0.8255 - val_accuracy: 0.7588\n",
            "Epoch 37/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.6816 - accuracy: 0.7809 - val_loss: 0.8659 - val_accuracy: 0.7527\n",
            "Epoch 38/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.7304 - accuracy: 0.7499 - val_loss: 0.8292 - val_accuracy: 0.7496\n",
            "Epoch 39/300\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6292 - accuracy: 0.7863 - val_loss: 0.8086 - val_accuracy: 0.7542\n",
            "Epoch 40/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.6614 - accuracy: 0.7734 - val_loss: 0.8046 - val_accuracy: 0.7573\n",
            "Epoch 41/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5906 - accuracy: 0.7932 - val_loss: 0.7977 - val_accuracy: 0.7588\n",
            "Epoch 42/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.6623 - accuracy: 0.7817 - val_loss: 0.8152 - val_accuracy: 0.7634\n",
            "Epoch 43/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.6443 - accuracy: 0.7728 - val_loss: 0.7947 - val_accuracy: 0.7664\n",
            "Epoch 44/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5896 - accuracy: 0.7881 - val_loss: 0.8231 - val_accuracy: 0.7511\n",
            "Epoch 45/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.6326 - accuracy: 0.7696 - val_loss: 0.8240 - val_accuracy: 0.7527\n",
            "Epoch 46/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.6585 - accuracy: 0.7696 - val_loss: 0.7458 - val_accuracy: 0.7847\n",
            "Epoch 47/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.6171 - accuracy: 0.7890 - val_loss: 0.7665 - val_accuracy: 0.7863\n",
            "Epoch 48/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5769 - accuracy: 0.8066 - val_loss: 0.8028 - val_accuracy: 0.7756\n",
            "Epoch 49/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5979 - accuracy: 0.7941 - val_loss: 0.7687 - val_accuracy: 0.7817\n",
            "Epoch 50/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5864 - accuracy: 0.7917 - val_loss: 0.8087 - val_accuracy: 0.7603\n",
            "Epoch 51/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.6064 - accuracy: 0.7965 - val_loss: 0.7508 - val_accuracy: 0.7695\n",
            "Epoch 52/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5539 - accuracy: 0.8003 - val_loss: 0.7803 - val_accuracy: 0.7618\n",
            "Epoch 53/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5593 - accuracy: 0.8156 - val_loss: 0.7577 - val_accuracy: 0.7603\n",
            "Epoch 54/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5776 - accuracy: 0.7977 - val_loss: 0.7265 - val_accuracy: 0.7863\n",
            "Epoch 55/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4773 - accuracy: 0.8341 - val_loss: 0.7782 - val_accuracy: 0.7786\n",
            "Epoch 56/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4547 - accuracy: 0.8402 - val_loss: 0.7854 - val_accuracy: 0.7863\n",
            "Epoch 57/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5203 - accuracy: 0.8303 - val_loss: 0.7384 - val_accuracy: 0.7817\n",
            "Epoch 58/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5295 - accuracy: 0.8345 - val_loss: 0.7654 - val_accuracy: 0.7847\n",
            "Epoch 59/300\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5433 - accuracy: 0.8098 - val_loss: 0.8070 - val_accuracy: 0.7618\n",
            "Epoch 60/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5440 - accuracy: 0.8183 - val_loss: 0.7513 - val_accuracy: 0.7893\n",
            "Epoch 61/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5040 - accuracy: 0.8245 - val_loss: 0.7757 - val_accuracy: 0.7863\n",
            "Epoch 62/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5194 - accuracy: 0.8284 - val_loss: 0.7670 - val_accuracy: 0.7756\n",
            "Epoch 63/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5589 - accuracy: 0.8103 - val_loss: 0.8470 - val_accuracy: 0.7664\n",
            "Epoch 64/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4759 - accuracy: 0.8318 - val_loss: 0.7974 - val_accuracy: 0.7847\n",
            "Epoch 65/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4902 - accuracy: 0.8232 - val_loss: 0.8134 - val_accuracy: 0.7832\n",
            "Epoch 66/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5173 - accuracy: 0.8286 - val_loss: 0.8241 - val_accuracy: 0.7939\n",
            "Epoch 67/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5165 - accuracy: 0.8201 - val_loss: 0.7796 - val_accuracy: 0.7908\n",
            "Epoch 68/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4980 - accuracy: 0.8304 - val_loss: 0.8023 - val_accuracy: 0.7756\n",
            "Epoch 69/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4581 - accuracy: 0.8444 - val_loss: 0.7513 - val_accuracy: 0.7969\n",
            "Epoch 70/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4757 - accuracy: 0.8441 - val_loss: 0.8340 - val_accuracy: 0.7786\n",
            "Epoch 71/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4859 - accuracy: 0.8313 - val_loss: 0.8177 - val_accuracy: 0.7710\n",
            "Epoch 72/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4481 - accuracy: 0.8442 - val_loss: 0.7617 - val_accuracy: 0.7939\n",
            "Epoch 73/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4437 - accuracy: 0.8418 - val_loss: 0.7837 - val_accuracy: 0.7878\n",
            "Epoch 74/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4519 - accuracy: 0.8399 - val_loss: 0.7508 - val_accuracy: 0.8122\n",
            "Epoch 75/300\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4290 - accuracy: 0.8535 - val_loss: 0.7803 - val_accuracy: 0.7893\n",
            "Epoch 76/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4562 - accuracy: 0.8603 - val_loss: 0.7468 - val_accuracy: 0.8076\n",
            "Epoch 77/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4508 - accuracy: 0.8497 - val_loss: 0.7193 - val_accuracy: 0.8107\n",
            "Epoch 78/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4705 - accuracy: 0.8447 - val_loss: 0.8157 - val_accuracy: 0.7802\n",
            "Epoch 79/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5188 - accuracy: 0.8269 - val_loss: 0.7680 - val_accuracy: 0.7893\n",
            "Epoch 80/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4175 - accuracy: 0.8695 - val_loss: 0.7676 - val_accuracy: 0.8061\n",
            "Epoch 81/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4620 - accuracy: 0.8529 - val_loss: 0.7222 - val_accuracy: 0.7954\n",
            "Epoch 82/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4628 - accuracy: 0.8430 - val_loss: 0.7175 - val_accuracy: 0.7985\n",
            "Epoch 83/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4235 - accuracy: 0.8487 - val_loss: 0.7553 - val_accuracy: 0.7939\n",
            "Epoch 84/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.3831 - accuracy: 0.8731 - val_loss: 0.7537 - val_accuracy: 0.8076\n",
            "Epoch 85/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4422 - accuracy: 0.8491 - val_loss: 0.7519 - val_accuracy: 0.8015\n",
            "Epoch 86/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5032 - accuracy: 0.8362 - val_loss: 0.7429 - val_accuracy: 0.8198\n",
            "Epoch 87/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4472 - accuracy: 0.8481 - val_loss: 0.7430 - val_accuracy: 0.8153\n",
            "Epoch 88/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.3807 - accuracy: 0.8762 - val_loss: 0.7573 - val_accuracy: 0.8092\n",
            "Epoch 89/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4348 - accuracy: 0.8497 - val_loss: 0.7245 - val_accuracy: 0.7939\n",
            "Epoch 90/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.3626 - accuracy: 0.8807 - val_loss: 0.7031 - val_accuracy: 0.8122\n",
            "Epoch 91/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.3317 - accuracy: 0.8836 - val_loss: 0.7373 - val_accuracy: 0.8137\n",
            "Epoch 92/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4019 - accuracy: 0.8588 - val_loss: 0.7491 - val_accuracy: 0.8031\n",
            "Epoch 93/300\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4430 - accuracy: 0.8548 - val_loss: 0.7156 - val_accuracy: 0.8229\n",
            "Epoch 94/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4348 - accuracy: 0.8607 - val_loss: 0.7792 - val_accuracy: 0.8076\n",
            "Epoch 95/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4017 - accuracy: 0.8599 - val_loss: 0.7611 - val_accuracy: 0.8137\n",
            "Epoch 96/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.3668 - accuracy: 0.8736 - val_loss: 0.7651 - val_accuracy: 0.8031\n",
            "Epoch 97/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.3535 - accuracy: 0.8768 - val_loss: 0.7727 - val_accuracy: 0.8046\n",
            "Epoch 98/300\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3489 - accuracy: 0.8869 - val_loss: 0.7844 - val_accuracy: 0.8122\n",
            "Epoch 99/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4068 - accuracy: 0.8694 - val_loss: 0.7722 - val_accuracy: 0.8046\n",
            "Epoch 100/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4220 - accuracy: 0.8605 - val_loss: 0.7361 - val_accuracy: 0.8260\n",
            "Epoch 101/300\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3506 - accuracy: 0.8948 - val_loss: 0.7583 - val_accuracy: 0.8031\n",
            "Epoch 102/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4062 - accuracy: 0.8615 - val_loss: 0.7335 - val_accuracy: 0.8031\n",
            "Epoch 103/300\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3941 - accuracy: 0.8674 - val_loss: 0.7333 - val_accuracy: 0.8061\n",
            "Epoch 104/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.3753 - accuracy: 0.8768 - val_loss: 0.7501 - val_accuracy: 0.8107\n",
            "Epoch 105/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4037 - accuracy: 0.8555 - val_loss: 0.7571 - val_accuracy: 0.8122\n",
            "Epoch 106/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.3634 - accuracy: 0.8665 - val_loss: 0.7540 - val_accuracy: 0.8183\n",
            "Epoch 107/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.3447 - accuracy: 0.8842 - val_loss: 0.7202 - val_accuracy: 0.8229\n",
            "Epoch 108/300\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3419 - accuracy: 0.8931 - val_loss: 0.7776 - val_accuracy: 0.8153\n",
            "Epoch 109/300\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3954 - accuracy: 0.8689 - val_loss: 0.7440 - val_accuracy: 0.8198\n",
            "Epoch 110/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.3078 - accuracy: 0.9017 - val_loss: 0.7224 - val_accuracy: 0.8168\n",
            "Epoch 111/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.3407 - accuracy: 0.8821 - val_loss: 0.7651 - val_accuracy: 0.8137\n",
            "Epoch 112/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.3810 - accuracy: 0.8740 - val_loss: 0.7433 - val_accuracy: 0.8183\n",
            "Epoch 113/300\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3796 - accuracy: 0.8725 - val_loss: 0.7814 - val_accuracy: 0.8168\n",
            "Epoch 114/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.3476 - accuracy: 0.8773 - val_loss: 0.7579 - val_accuracy: 0.8198\n",
            "Epoch 115/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.3438 - accuracy: 0.8906 - val_loss: 0.7671 - val_accuracy: 0.8122\n",
            "Epoch 116/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.3718 - accuracy: 0.8753 - val_loss: 0.7954 - val_accuracy: 0.8107\n",
            "Epoch 117/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4073 - accuracy: 0.8556 - val_loss: 0.7432 - val_accuracy: 0.8229\n",
            "Epoch 118/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.3270 - accuracy: 0.8907 - val_loss: 0.7781 - val_accuracy: 0.8092\n",
            "Epoch 119/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.3188 - accuracy: 0.8971 - val_loss: 0.7751 - val_accuracy: 0.8183\n",
            "Epoch 120/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.3433 - accuracy: 0.8820 - val_loss: 0.7849 - val_accuracy: 0.8244\n",
            "Epoch 121/300\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3385 - accuracy: 0.8882 - val_loss: 0.7493 - val_accuracy: 0.8137\n",
            "Epoch 122/300\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.2999 - accuracy: 0.8925 - val_loss: 0.7990 - val_accuracy: 0.8122\n",
            "Epoch 123/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.2975 - accuracy: 0.8983 - val_loss: 0.7632 - val_accuracy: 0.8015\n",
            "Epoch 124/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.3155 - accuracy: 0.8903 - val_loss: 0.8085 - val_accuracy: 0.8137\n",
            "Epoch 125/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.2947 - accuracy: 0.9027 - val_loss: 0.7849 - val_accuracy: 0.8137\n",
            "Epoch 126/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.3044 - accuracy: 0.8885 - val_loss: 0.7666 - val_accuracy: 0.8336\n",
            "Epoch 127/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.3431 - accuracy: 0.8852 - val_loss: 0.7919 - val_accuracy: 0.8198\n",
            "Epoch 128/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.3045 - accuracy: 0.8897 - val_loss: 0.7925 - val_accuracy: 0.8107\n",
            "Epoch 129/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.3731 - accuracy: 0.8825 - val_loss: 0.7274 - val_accuracy: 0.8336\n",
            "Epoch 130/300\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.3361 - accuracy: 0.8813 - val_loss: 0.7379 - val_accuracy: 0.8168\n",
            "1\n",
            "model 0\n",
            "Epoch 1/300\n",
            "8/8 [==============================] - 4s 264ms/step - loss: 2.2656 - accuracy: 0.1408 - val_loss: 2.1253 - val_accuracy: 0.1927\n",
            "Epoch 2/300\n",
            "8/8 [==============================] - 2s 201ms/step - loss: 2.1361 - accuracy: 0.2198 - val_loss: 2.0389 - val_accuracy: 0.2409\n",
            "Epoch 3/300\n",
            "8/8 [==============================] - 2s 198ms/step - loss: 2.0248 - accuracy: 0.2472 - val_loss: 1.9212 - val_accuracy: 0.2797\n",
            "Epoch 4/300\n",
            "8/8 [==============================] - 2s 199ms/step - loss: 1.8975 - accuracy: 0.2903 - val_loss: 1.9135 - val_accuracy: 0.2844\n",
            "Epoch 5/300\n",
            "8/8 [==============================] - 2s 195ms/step - loss: 1.8726 - accuracy: 0.3072 - val_loss: 1.8644 - val_accuracy: 0.2937\n",
            "Epoch 6/300\n",
            "8/8 [==============================] - 2s 198ms/step - loss: 1.7913 - accuracy: 0.3377 - val_loss: 1.7564 - val_accuracy: 0.3458\n",
            "Epoch 7/300\n",
            "8/8 [==============================] - 2s 199ms/step - loss: 1.7381 - accuracy: 0.3589 - val_loss: 1.7022 - val_accuracy: 0.3924\n",
            "Epoch 8/300\n",
            "8/8 [==============================] - 2s 201ms/step - loss: 1.6456 - accuracy: 0.4021 - val_loss: 1.6026 - val_accuracy: 0.4289\n",
            "Epoch 9/300\n",
            "8/8 [==============================] - 2s 202ms/step - loss: 1.5601 - accuracy: 0.4538 - val_loss: 1.5298 - val_accuracy: 0.4825\n",
            "Epoch 10/300\n",
            "8/8 [==============================] - 2s 199ms/step - loss: 1.4179 - accuracy: 0.5029 - val_loss: 1.3663 - val_accuracy: 0.5245\n",
            "Epoch 11/300\n",
            "8/8 [==============================] - 2s 200ms/step - loss: 1.3191 - accuracy: 0.5489 - val_loss: 1.2924 - val_accuracy: 0.5804\n",
            "Epoch 12/300\n",
            "8/8 [==============================] - 2s 198ms/step - loss: 1.2394 - accuracy: 0.5911 - val_loss: 1.2758 - val_accuracy: 0.5672\n",
            "Epoch 13/300\n",
            "8/8 [==============================] - 2s 200ms/step - loss: 1.1475 - accuracy: 0.6153 - val_loss: 1.1576 - val_accuracy: 0.6185\n",
            "Epoch 14/300\n",
            "8/8 [==============================] - 2s 200ms/step - loss: 1.0488 - accuracy: 0.6487 - val_loss: 1.0895 - val_accuracy: 0.6418\n",
            "Epoch 15/300\n",
            "8/8 [==============================] - 2s 199ms/step - loss: 0.9726 - accuracy: 0.6732 - val_loss: 1.0241 - val_accuracy: 0.6636\n",
            "Epoch 16/300\n",
            "8/8 [==============================] - 2s 194ms/step - loss: 0.9328 - accuracy: 0.7006 - val_loss: 0.9650 - val_accuracy: 0.6915\n",
            "Epoch 17/300\n",
            "8/8 [==============================] - 2s 196ms/step - loss: 0.8434 - accuracy: 0.7347 - val_loss: 0.9100 - val_accuracy: 0.7141\n",
            "Epoch 18/300\n",
            "8/8 [==============================] - 2s 197ms/step - loss: 0.7933 - accuracy: 0.7492 - val_loss: 0.9090 - val_accuracy: 0.7055\n",
            "Epoch 19/300\n",
            "8/8 [==============================] - 2s 193ms/step - loss: 0.7305 - accuracy: 0.7647 - val_loss: 0.8937 - val_accuracy: 0.7164\n",
            "Epoch 20/300\n",
            "8/8 [==============================] - 2s 196ms/step - loss: 0.6821 - accuracy: 0.7837 - val_loss: 0.8635 - val_accuracy: 0.7242\n",
            "Epoch 21/300\n",
            "8/8 [==============================] - 2s 198ms/step - loss: 0.6541 - accuracy: 0.7908 - val_loss: 0.8229 - val_accuracy: 0.7413\n",
            "Epoch 22/300\n",
            "8/8 [==============================] - 2s 203ms/step - loss: 0.5670 - accuracy: 0.8210 - val_loss: 0.7296 - val_accuracy: 0.7661\n",
            "Epoch 23/300\n",
            "8/8 [==============================] - 2s 200ms/step - loss: 0.5025 - accuracy: 0.8362 - val_loss: 0.7548 - val_accuracy: 0.7607\n",
            "Epoch 24/300\n",
            "8/8 [==============================] - 2s 200ms/step - loss: 0.4576 - accuracy: 0.8589 - val_loss: 0.7889 - val_accuracy: 0.7630\n",
            "Epoch 25/300\n",
            "8/8 [==============================] - 2s 198ms/step - loss: 0.4591 - accuracy: 0.8549 - val_loss: 0.7766 - val_accuracy: 0.7708\n",
            "Epoch 26/300\n",
            "8/8 [==============================] - 2s 200ms/step - loss: 0.4570 - accuracy: 0.8574 - val_loss: 0.7964 - val_accuracy: 0.7685\n",
            "Epoch 27/300\n",
            "8/8 [==============================] - 2s 199ms/step - loss: 0.4316 - accuracy: 0.8640 - val_loss: 0.8129 - val_accuracy: 0.7739\n",
            "Epoch 28/300\n",
            "8/8 [==============================] - 2s 198ms/step - loss: 0.3634 - accuracy: 0.8808 - val_loss: 0.7139 - val_accuracy: 0.7902\n",
            "Epoch 29/300\n",
            "8/8 [==============================] - 2s 202ms/step - loss: 0.3152 - accuracy: 0.9079 - val_loss: 0.7829 - val_accuracy: 0.7786\n",
            "Epoch 30/300\n",
            "8/8 [==============================] - 2s 200ms/step - loss: 0.3100 - accuracy: 0.9018 - val_loss: 0.7433 - val_accuracy: 0.7770\n",
            "Epoch 31/300\n",
            "8/8 [==============================] - 2s 195ms/step - loss: 0.2986 - accuracy: 0.9105 - val_loss: 0.8430 - val_accuracy: 0.7731\n",
            "Epoch 32/300\n",
            "8/8 [==============================] - 2s 197ms/step - loss: 0.3023 - accuracy: 0.9067 - val_loss: 0.8248 - val_accuracy: 0.7762\n",
            "Epoch 33/300\n",
            "8/8 [==============================] - 2s 199ms/step - loss: 0.2700 - accuracy: 0.9158 - val_loss: 0.7427 - val_accuracy: 0.7949\n",
            "Epoch 34/300\n",
            "8/8 [==============================] - 2s 196ms/step - loss: 0.2478 - accuracy: 0.9167 - val_loss: 0.8038 - val_accuracy: 0.7887\n",
            "Epoch 35/300\n",
            "8/8 [==============================] - 2s 206ms/step - loss: 0.2461 - accuracy: 0.9198 - val_loss: 0.7955 - val_accuracy: 0.7933\n",
            "Epoch 36/300\n",
            "8/8 [==============================] - 2s 198ms/step - loss: 0.2635 - accuracy: 0.9137 - val_loss: 0.7806 - val_accuracy: 0.7941\n",
            "Epoch 37/300\n",
            "8/8 [==============================] - 2s 199ms/step - loss: 0.2443 - accuracy: 0.9225 - val_loss: 0.8318 - val_accuracy: 0.7832\n",
            "Epoch 38/300\n",
            "8/8 [==============================] - 2s 196ms/step - loss: 0.2004 - accuracy: 0.9337 - val_loss: 0.8250 - val_accuracy: 0.7925\n",
            "Epoch 39/300\n",
            "8/8 [==============================] - 2s 196ms/step - loss: 0.1757 - accuracy: 0.9457 - val_loss: 0.7749 - val_accuracy: 0.7995\n",
            "Epoch 40/300\n",
            "8/8 [==============================] - 2s 194ms/step - loss: 0.1707 - accuracy: 0.9504 - val_loss: 0.8267 - val_accuracy: 0.7941\n",
            "Epoch 41/300\n",
            "8/8 [==============================] - 2s 197ms/step - loss: 0.1556 - accuracy: 0.9511 - val_loss: 0.8397 - val_accuracy: 0.7972\n",
            "Epoch 42/300\n",
            "8/8 [==============================] - 2s 199ms/step - loss: 0.1406 - accuracy: 0.9601 - val_loss: 0.8624 - val_accuracy: 0.7832\n",
            "Epoch 43/300\n",
            "8/8 [==============================] - 2s 196ms/step - loss: 0.1555 - accuracy: 0.9534 - val_loss: 0.9545 - val_accuracy: 0.7863\n",
            "Epoch 44/300\n",
            "8/8 [==============================] - 2s 197ms/step - loss: 0.1396 - accuracy: 0.9579 - val_loss: 0.9285 - val_accuracy: 0.7871\n",
            "Epoch 45/300\n",
            "8/8 [==============================] - 2s 199ms/step - loss: 0.1266 - accuracy: 0.9638 - val_loss: 0.8570 - val_accuracy: 0.7949\n",
            "Epoch 46/300\n",
            "8/8 [==============================] - 2s 201ms/step - loss: 0.1157 - accuracy: 0.9669 - val_loss: 0.8598 - val_accuracy: 0.8003\n",
            "Epoch 47/300\n",
            "8/8 [==============================] - 2s 203ms/step - loss: 0.0950 - accuracy: 0.9745 - val_loss: 0.8939 - val_accuracy: 0.7988\n",
            "Epoch 48/300\n",
            "8/8 [==============================] - 2s 199ms/step - loss: 0.0962 - accuracy: 0.9720 - val_loss: 0.9357 - val_accuracy: 0.7918\n",
            "Epoch 49/300\n",
            "8/8 [==============================] - 2s 199ms/step - loss: 0.0752 - accuracy: 0.9811 - val_loss: 0.9379 - val_accuracy: 0.7949\n",
            "Epoch 50/300\n",
            "8/8 [==============================] - 2s 200ms/step - loss: 0.0739 - accuracy: 0.9841 - val_loss: 0.9229 - val_accuracy: 0.8003\n",
            "Epoch 51/300\n",
            "8/8 [==============================] - 2s 199ms/step - loss: 0.0685 - accuracy: 0.9824 - val_loss: 0.9460 - val_accuracy: 0.7988\n",
            "Epoch 52/300\n",
            "8/8 [==============================] - 2s 201ms/step - loss: 0.0616 - accuracy: 0.9864 - val_loss: 0.9742 - val_accuracy: 0.8050\n",
            "Epoch 53/300\n",
            "8/8 [==============================] - 2s 199ms/step - loss: 0.0551 - accuracy: 0.9855 - val_loss: 0.9670 - val_accuracy: 0.8042\n",
            "Epoch 54/300\n",
            "8/8 [==============================] - 2s 197ms/step - loss: 0.0474 - accuracy: 0.9898 - val_loss: 1.0247 - val_accuracy: 0.7902\n",
            "Epoch 55/300\n",
            "8/8 [==============================] - 2s 198ms/step - loss: 0.0528 - accuracy: 0.9878 - val_loss: 1.0113 - val_accuracy: 0.7988\n",
            "Epoch 56/300\n",
            "8/8 [==============================] - 2s 197ms/step - loss: 0.0556 - accuracy: 0.9883 - val_loss: 1.0767 - val_accuracy: 0.7980\n",
            "Epoch 57/300\n",
            "8/8 [==============================] - 2s 199ms/step - loss: 0.0636 - accuracy: 0.9834 - val_loss: 1.1023 - val_accuracy: 0.7902\n",
            "Epoch 58/300\n",
            "8/8 [==============================] - 2s 200ms/step - loss: 0.0531 - accuracy: 0.9883 - val_loss: 1.1141 - val_accuracy: 0.7910\n",
            "Epoch 59/300\n",
            "8/8 [==============================] - 2s 200ms/step - loss: 0.0432 - accuracy: 0.9892 - val_loss: 1.0935 - val_accuracy: 0.7941\n",
            "Epoch 60/300\n",
            "8/8 [==============================] - 2s 199ms/step - loss: 0.0457 - accuracy: 0.9880 - val_loss: 1.0738 - val_accuracy: 0.7980\n",
            "Epoch 61/300\n",
            "8/8 [==============================] - 2s 202ms/step - loss: 0.0337 - accuracy: 0.9944 - val_loss: 1.0878 - val_accuracy: 0.7956\n",
            "Epoch 62/300\n",
            "8/8 [==============================] - 2s 202ms/step - loss: 0.0350 - accuracy: 0.9931 - val_loss: 1.0935 - val_accuracy: 0.8065\n",
            "Epoch 63/300\n",
            "8/8 [==============================] - 2s 197ms/step - loss: 0.0304 - accuracy: 0.9947 - val_loss: 1.0803 - val_accuracy: 0.8057\n",
            "Epoch 64/300\n",
            "8/8 [==============================] - 2s 195ms/step - loss: 0.0265 - accuracy: 0.9947 - val_loss: 1.1072 - val_accuracy: 0.8011\n",
            "Epoch 65/300\n",
            "8/8 [==============================] - 2s 201ms/step - loss: 0.0233 - accuracy: 0.9969 - val_loss: 1.1244 - val_accuracy: 0.7988\n",
            "Epoch 66/300\n",
            "8/8 [==============================] - 2s 203ms/step - loss: 0.0208 - accuracy: 0.9967 - val_loss: 1.1526 - val_accuracy: 0.8003\n",
            "Epoch 67/300\n",
            "8/8 [==============================] - 2s 198ms/step - loss: 0.0221 - accuracy: 0.9956 - val_loss: 1.1694 - val_accuracy: 0.7972\n",
            "Epoch 68/300\n",
            "8/8 [==============================] - 2s 200ms/step - loss: 0.0212 - accuracy: 0.9960 - val_loss: 1.1927 - val_accuracy: 0.7956\n",
            "model 1\n",
            "Epoch 1/300\n",
            "8/8 [==============================] - 4s 378ms/step - loss: 2.2608 - accuracy: 0.1407 - val_loss: 1.9433 - val_accuracy: 0.3217\n",
            "Epoch 2/300\n",
            "8/8 [==============================] - 3s 320ms/step - loss: 1.9522 - accuracy: 0.3215 - val_loss: 1.6230 - val_accuracy: 0.4903\n",
            "Epoch 3/300\n",
            "8/8 [==============================] - 2s 313ms/step - loss: 1.6487 - accuracy: 0.4449 - val_loss: 1.4176 - val_accuracy: 0.5354\n",
            "Epoch 4/300\n",
            "8/8 [==============================] - 3s 318ms/step - loss: 1.4828 - accuracy: 0.4937 - val_loss: 1.2903 - val_accuracy: 0.6053\n",
            "Epoch 5/300\n",
            "8/8 [==============================] - 3s 318ms/step - loss: 1.3695 - accuracy: 0.5576 - val_loss: 1.1320 - val_accuracy: 0.6682\n",
            "Epoch 6/300\n",
            "8/8 [==============================] - 3s 322ms/step - loss: 1.2433 - accuracy: 0.5850 - val_loss: 1.0435 - val_accuracy: 0.6830\n",
            "Epoch 7/300\n",
            "8/8 [==============================] - 3s 319ms/step - loss: 1.1878 - accuracy: 0.6132 - val_loss: 0.9982 - val_accuracy: 0.6954\n",
            "Epoch 8/300\n",
            "8/8 [==============================] - 3s 322ms/step - loss: 1.0948 - accuracy: 0.6543 - val_loss: 0.9476 - val_accuracy: 0.7086\n",
            "Epoch 9/300\n",
            "8/8 [==============================] - 3s 320ms/step - loss: 1.0950 - accuracy: 0.6493 - val_loss: 0.8857 - val_accuracy: 0.7319\n",
            "Epoch 10/300\n",
            "8/8 [==============================] - 3s 334ms/step - loss: 1.0225 - accuracy: 0.6676 - val_loss: 0.8567 - val_accuracy: 0.7413\n",
            "Epoch 11/300\n",
            "8/8 [==============================] - 3s 361ms/step - loss: 0.9951 - accuracy: 0.6709 - val_loss: 0.8079 - val_accuracy: 0.7405\n",
            "Epoch 12/300\n",
            "8/8 [==============================] - 3s 318ms/step - loss: 0.9233 - accuracy: 0.7008 - val_loss: 0.7733 - val_accuracy: 0.7576\n",
            "Epoch 13/300\n",
            "8/8 [==============================] - 3s 348ms/step - loss: 0.8832 - accuracy: 0.7142 - val_loss: 0.7489 - val_accuracy: 0.7754\n",
            "Epoch 14/300\n",
            "8/8 [==============================] - 3s 334ms/step - loss: 0.8259 - accuracy: 0.7378 - val_loss: 0.7361 - val_accuracy: 0.7770\n",
            "Epoch 15/300\n",
            "8/8 [==============================] - 3s 323ms/step - loss: 0.7818 - accuracy: 0.7471 - val_loss: 0.7149 - val_accuracy: 0.7801\n",
            "Epoch 16/300\n",
            "8/8 [==============================] - 3s 321ms/step - loss: 0.7612 - accuracy: 0.7579 - val_loss: 0.6721 - val_accuracy: 0.8073\n",
            "Epoch 17/300\n",
            "8/8 [==============================] - 3s 330ms/step - loss: 0.7127 - accuracy: 0.7624 - val_loss: 0.6352 - val_accuracy: 0.8127\n",
            "Epoch 18/300\n",
            "8/8 [==============================] - 3s 356ms/step - loss: 0.6661 - accuracy: 0.7907 - val_loss: 0.6241 - val_accuracy: 0.8174\n",
            "Epoch 19/300\n",
            "8/8 [==============================] - 3s 357ms/step - loss: 0.6630 - accuracy: 0.7842 - val_loss: 0.6374 - val_accuracy: 0.8065\n",
            "Epoch 20/300\n",
            "8/8 [==============================] - 3s 351ms/step - loss: 0.6566 - accuracy: 0.7920 - val_loss: 0.6278 - val_accuracy: 0.8143\n",
            "Epoch 21/300\n",
            "8/8 [==============================] - 3s 342ms/step - loss: 0.6194 - accuracy: 0.7984 - val_loss: 0.5802 - val_accuracy: 0.8283\n",
            "Epoch 22/300\n",
            "8/8 [==============================] - 3s 325ms/step - loss: 0.5845 - accuracy: 0.8099 - val_loss: 0.5778 - val_accuracy: 0.8267\n",
            "Epoch 23/300\n",
            "8/8 [==============================] - 3s 359ms/step - loss: 0.5804 - accuracy: 0.8131 - val_loss: 0.5638 - val_accuracy: 0.8322\n",
            "Epoch 24/300\n",
            "8/8 [==============================] - 3s 342ms/step - loss: 0.5082 - accuracy: 0.8393 - val_loss: 0.5400 - val_accuracy: 0.8462\n",
            "Epoch 25/300\n",
            "8/8 [==============================] - 3s 381ms/step - loss: 0.5051 - accuracy: 0.8375 - val_loss: 0.5505 - val_accuracy: 0.8392\n",
            "Epoch 26/300\n",
            "8/8 [==============================] - 3s 361ms/step - loss: 0.5193 - accuracy: 0.8297 - val_loss: 0.5522 - val_accuracy: 0.8384\n",
            "Epoch 27/300\n",
            "8/8 [==============================] - 3s 347ms/step - loss: 0.4898 - accuracy: 0.8422 - val_loss: 0.5442 - val_accuracy: 0.8392\n",
            "Epoch 28/300\n",
            "8/8 [==============================] - 3s 341ms/step - loss: 0.4636 - accuracy: 0.8445 - val_loss: 0.5420 - val_accuracy: 0.8423\n",
            "Epoch 29/300\n",
            "8/8 [==============================] - 3s 358ms/step - loss: 0.4529 - accuracy: 0.8471 - val_loss: 0.5202 - val_accuracy: 0.8531\n",
            "Epoch 30/300\n",
            "8/8 [==============================] - 3s 332ms/step - loss: 0.4512 - accuracy: 0.8512 - val_loss: 0.5159 - val_accuracy: 0.8446\n",
            "Epoch 31/300\n",
            "8/8 [==============================] - 3s 340ms/step - loss: 0.4086 - accuracy: 0.8684 - val_loss: 0.4965 - val_accuracy: 0.8524\n",
            "Epoch 32/300\n",
            "8/8 [==============================] - 3s 325ms/step - loss: 0.4346 - accuracy: 0.8518 - val_loss: 0.5285 - val_accuracy: 0.8477\n",
            "Epoch 33/300\n",
            "8/8 [==============================] - 3s 344ms/step - loss: 0.4049 - accuracy: 0.8629 - val_loss: 0.5071 - val_accuracy: 0.8485\n",
            "Epoch 34/300\n",
            "8/8 [==============================] - 3s 322ms/step - loss: 0.4045 - accuracy: 0.8597 - val_loss: 0.5096 - val_accuracy: 0.8508\n",
            "Epoch 35/300\n",
            "8/8 [==============================] - 3s 357ms/step - loss: 0.3725 - accuracy: 0.8715 - val_loss: 0.5129 - val_accuracy: 0.8516\n",
            "Epoch 36/300\n",
            "8/8 [==============================] - 3s 325ms/step - loss: 0.3409 - accuracy: 0.8800 - val_loss: 0.5191 - val_accuracy: 0.8508\n",
            "Epoch 37/300\n",
            "8/8 [==============================] - 3s 323ms/step - loss: 0.3515 - accuracy: 0.8787 - val_loss: 0.5280 - val_accuracy: 0.8547\n",
            "Epoch 38/300\n",
            "8/8 [==============================] - 3s 322ms/step - loss: 0.3558 - accuracy: 0.8766 - val_loss: 0.5149 - val_accuracy: 0.8547\n",
            "Epoch 39/300\n",
            "8/8 [==============================] - 3s 327ms/step - loss: 0.3321 - accuracy: 0.8876 - val_loss: 0.5099 - val_accuracy: 0.8547\n",
            "Epoch 40/300\n",
            "8/8 [==============================] - 3s 330ms/step - loss: 0.3345 - accuracy: 0.8898 - val_loss: 0.5248 - val_accuracy: 0.8586\n",
            "Epoch 41/300\n",
            "8/8 [==============================] - 3s 330ms/step - loss: 0.3217 - accuracy: 0.8913 - val_loss: 0.5224 - val_accuracy: 0.8539\n",
            "Epoch 42/300\n",
            "8/8 [==============================] - 3s 327ms/step - loss: 0.3245 - accuracy: 0.8845 - val_loss: 0.4868 - val_accuracy: 0.8601\n",
            "Epoch 43/300\n",
            "8/8 [==============================] - 3s 320ms/step - loss: 0.3116 - accuracy: 0.8929 - val_loss: 0.5029 - val_accuracy: 0.8609\n",
            "Epoch 44/300\n",
            "8/8 [==============================] - 3s 327ms/step - loss: 0.2937 - accuracy: 0.8966 - val_loss: 0.5169 - val_accuracy: 0.8570\n",
            "Epoch 45/300\n",
            "8/8 [==============================] - 3s 326ms/step - loss: 0.3085 - accuracy: 0.9006 - val_loss: 0.5102 - val_accuracy: 0.8555\n",
            "Epoch 46/300\n",
            "8/8 [==============================] - 3s 341ms/step - loss: 0.3044 - accuracy: 0.8932 - val_loss: 0.5264 - val_accuracy: 0.8539\n",
            "Epoch 47/300\n",
            "8/8 [==============================] - 3s 325ms/step - loss: 0.2915 - accuracy: 0.9105 - val_loss: 0.5072 - val_accuracy: 0.8609\n",
            "Epoch 48/300\n",
            "8/8 [==============================] - 3s 323ms/step - loss: 0.2533 - accuracy: 0.9151 - val_loss: 0.4894 - val_accuracy: 0.8648\n",
            "Epoch 49/300\n",
            "8/8 [==============================] - 3s 320ms/step - loss: 0.2743 - accuracy: 0.9066 - val_loss: 0.4963 - val_accuracy: 0.8695\n",
            "Epoch 50/300\n",
            "8/8 [==============================] - 3s 324ms/step - loss: 0.2455 - accuracy: 0.9196 - val_loss: 0.5108 - val_accuracy: 0.8664\n",
            "Epoch 51/300\n",
            "8/8 [==============================] - 3s 330ms/step - loss: 0.2268 - accuracy: 0.9274 - val_loss: 0.5375 - val_accuracy: 0.8609\n",
            "Epoch 52/300\n",
            "8/8 [==============================] - 3s 332ms/step - loss: 0.2511 - accuracy: 0.9150 - val_loss: 0.4921 - val_accuracy: 0.8702\n",
            "Epoch 53/300\n",
            "8/8 [==============================] - 3s 323ms/step - loss: 0.2443 - accuracy: 0.9179 - val_loss: 0.5023 - val_accuracy: 0.8632\n",
            "Epoch 54/300\n",
            "8/8 [==============================] - 3s 331ms/step - loss: 0.2508 - accuracy: 0.9188 - val_loss: 0.5008 - val_accuracy: 0.8594\n",
            "Epoch 55/300\n",
            "8/8 [==============================] - 3s 338ms/step - loss: 0.2355 - accuracy: 0.9244 - val_loss: 0.5046 - val_accuracy: 0.8640\n",
            "Epoch 56/300\n",
            "8/8 [==============================] - 3s 324ms/step - loss: 0.2379 - accuracy: 0.9204 - val_loss: 0.5164 - val_accuracy: 0.8679\n",
            "Epoch 57/300\n",
            "8/8 [==============================] - 3s 329ms/step - loss: 0.2329 - accuracy: 0.9203 - val_loss: 0.5182 - val_accuracy: 0.8594\n",
            "Epoch 58/300\n",
            "8/8 [==============================] - 3s 325ms/step - loss: 0.2215 - accuracy: 0.9257 - val_loss: 0.5150 - val_accuracy: 0.8632\n",
            "Epoch 59/300\n",
            "8/8 [==============================] - 3s 329ms/step - loss: 0.2001 - accuracy: 0.9324 - val_loss: 0.5098 - val_accuracy: 0.8578\n",
            "Epoch 60/300\n",
            "8/8 [==============================] - 3s 349ms/step - loss: 0.2211 - accuracy: 0.9264 - val_loss: 0.5298 - val_accuracy: 0.8578\n",
            "Epoch 61/300\n",
            "8/8 [==============================] - 3s 332ms/step - loss: 0.2103 - accuracy: 0.9317 - val_loss: 0.5353 - val_accuracy: 0.8617\n",
            "Epoch 62/300\n",
            "8/8 [==============================] - 3s 321ms/step - loss: 0.1879 - accuracy: 0.9399 - val_loss: 0.5254 - val_accuracy: 0.8664\n",
            "Epoch 63/300\n",
            "8/8 [==============================] - 3s 337ms/step - loss: 0.1857 - accuracy: 0.9393 - val_loss: 0.5242 - val_accuracy: 0.8570\n",
            "Epoch 64/300\n",
            "8/8 [==============================] - 3s 327ms/step - loss: 0.1825 - accuracy: 0.9385 - val_loss: 0.5284 - val_accuracy: 0.8594\n",
            "Epoch 65/300\n",
            "8/8 [==============================] - 3s 327ms/step - loss: 0.1822 - accuracy: 0.9373 - val_loss: 0.5375 - val_accuracy: 0.8609\n",
            "Epoch 66/300\n",
            "8/8 [==============================] - 3s 330ms/step - loss: 0.1739 - accuracy: 0.9437 - val_loss: 0.5423 - val_accuracy: 0.8594\n",
            "Epoch 67/300\n",
            "8/8 [==============================] - 3s 329ms/step - loss: 0.1676 - accuracy: 0.9440 - val_loss: 0.5391 - val_accuracy: 0.8617\n",
            "Epoch 68/300\n",
            "8/8 [==============================] - 3s 350ms/step - loss: 0.1791 - accuracy: 0.9417 - val_loss: 0.5290 - val_accuracy: 0.8625\n",
            "Epoch 69/300\n",
            "8/8 [==============================] - 3s 349ms/step - loss: 0.1811 - accuracy: 0.9345 - val_loss: 0.5279 - val_accuracy: 0.8601\n",
            "Epoch 70/300\n",
            "8/8 [==============================] - 3s 405ms/step - loss: 0.1716 - accuracy: 0.9416 - val_loss: 0.5256 - val_accuracy: 0.8617\n",
            "Epoch 71/300\n",
            "8/8 [==============================] - 3s 336ms/step - loss: 0.1699 - accuracy: 0.9433 - val_loss: 0.5392 - val_accuracy: 0.8664\n",
            "Epoch 72/300\n",
            "8/8 [==============================] - 3s 323ms/step - loss: 0.1744 - accuracy: 0.9435 - val_loss: 0.5163 - val_accuracy: 0.8695\n",
            "Epoch 73/300\n",
            "8/8 [==============================] - 3s 340ms/step - loss: 0.1644 - accuracy: 0.9473 - val_loss: 0.5197 - val_accuracy: 0.8726\n",
            "Epoch 74/300\n",
            "8/8 [==============================] - 3s 341ms/step - loss: 0.1722 - accuracy: 0.9459 - val_loss: 0.5165 - val_accuracy: 0.8702\n",
            "Epoch 75/300\n",
            "8/8 [==============================] - 3s 327ms/step - loss: 0.1589 - accuracy: 0.9481 - val_loss: 0.5341 - val_accuracy: 0.8609\n",
            "Epoch 76/300\n",
            "8/8 [==============================] - 3s 346ms/step - loss: 0.1572 - accuracy: 0.9492 - val_loss: 0.5399 - val_accuracy: 0.8656\n",
            "Epoch 77/300\n",
            "8/8 [==============================] - 3s 381ms/step - loss: 0.1479 - accuracy: 0.9551 - val_loss: 0.5473 - val_accuracy: 0.8664\n",
            "Epoch 78/300\n",
            "8/8 [==============================] - 3s 378ms/step - loss: 0.1628 - accuracy: 0.9462 - val_loss: 0.5528 - val_accuracy: 0.8601\n",
            "Epoch 79/300\n",
            "8/8 [==============================] - 3s 331ms/step - loss: 0.1651 - accuracy: 0.9495 - val_loss: 0.5447 - val_accuracy: 0.8625\n",
            "Epoch 80/300\n",
            "8/8 [==============================] - 3s 338ms/step - loss: 0.1548 - accuracy: 0.9499 - val_loss: 0.5583 - val_accuracy: 0.8570\n",
            "Epoch 81/300\n",
            "8/8 [==============================] - 3s 409ms/step - loss: 0.1442 - accuracy: 0.9505 - val_loss: 0.5311 - val_accuracy: 0.8640\n",
            "Epoch 82/300\n",
            "8/8 [==============================] - 3s 396ms/step - loss: 0.1541 - accuracy: 0.9497 - val_loss: 0.5638 - val_accuracy: 0.8609\n",
            "model 2\n",
            "Epoch 1/300\n",
            "121/121 [==============================] - 2s 11ms/step - loss: 2.0836 - accuracy: 0.2336 - val_loss: 1.5451 - val_accuracy: 0.4709\n",
            "Epoch 2/300\n",
            "121/121 [==============================] - 1s 10ms/step - loss: 1.4241 - accuracy: 0.5218 - val_loss: 1.2129 - val_accuracy: 0.6107\n",
            "Epoch 3/300\n",
            "121/121 [==============================] - 1s 9ms/step - loss: 1.2475 - accuracy: 0.5989 - val_loss: 1.1230 - val_accuracy: 0.6472\n",
            "Epoch 4/300\n",
            "121/121 [==============================] - 1s 7ms/step - loss: 1.1105 - accuracy: 0.6483 - val_loss: 1.0051 - val_accuracy: 0.6799\n",
            "Epoch 5/300\n",
            "121/121 [==============================] - 1s 7ms/step - loss: 1.0262 - accuracy: 0.6753 - val_loss: 0.9898 - val_accuracy: 0.6783\n",
            "Epoch 6/300\n",
            "121/121 [==============================] - 1s 7ms/step - loss: 0.9691 - accuracy: 0.6799 - val_loss: 0.9015 - val_accuracy: 0.7312\n",
            "Epoch 7/300\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.9122 - accuracy: 0.7081 - val_loss: 0.8698 - val_accuracy: 0.7312\n",
            "Epoch 8/300\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.8766 - accuracy: 0.7226 - val_loss: 0.8606 - val_accuracy: 0.7389\n",
            "Epoch 9/300\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.8506 - accuracy: 0.7244 - val_loss: 0.8370 - val_accuracy: 0.7389\n",
            "Epoch 10/300\n",
            "121/121 [==============================] - 1s 11ms/step - loss: 0.7512 - accuracy: 0.7599 - val_loss: 0.8631 - val_accuracy: 0.7343\n",
            "Epoch 11/300\n",
            "121/121 [==============================] - 1s 9ms/step - loss: 0.7381 - accuracy: 0.7661 - val_loss: 0.7727 - val_accuracy: 0.7599\n",
            "Epoch 12/300\n",
            "121/121 [==============================] - 1s 9ms/step - loss: 0.7066 - accuracy: 0.7785 - val_loss: 0.7358 - val_accuracy: 0.7817\n",
            "Epoch 13/300\n",
            "121/121 [==============================] - 1s 10ms/step - loss: 0.6966 - accuracy: 0.7726 - val_loss: 0.7377 - val_accuracy: 0.7786\n",
            "Epoch 14/300\n",
            "121/121 [==============================] - 2s 13ms/step - loss: 0.6619 - accuracy: 0.7911 - val_loss: 0.7421 - val_accuracy: 0.7801\n",
            "Epoch 15/300\n",
            "121/121 [==============================] - 1s 12ms/step - loss: 0.6632 - accuracy: 0.7872 - val_loss: 0.7246 - val_accuracy: 0.7832\n",
            "Epoch 16/300\n",
            "121/121 [==============================] - 1s 11ms/step - loss: 0.6121 - accuracy: 0.8002 - val_loss: 0.7300 - val_accuracy: 0.7762\n",
            "Epoch 17/300\n",
            "121/121 [==============================] - 1s 9ms/step - loss: 0.6064 - accuracy: 0.8019 - val_loss: 0.7209 - val_accuracy: 0.7824\n",
            "Epoch 18/300\n",
            "121/121 [==============================] - 1s 9ms/step - loss: 0.6237 - accuracy: 0.7925 - val_loss: 0.6930 - val_accuracy: 0.7887\n",
            "Epoch 19/300\n",
            "121/121 [==============================] - 1s 10ms/step - loss: 0.5651 - accuracy: 0.8249 - val_loss: 0.7083 - val_accuracy: 0.7840\n",
            "Epoch 20/300\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.5869 - accuracy: 0.8097 - val_loss: 0.6915 - val_accuracy: 0.7933\n",
            "Epoch 21/300\n",
            "121/121 [==============================] - 2s 14ms/step - loss: 0.5585 - accuracy: 0.8208 - val_loss: 0.6906 - val_accuracy: 0.7910\n",
            "Epoch 22/300\n",
            "121/121 [==============================] - 1s 12ms/step - loss: 0.5430 - accuracy: 0.8262 - val_loss: 0.7131 - val_accuracy: 0.7902\n",
            "Epoch 23/300\n",
            "121/121 [==============================] - 1s 10ms/step - loss: 0.5429 - accuracy: 0.8275 - val_loss: 0.6810 - val_accuracy: 0.7902\n",
            "Epoch 24/300\n",
            "121/121 [==============================] - 2s 12ms/step - loss: 0.5375 - accuracy: 0.8262 - val_loss: 0.6673 - val_accuracy: 0.7995\n",
            "Epoch 25/300\n",
            "121/121 [==============================] - 1s 10ms/step - loss: 0.5371 - accuracy: 0.8222 - val_loss: 0.6887 - val_accuracy: 0.7972\n",
            "Epoch 26/300\n",
            "121/121 [==============================] - 1s 10ms/step - loss: 0.5320 - accuracy: 0.8192 - val_loss: 0.6937 - val_accuracy: 0.7988\n",
            "Epoch 27/300\n",
            "121/121 [==============================] - 1s 9ms/step - loss: 0.5227 - accuracy: 0.8299 - val_loss: 0.6603 - val_accuracy: 0.7995\n",
            "Epoch 28/300\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.4542 - accuracy: 0.8553 - val_loss: 0.7078 - val_accuracy: 0.7941\n",
            "Epoch 29/300\n",
            "121/121 [==============================] - 1s 9ms/step - loss: 0.4676 - accuracy: 0.8431 - val_loss: 0.6378 - val_accuracy: 0.8104\n",
            "Epoch 30/300\n",
            "121/121 [==============================] - 1s 11ms/step - loss: 0.4819 - accuracy: 0.8423 - val_loss: 0.6595 - val_accuracy: 0.8034\n",
            "Epoch 31/300\n",
            "121/121 [==============================] - 2s 20ms/step - loss: 0.4697 - accuracy: 0.8457 - val_loss: 0.6539 - val_accuracy: 0.8096\n",
            "Epoch 32/300\n",
            "121/121 [==============================] - 1s 12ms/step - loss: 0.4486 - accuracy: 0.8611 - val_loss: 0.6537 - val_accuracy: 0.8042\n",
            "Epoch 33/300\n",
            "121/121 [==============================] - 1s 7ms/step - loss: 0.4437 - accuracy: 0.8567 - val_loss: 0.6832 - val_accuracy: 0.8073\n",
            "Epoch 34/300\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.4577 - accuracy: 0.8454 - val_loss: 0.6733 - val_accuracy: 0.8042\n",
            "Epoch 35/300\n",
            "121/121 [==============================] - 1s 7ms/step - loss: 0.4447 - accuracy: 0.8509 - val_loss: 0.6953 - val_accuracy: 0.8003\n",
            "Epoch 36/300\n",
            "121/121 [==============================] - 1s 7ms/step - loss: 0.4479 - accuracy: 0.8449 - val_loss: 0.6721 - val_accuracy: 0.7980\n",
            "Epoch 37/300\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.4313 - accuracy: 0.8478 - val_loss: 0.6718 - val_accuracy: 0.8057\n",
            "Epoch 38/300\n",
            "121/121 [==============================] - 1s 10ms/step - loss: 0.4368 - accuracy: 0.8636 - val_loss: 0.6893 - val_accuracy: 0.7964\n",
            "Epoch 39/300\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.4183 - accuracy: 0.8601 - val_loss: 0.6922 - val_accuracy: 0.7980\n",
            "Epoch 40/300\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.4314 - accuracy: 0.8535 - val_loss: 0.6728 - val_accuracy: 0.8081\n",
            "Epoch 41/300\n",
            "121/121 [==============================] - 1s 10ms/step - loss: 0.4260 - accuracy: 0.8576 - val_loss: 0.6669 - val_accuracy: 0.8019\n",
            "Epoch 42/300\n",
            "121/121 [==============================] - 1s 9ms/step - loss: 0.4149 - accuracy: 0.8614 - val_loss: 0.6356 - val_accuracy: 0.8228\n",
            "Epoch 43/300\n",
            "121/121 [==============================] - 1s 9ms/step - loss: 0.4107 - accuracy: 0.8636 - val_loss: 0.6554 - val_accuracy: 0.8104\n",
            "Epoch 44/300\n",
            "121/121 [==============================] - 1s 11ms/step - loss: 0.4429 - accuracy: 0.8479 - val_loss: 0.6867 - val_accuracy: 0.8065\n",
            "Epoch 45/300\n",
            "121/121 [==============================] - 1s 11ms/step - loss: 0.3551 - accuracy: 0.8810 - val_loss: 0.6371 - val_accuracy: 0.8182\n",
            "Epoch 46/300\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.3957 - accuracy: 0.8681 - val_loss: 0.6685 - val_accuracy: 0.8236\n",
            "Epoch 47/300\n",
            "121/121 [==============================] - 1s 9ms/step - loss: 0.3827 - accuracy: 0.8684 - val_loss: 0.6683 - val_accuracy: 0.8135\n",
            "Epoch 48/300\n",
            "121/121 [==============================] - 1s 9ms/step - loss: 0.3480 - accuracy: 0.8876 - val_loss: 0.6306 - val_accuracy: 0.8159\n",
            "Epoch 49/300\n",
            "121/121 [==============================] - 1s 11ms/step - loss: 0.3841 - accuracy: 0.8730 - val_loss: 0.6525 - val_accuracy: 0.8205\n",
            "Epoch 50/300\n",
            "121/121 [==============================] - 1s 10ms/step - loss: 0.3568 - accuracy: 0.8868 - val_loss: 0.6630 - val_accuracy: 0.8135\n",
            "Epoch 51/300\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.3556 - accuracy: 0.8779 - val_loss: 0.6686 - val_accuracy: 0.8135\n",
            "Epoch 52/300\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.3517 - accuracy: 0.8793 - val_loss: 0.6805 - val_accuracy: 0.8190\n",
            "Epoch 53/300\n",
            "121/121 [==============================] - 1s 9ms/step - loss: 0.3733 - accuracy: 0.8706 - val_loss: 0.6451 - val_accuracy: 0.8042\n",
            "Epoch 54/300\n",
            "121/121 [==============================] - 1s 9ms/step - loss: 0.3211 - accuracy: 0.8892 - val_loss: 0.6865 - val_accuracy: 0.8190\n",
            "Epoch 55/300\n",
            "121/121 [==============================] - 1s 9ms/step - loss: 0.3450 - accuracy: 0.8828 - val_loss: 0.6593 - val_accuracy: 0.8120\n",
            "Epoch 56/300\n",
            "121/121 [==============================] - 1s 9ms/step - loss: 0.3488 - accuracy: 0.8822 - val_loss: 0.6497 - val_accuracy: 0.8166\n",
            "Epoch 57/300\n",
            "121/121 [==============================] - 1s 11ms/step - loss: 0.3163 - accuracy: 0.9040 - val_loss: 0.6570 - val_accuracy: 0.8236\n",
            "Epoch 58/300\n",
            "121/121 [==============================] - 1s 10ms/step - loss: 0.3479 - accuracy: 0.8889 - val_loss: 0.6711 - val_accuracy: 0.8096\n",
            "Epoch 59/300\n",
            "121/121 [==============================] - 1s 9ms/step - loss: 0.3346 - accuracy: 0.8934 - val_loss: 0.6591 - val_accuracy: 0.8228\n",
            "Epoch 60/300\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.3285 - accuracy: 0.8931 - val_loss: 0.6581 - val_accuracy: 0.8213\n",
            "Epoch 61/300\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.3535 - accuracy: 0.8854 - val_loss: 0.7078 - val_accuracy: 0.8182\n",
            "Epoch 62/300\n",
            "121/121 [==============================] - 1s 9ms/step - loss: 0.3351 - accuracy: 0.8846 - val_loss: 0.6742 - val_accuracy: 0.8205\n",
            "Epoch 63/300\n",
            "121/121 [==============================] - 1s 11ms/step - loss: 0.3205 - accuracy: 0.8937 - val_loss: 0.6964 - val_accuracy: 0.8143\n",
            "Epoch 64/300\n",
            "121/121 [==============================] - 1s 9ms/step - loss: 0.3364 - accuracy: 0.8961 - val_loss: 0.6552 - val_accuracy: 0.8151\n",
            "Epoch 65/300\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.3178 - accuracy: 0.9003 - val_loss: 0.6566 - val_accuracy: 0.8236\n",
            "Epoch 66/300\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.2955 - accuracy: 0.9002 - val_loss: 0.6709 - val_accuracy: 0.8244\n",
            "Epoch 67/300\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.3245 - accuracy: 0.8964 - val_loss: 0.6843 - val_accuracy: 0.8127\n",
            "Epoch 68/300\n",
            "121/121 [==============================] - 1s 7ms/step - loss: 0.2903 - accuracy: 0.9062 - val_loss: 0.6577 - val_accuracy: 0.8275\n",
            "Epoch 69/300\n",
            "121/121 [==============================] - 1s 7ms/step - loss: 0.3097 - accuracy: 0.8944 - val_loss: 0.6819 - val_accuracy: 0.8135\n",
            "Epoch 70/300\n",
            "121/121 [==============================] - 1s 7ms/step - loss: 0.2980 - accuracy: 0.9067 - val_loss: 0.6909 - val_accuracy: 0.8236\n",
            "Epoch 71/300\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.2970 - accuracy: 0.8965 - val_loss: 0.6934 - val_accuracy: 0.8197\n",
            "Epoch 72/300\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.3419 - accuracy: 0.8821 - val_loss: 0.6546 - val_accuracy: 0.8221\n",
            "Epoch 73/300\n",
            "121/121 [==============================] - 1s 9ms/step - loss: 0.3195 - accuracy: 0.8980 - val_loss: 0.6539 - val_accuracy: 0.8267\n",
            "Epoch 74/300\n",
            "121/121 [==============================] - 2s 13ms/step - loss: 0.2725 - accuracy: 0.9085 - val_loss: 0.6719 - val_accuracy: 0.8190\n",
            "Epoch 75/300\n",
            "121/121 [==============================] - 1s 11ms/step - loss: 0.2679 - accuracy: 0.9087 - val_loss: 0.6447 - val_accuracy: 0.8314\n",
            "Epoch 76/300\n",
            "121/121 [==============================] - 1s 9ms/step - loss: 0.2814 - accuracy: 0.9077 - val_loss: 0.6692 - val_accuracy: 0.8298\n",
            "Epoch 77/300\n",
            "121/121 [==============================] - 1s 7ms/step - loss: 0.3068 - accuracy: 0.8966 - val_loss: 0.6931 - val_accuracy: 0.8174\n",
            "Epoch 78/300\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.3115 - accuracy: 0.8963 - val_loss: 0.6803 - val_accuracy: 0.8205\n",
            "Epoch 79/300\n",
            "121/121 [==============================] - 1s 7ms/step - loss: 0.3021 - accuracy: 0.8992 - val_loss: 0.6601 - val_accuracy: 0.8127\n",
            "Epoch 80/300\n",
            "121/121 [==============================] - 1s 7ms/step - loss: 0.2983 - accuracy: 0.8987 - val_loss: 0.6441 - val_accuracy: 0.8260\n",
            "Epoch 81/300\n",
            "121/121 [==============================] - 1s 7ms/step - loss: 0.2696 - accuracy: 0.9113 - val_loss: 0.6492 - val_accuracy: 0.8329\n",
            "Epoch 82/300\n",
            "121/121 [==============================] - 1s 7ms/step - loss: 0.2649 - accuracy: 0.9171 - val_loss: 0.6621 - val_accuracy: 0.8221\n",
            "Epoch 83/300\n",
            "121/121 [==============================] - 1s 7ms/step - loss: 0.2712 - accuracy: 0.9030 - val_loss: 0.6673 - val_accuracy: 0.8228\n",
            "Epoch 84/300\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.2913 - accuracy: 0.9058 - val_loss: 0.6624 - val_accuracy: 0.8174\n",
            "Epoch 85/300\n",
            "121/121 [==============================] - 1s 9ms/step - loss: 0.2769 - accuracy: 0.9102 - val_loss: 0.6825 - val_accuracy: 0.8213\n",
            "Epoch 86/300\n",
            "121/121 [==============================] - 1s 12ms/step - loss: 0.2533 - accuracy: 0.9165 - val_loss: 0.7015 - val_accuracy: 0.8260\n",
            "Epoch 87/300\n",
            "121/121 [==============================] - 1s 9ms/step - loss: 0.2906 - accuracy: 0.9049 - val_loss: 0.7154 - val_accuracy: 0.8228\n",
            "Epoch 88/300\n",
            "121/121 [==============================] - 1s 11ms/step - loss: 0.3271 - accuracy: 0.8922 - val_loss: 0.6596 - val_accuracy: 0.8190\n",
            "2\n",
            "model 0\n",
            "Epoch 1/300\n",
            "9/9 [==============================] - 4s 282ms/step - loss: 2.2511 - accuracy: 0.1173 - val_loss: 2.0972 - val_accuracy: 0.2000\n",
            "Epoch 2/300\n",
            "9/9 [==============================] - 2s 265ms/step - loss: 2.0876 - accuracy: 0.2098 - val_loss: 1.9869 - val_accuracy: 0.2428\n",
            "Epoch 3/300\n",
            "9/9 [==============================] - 2s 197ms/step - loss: 1.9696 - accuracy: 0.2759 - val_loss: 1.8668 - val_accuracy: 0.3268\n",
            "Epoch 4/300\n",
            "9/9 [==============================] - 2s 196ms/step - loss: 1.8634 - accuracy: 0.3033 - val_loss: 1.8165 - val_accuracy: 0.3464\n",
            "Epoch 5/300\n",
            "9/9 [==============================] - 2s 212ms/step - loss: 1.7866 - accuracy: 0.3487 - val_loss: 1.6966 - val_accuracy: 0.3899\n",
            "Epoch 6/300\n",
            "9/9 [==============================] - 2s 200ms/step - loss: 1.6706 - accuracy: 0.3900 - val_loss: 1.5219 - val_accuracy: 0.4471\n",
            "Epoch 7/300\n",
            "9/9 [==============================] - 2s 200ms/step - loss: 1.5328 - accuracy: 0.4412 - val_loss: 1.4745 - val_accuracy: 0.4855\n",
            "Epoch 8/300\n",
            "9/9 [==============================] - 2s 200ms/step - loss: 1.4457 - accuracy: 0.4932 - val_loss: 1.3781 - val_accuracy: 0.5268\n",
            "Epoch 9/300\n",
            "9/9 [==============================] - 2s 225ms/step - loss: 1.3102 - accuracy: 0.5406 - val_loss: 1.2317 - val_accuracy: 0.5768\n",
            "Epoch 10/300\n",
            "9/9 [==============================] - 2s 242ms/step - loss: 1.2326 - accuracy: 0.5739 - val_loss: 1.1135 - val_accuracy: 0.6275\n",
            "Epoch 11/300\n",
            "9/9 [==============================] - 2s 214ms/step - loss: 1.0886 - accuracy: 0.6329 - val_loss: 1.0708 - val_accuracy: 0.6391\n",
            "Epoch 12/300\n",
            "9/9 [==============================] - 2s 226ms/step - loss: 1.0349 - accuracy: 0.6514 - val_loss: 0.9490 - val_accuracy: 0.6841\n",
            "Epoch 13/300\n",
            "9/9 [==============================] - 2s 196ms/step - loss: 0.9124 - accuracy: 0.6987 - val_loss: 0.9755 - val_accuracy: 0.6826\n",
            "Epoch 14/300\n",
            "9/9 [==============================] - 2s 195ms/step - loss: 0.8844 - accuracy: 0.7119 - val_loss: 0.8794 - val_accuracy: 0.7370\n",
            "Epoch 15/300\n",
            "9/9 [==============================] - 2s 206ms/step - loss: 0.7684 - accuracy: 0.7589 - val_loss: 1.0173 - val_accuracy: 0.6775\n",
            "Epoch 16/300\n",
            "9/9 [==============================] - 2s 248ms/step - loss: 0.8650 - accuracy: 0.7265 - val_loss: 0.9216 - val_accuracy: 0.7123\n",
            "Epoch 17/300\n",
            "9/9 [==============================] - 2s 206ms/step - loss: 0.7627 - accuracy: 0.7514 - val_loss: 0.7812 - val_accuracy: 0.7746\n",
            "Epoch 18/300\n",
            "9/9 [==============================] - 2s 195ms/step - loss: 0.6678 - accuracy: 0.7904 - val_loss: 0.7835 - val_accuracy: 0.7616\n",
            "Epoch 19/300\n",
            "9/9 [==============================] - 2s 195ms/step - loss: 0.6061 - accuracy: 0.8159 - val_loss: 0.8917 - val_accuracy: 0.7094\n",
            "Epoch 20/300\n",
            "9/9 [==============================] - 2s 198ms/step - loss: 0.6580 - accuracy: 0.7865 - val_loss: 0.7338 - val_accuracy: 0.7804\n",
            "Epoch 21/300\n",
            "9/9 [==============================] - 2s 195ms/step - loss: 0.5545 - accuracy: 0.8307 - val_loss: 0.6891 - val_accuracy: 0.7971\n",
            "Epoch 22/300\n",
            "9/9 [==============================] - 2s 195ms/step - loss: 0.4982 - accuracy: 0.8477 - val_loss: 0.6738 - val_accuracy: 0.8007\n",
            "Epoch 23/300\n",
            "9/9 [==============================] - 2s 194ms/step - loss: 0.4609 - accuracy: 0.8588 - val_loss: 0.6943 - val_accuracy: 0.7920\n",
            "Epoch 24/300\n",
            "9/9 [==============================] - 2s 199ms/step - loss: 0.4551 - accuracy: 0.8616 - val_loss: 0.7216 - val_accuracy: 0.7935\n",
            "Epoch 25/300\n",
            "9/9 [==============================] - 2s 210ms/step - loss: 0.4426 - accuracy: 0.8628 - val_loss: 0.7099 - val_accuracy: 0.8014\n",
            "Epoch 26/300\n",
            "9/9 [==============================] - 2s 205ms/step - loss: 0.4125 - accuracy: 0.8697 - val_loss: 0.6645 - val_accuracy: 0.8094\n",
            "Epoch 27/300\n",
            "9/9 [==============================] - 2s 198ms/step - loss: 0.3481 - accuracy: 0.8993 - val_loss: 0.7056 - val_accuracy: 0.8094\n",
            "Epoch 28/300\n",
            "9/9 [==============================] - 2s 192ms/step - loss: 0.3450 - accuracy: 0.8926 - val_loss: 0.7121 - val_accuracy: 0.7935\n",
            "Epoch 29/300\n",
            "9/9 [==============================] - 2s 198ms/step - loss: 0.3619 - accuracy: 0.8846 - val_loss: 0.7516 - val_accuracy: 0.7870\n",
            "Epoch 30/300\n",
            "9/9 [==============================] - 2s 193ms/step - loss: 0.3727 - accuracy: 0.8748 - val_loss: 0.6528 - val_accuracy: 0.8094\n",
            "Epoch 31/300\n",
            "9/9 [==============================] - 2s 202ms/step - loss: 0.2879 - accuracy: 0.9143 - val_loss: 0.6265 - val_accuracy: 0.8232\n",
            "Epoch 32/300\n",
            "9/9 [==============================] - 2s 192ms/step - loss: 0.2655 - accuracy: 0.9259 - val_loss: 0.6748 - val_accuracy: 0.8167\n",
            "Epoch 33/300\n",
            "9/9 [==============================] - 2s 192ms/step - loss: 0.2515 - accuracy: 0.9256 - val_loss: 0.6953 - val_accuracy: 0.8196\n",
            "Epoch 34/300\n",
            "9/9 [==============================] - 2s 195ms/step - loss: 0.2507 - accuracy: 0.9256 - val_loss: 0.6785 - val_accuracy: 0.8254\n",
            "Epoch 35/300\n",
            "9/9 [==============================] - 2s 195ms/step - loss: 0.2226 - accuracy: 0.9294 - val_loss: 0.6642 - val_accuracy: 0.8239\n",
            "Epoch 36/300\n",
            "9/9 [==============================] - 2s 205ms/step - loss: 0.2138 - accuracy: 0.9391 - val_loss: 0.6509 - val_accuracy: 0.8203\n",
            "Epoch 37/300\n",
            "9/9 [==============================] - 2s 200ms/step - loss: 0.2518 - accuracy: 0.9261 - val_loss: 0.7386 - val_accuracy: 0.8065\n",
            "Epoch 38/300\n",
            "9/9 [==============================] - 2s 196ms/step - loss: 0.2236 - accuracy: 0.9349 - val_loss: 0.7177 - val_accuracy: 0.8130\n",
            "Epoch 39/300\n",
            "9/9 [==============================] - 2s 200ms/step - loss: 0.2035 - accuracy: 0.9354 - val_loss: 0.6530 - val_accuracy: 0.8261\n",
            "Epoch 40/300\n",
            "9/9 [==============================] - 2s 202ms/step - loss: 0.1868 - accuracy: 0.9458 - val_loss: 0.6712 - val_accuracy: 0.8239\n",
            "Epoch 41/300\n",
            "9/9 [==============================] - 2s 193ms/step - loss: 0.1572 - accuracy: 0.9524 - val_loss: 0.6596 - val_accuracy: 0.8312\n",
            "Epoch 42/300\n",
            "9/9 [==============================] - 2s 194ms/step - loss: 0.1470 - accuracy: 0.9582 - val_loss: 0.6925 - val_accuracy: 0.8268\n",
            "Epoch 43/300\n",
            "9/9 [==============================] - 2s 197ms/step - loss: 0.1307 - accuracy: 0.9636 - val_loss: 0.7187 - val_accuracy: 0.8268\n",
            "Epoch 44/300\n",
            "9/9 [==============================] - 2s 191ms/step - loss: 0.1400 - accuracy: 0.9581 - val_loss: 0.8038 - val_accuracy: 0.8130\n",
            "Epoch 45/300\n",
            "9/9 [==============================] - 2s 191ms/step - loss: 0.1440 - accuracy: 0.9567 - val_loss: 0.7530 - val_accuracy: 0.8210\n",
            "Epoch 46/300\n",
            "9/9 [==============================] - 2s 200ms/step - loss: 0.1382 - accuracy: 0.9597 - val_loss: 0.6960 - val_accuracy: 0.8326\n",
            "Epoch 47/300\n",
            "9/9 [==============================] - 2s 204ms/step - loss: 0.1140 - accuracy: 0.9670 - val_loss: 0.7438 - val_accuracy: 0.8290\n",
            "Epoch 48/300\n",
            "9/9 [==============================] - 2s 204ms/step - loss: 0.0957 - accuracy: 0.9744 - val_loss: 0.7629 - val_accuracy: 0.8225\n",
            "Epoch 49/300\n",
            "9/9 [==============================] - 2s 200ms/step - loss: 0.0901 - accuracy: 0.9788 - val_loss: 0.7382 - val_accuracy: 0.8297\n",
            "Epoch 50/300\n",
            "9/9 [==============================] - 2s 201ms/step - loss: 0.0867 - accuracy: 0.9766 - val_loss: 0.8161 - val_accuracy: 0.8138\n",
            "Epoch 51/300\n",
            "9/9 [==============================] - 2s 202ms/step - loss: 0.0779 - accuracy: 0.9776 - val_loss: 0.7848 - val_accuracy: 0.8232\n",
            "Epoch 52/300\n",
            "9/9 [==============================] - 2s 196ms/step - loss: 0.0851 - accuracy: 0.9773 - val_loss: 0.8147 - val_accuracy: 0.8254\n",
            "Epoch 53/300\n",
            "9/9 [==============================] - 2s 194ms/step - loss: 0.0716 - accuracy: 0.9797 - val_loss: 0.7845 - val_accuracy: 0.8261\n",
            "Epoch 54/300\n",
            "9/9 [==============================] - 2s 193ms/step - loss: 0.0513 - accuracy: 0.9872 - val_loss: 0.8859 - val_accuracy: 0.8152\n",
            "Epoch 55/300\n",
            "9/9 [==============================] - 2s 198ms/step - loss: 0.0666 - accuracy: 0.9809 - val_loss: 0.8370 - val_accuracy: 0.8268\n",
            "Epoch 56/300\n",
            "9/9 [==============================] - 2s 211ms/step - loss: 0.0558 - accuracy: 0.9857 - val_loss: 0.8411 - val_accuracy: 0.8188\n",
            "Epoch 57/300\n",
            "9/9 [==============================] - 2s 201ms/step - loss: 0.0692 - accuracy: 0.9775 - val_loss: 0.9016 - val_accuracy: 0.8116\n",
            "Epoch 58/300\n",
            "9/9 [==============================] - 2s 205ms/step - loss: 0.0777 - accuracy: 0.9767 - val_loss: 0.8145 - val_accuracy: 0.8225\n",
            "Epoch 59/300\n",
            "9/9 [==============================] - 2s 193ms/step - loss: 0.0583 - accuracy: 0.9839 - val_loss: 0.8814 - val_accuracy: 0.8159\n",
            "Epoch 60/300\n",
            "9/9 [==============================] - 2s 194ms/step - loss: 0.0519 - accuracy: 0.9864 - val_loss: 0.8287 - val_accuracy: 0.8290\n",
            "Epoch 61/300\n",
            "9/9 [==============================] - 2s 195ms/step - loss: 0.0485 - accuracy: 0.9869 - val_loss: 0.8690 - val_accuracy: 0.8239\n",
            "Epoch 62/300\n",
            "9/9 [==============================] - 2s 195ms/step - loss: 0.0476 - accuracy: 0.9877 - val_loss: 0.8841 - val_accuracy: 0.8203\n",
            "Epoch 63/300\n",
            "9/9 [==============================] - 2s 194ms/step - loss: 0.0361 - accuracy: 0.9918 - val_loss: 0.8848 - val_accuracy: 0.8246\n",
            "Epoch 64/300\n",
            "9/9 [==============================] - 2s 197ms/step - loss: 0.0342 - accuracy: 0.9934 - val_loss: 0.8946 - val_accuracy: 0.8312\n",
            "Epoch 65/300\n",
            "9/9 [==============================] - 2s 202ms/step - loss: 0.0383 - accuracy: 0.9876 - val_loss: 0.9459 - val_accuracy: 0.8290\n",
            "Epoch 66/300\n",
            "9/9 [==============================] - 2s 217ms/step - loss: 0.0485 - accuracy: 0.9883 - val_loss: 0.9383 - val_accuracy: 0.8130\n",
            "Epoch 67/300\n",
            "9/9 [==============================] - 2s 200ms/step - loss: 0.1155 - accuracy: 0.9679 - val_loss: 0.9951 - val_accuracy: 0.8094\n",
            "Epoch 68/300\n",
            "9/9 [==============================] - 2s 219ms/step - loss: 0.4740 - accuracy: 0.8822 - val_loss: 0.9353 - val_accuracy: 0.7978\n",
            "Epoch 69/300\n",
            "9/9 [==============================] - 2s 222ms/step - loss: 0.2203 - accuracy: 0.9201 - val_loss: 0.8915 - val_accuracy: 0.8072\n",
            "Epoch 70/300\n",
            "9/9 [==============================] - 2s 223ms/step - loss: 0.1676 - accuracy: 0.9404 - val_loss: 0.8106 - val_accuracy: 0.8290\n",
            "Epoch 71/300\n",
            "9/9 [==============================] - 2s 197ms/step - loss: 0.1026 - accuracy: 0.9687 - val_loss: 0.8180 - val_accuracy: 0.8210\n",
            "model 1\n",
            "Epoch 1/300\n",
            "9/9 [==============================] - 5s 400ms/step - loss: 2.2350 - accuracy: 0.1466 - val_loss: 2.1043 - val_accuracy: 0.2232\n",
            "Epoch 2/300\n",
            "9/9 [==============================] - 4s 415ms/step - loss: 1.9534 - accuracy: 0.3122 - val_loss: 1.6589 - val_accuracy: 0.4391\n",
            "Epoch 3/300\n",
            "9/9 [==============================] - 3s 341ms/step - loss: 1.6494 - accuracy: 0.4499 - val_loss: 1.4461 - val_accuracy: 0.5319\n",
            "Epoch 4/300\n",
            "9/9 [==============================] - 3s 311ms/step - loss: 1.4959 - accuracy: 0.4903 - val_loss: 1.3257 - val_accuracy: 0.5725\n",
            "Epoch 5/300\n",
            "9/9 [==============================] - 3s 362ms/step - loss: 1.3576 - accuracy: 0.5465 - val_loss: 1.2053 - val_accuracy: 0.6210\n",
            "Epoch 6/300\n",
            "9/9 [==============================] - 3s 359ms/step - loss: 1.2465 - accuracy: 0.5884 - val_loss: 1.1471 - val_accuracy: 0.6558\n",
            "Epoch 7/300\n",
            "9/9 [==============================] - 3s 362ms/step - loss: 1.1819 - accuracy: 0.6193 - val_loss: 1.0449 - val_accuracy: 0.6754\n",
            "Epoch 8/300\n",
            "9/9 [==============================] - 3s 366ms/step - loss: 1.1121 - accuracy: 0.6394 - val_loss: 1.0136 - val_accuracy: 0.6964\n",
            "Epoch 9/300\n",
            "9/9 [==============================] - 3s 338ms/step - loss: 1.0181 - accuracy: 0.6757 - val_loss: 0.9100 - val_accuracy: 0.7283\n",
            "Epoch 10/300\n",
            "9/9 [==============================] - 3s 355ms/step - loss: 0.9830 - accuracy: 0.6759 - val_loss: 0.8907 - val_accuracy: 0.7326\n",
            "Epoch 11/300\n",
            "9/9 [==============================] - 3s 370ms/step - loss: 0.9361 - accuracy: 0.7064 - val_loss: 0.8485 - val_accuracy: 0.7435\n",
            "Epoch 12/300\n",
            "9/9 [==============================] - 3s 341ms/step - loss: 0.9107 - accuracy: 0.7088 - val_loss: 0.8357 - val_accuracy: 0.7536\n",
            "Epoch 13/300\n",
            "9/9 [==============================] - 3s 371ms/step - loss: 0.8718 - accuracy: 0.7256 - val_loss: 0.7584 - val_accuracy: 0.7710\n",
            "Epoch 14/300\n",
            "9/9 [==============================] - 3s 319ms/step - loss: 0.8420 - accuracy: 0.7239 - val_loss: 0.7296 - val_accuracy: 0.7841\n",
            "Epoch 15/300\n",
            "9/9 [==============================] - 3s 320ms/step - loss: 0.7826 - accuracy: 0.7522 - val_loss: 0.7223 - val_accuracy: 0.7862\n",
            "Epoch 16/300\n",
            "9/9 [==============================] - 3s 319ms/step - loss: 0.7405 - accuracy: 0.7664 - val_loss: 0.6981 - val_accuracy: 0.7964\n",
            "Epoch 17/300\n",
            "9/9 [==============================] - 3s 309ms/step - loss: 0.7376 - accuracy: 0.7557 - val_loss: 0.6741 - val_accuracy: 0.8022\n",
            "Epoch 18/300\n",
            "9/9 [==============================] - 3s 343ms/step - loss: 0.7091 - accuracy: 0.7707 - val_loss: 0.6685 - val_accuracy: 0.8029\n",
            "Epoch 19/300\n",
            "9/9 [==============================] - 3s 345ms/step - loss: 0.6687 - accuracy: 0.7842 - val_loss: 0.6514 - val_accuracy: 0.8043\n",
            "Epoch 20/300\n",
            "9/9 [==============================] - 3s 348ms/step - loss: 0.6195 - accuracy: 0.8060 - val_loss: 0.6346 - val_accuracy: 0.8152\n",
            "Epoch 21/300\n",
            "9/9 [==============================] - 3s 329ms/step - loss: 0.6296 - accuracy: 0.8008 - val_loss: 0.6093 - val_accuracy: 0.8159\n",
            "Epoch 22/300\n",
            "9/9 [==============================] - 3s 322ms/step - loss: 0.6068 - accuracy: 0.7989 - val_loss: 0.5908 - val_accuracy: 0.8196\n",
            "Epoch 23/300\n",
            "9/9 [==============================] - 3s 362ms/step - loss: 0.5678 - accuracy: 0.8184 - val_loss: 0.5931 - val_accuracy: 0.8217\n",
            "Epoch 24/300\n",
            "9/9 [==============================] - 3s 363ms/step - loss: 0.5630 - accuracy: 0.8233 - val_loss: 0.5813 - val_accuracy: 0.8304\n",
            "Epoch 25/300\n",
            "9/9 [==============================] - 3s 319ms/step - loss: 0.5383 - accuracy: 0.8318 - val_loss: 0.5876 - val_accuracy: 0.8203\n",
            "Epoch 26/300\n",
            "9/9 [==============================] - 3s 305ms/step - loss: 0.5209 - accuracy: 0.8273 - val_loss: 0.5691 - val_accuracy: 0.8341\n",
            "Epoch 27/300\n",
            "9/9 [==============================] - 3s 314ms/step - loss: 0.5334 - accuracy: 0.8235 - val_loss: 0.5456 - val_accuracy: 0.8428\n",
            "Epoch 28/300\n",
            "9/9 [==============================] - 3s 310ms/step - loss: 0.5038 - accuracy: 0.8322 - val_loss: 0.5496 - val_accuracy: 0.8319\n",
            "Epoch 29/300\n",
            "9/9 [==============================] - 3s 312ms/step - loss: 0.4927 - accuracy: 0.8338 - val_loss: 0.5270 - val_accuracy: 0.8478\n",
            "Epoch 30/300\n",
            "9/9 [==============================] - 3s 314ms/step - loss: 0.4475 - accuracy: 0.8540 - val_loss: 0.5334 - val_accuracy: 0.8420\n",
            "Epoch 31/300\n",
            "9/9 [==============================] - 3s 309ms/step - loss: 0.4387 - accuracy: 0.8546 - val_loss: 0.5363 - val_accuracy: 0.8435\n",
            "Epoch 32/300\n",
            "9/9 [==============================] - 3s 317ms/step - loss: 0.4268 - accuracy: 0.8557 - val_loss: 0.5448 - val_accuracy: 0.8384\n",
            "Epoch 33/300\n",
            "9/9 [==============================] - 3s 324ms/step - loss: 0.4254 - accuracy: 0.8581 - val_loss: 0.5416 - val_accuracy: 0.8384\n",
            "Epoch 34/300\n",
            "9/9 [==============================] - 3s 311ms/step - loss: 0.4365 - accuracy: 0.8498 - val_loss: 0.5235 - val_accuracy: 0.8377\n",
            "Epoch 35/300\n",
            "9/9 [==============================] - 3s 305ms/step - loss: 0.4039 - accuracy: 0.8633 - val_loss: 0.5275 - val_accuracy: 0.8413\n",
            "Epoch 36/300\n",
            "9/9 [==============================] - 3s 348ms/step - loss: 0.3746 - accuracy: 0.8740 - val_loss: 0.5500 - val_accuracy: 0.8290\n",
            "Epoch 37/300\n",
            "9/9 [==============================] - 4s 420ms/step - loss: 0.3995 - accuracy: 0.8721 - val_loss: 0.5126 - val_accuracy: 0.8457\n",
            "Epoch 38/300\n",
            "9/9 [==============================] - 3s 314ms/step - loss: 0.3717 - accuracy: 0.8718 - val_loss: 0.5294 - val_accuracy: 0.8326\n",
            "Epoch 39/300\n",
            "9/9 [==============================] - 3s 311ms/step - loss: 0.3525 - accuracy: 0.8861 - val_loss: 0.5240 - val_accuracy: 0.8399\n",
            "Epoch 40/300\n",
            "9/9 [==============================] - 3s 316ms/step - loss: 0.3579 - accuracy: 0.8830 - val_loss: 0.5196 - val_accuracy: 0.8449\n",
            "Epoch 41/300\n",
            "9/9 [==============================] - 3s 310ms/step - loss: 0.3385 - accuracy: 0.8850 - val_loss: 0.4929 - val_accuracy: 0.8493\n",
            "Epoch 42/300\n",
            "9/9 [==============================] - 3s 315ms/step - loss: 0.3335 - accuracy: 0.8919 - val_loss: 0.5020 - val_accuracy: 0.8507\n",
            "Epoch 43/300\n",
            "9/9 [==============================] - 3s 334ms/step - loss: 0.3311 - accuracy: 0.8891 - val_loss: 0.5253 - val_accuracy: 0.8312\n",
            "Epoch 44/300\n",
            "9/9 [==============================] - 3s 319ms/step - loss: 0.3231 - accuracy: 0.8926 - val_loss: 0.5265 - val_accuracy: 0.8449\n",
            "Epoch 45/300\n",
            "9/9 [==============================] - 3s 306ms/step - loss: 0.3192 - accuracy: 0.8947 - val_loss: 0.5317 - val_accuracy: 0.8391\n",
            "Epoch 46/300\n",
            "9/9 [==============================] - 3s 310ms/step - loss: 0.3075 - accuracy: 0.8919 - val_loss: 0.4963 - val_accuracy: 0.8529\n",
            "Epoch 47/300\n",
            "9/9 [==============================] - 3s 302ms/step - loss: 0.3241 - accuracy: 0.8869 - val_loss: 0.5305 - val_accuracy: 0.8457\n",
            "Epoch 48/300\n",
            "9/9 [==============================] - 3s 302ms/step - loss: 0.3108 - accuracy: 0.8954 - val_loss: 0.4923 - val_accuracy: 0.8551\n",
            "Epoch 49/300\n",
            "9/9 [==============================] - 3s 341ms/step - loss: 0.3014 - accuracy: 0.8889 - val_loss: 0.4880 - val_accuracy: 0.8543\n",
            "Epoch 50/300\n",
            "9/9 [==============================] - 3s 341ms/step - loss: 0.2766 - accuracy: 0.9085 - val_loss: 0.5044 - val_accuracy: 0.8442\n",
            "Epoch 51/300\n",
            "9/9 [==============================] - 3s 309ms/step - loss: 0.2864 - accuracy: 0.9055 - val_loss: 0.4810 - val_accuracy: 0.8638\n",
            "Epoch 52/300\n",
            "9/9 [==============================] - 3s 326ms/step - loss: 0.2739 - accuracy: 0.9085 - val_loss: 0.4910 - val_accuracy: 0.8536\n",
            "Epoch 53/300\n",
            "9/9 [==============================] - 3s 321ms/step - loss: 0.2832 - accuracy: 0.9032 - val_loss: 0.4972 - val_accuracy: 0.8529\n",
            "Epoch 54/300\n",
            "9/9 [==============================] - 3s 312ms/step - loss: 0.2698 - accuracy: 0.9111 - val_loss: 0.4898 - val_accuracy: 0.8478\n",
            "Epoch 55/300\n",
            "9/9 [==============================] - 3s 320ms/step - loss: 0.2502 - accuracy: 0.9124 - val_loss: 0.4913 - val_accuracy: 0.8594\n",
            "Epoch 56/300\n",
            "9/9 [==============================] - 3s 311ms/step - loss: 0.2661 - accuracy: 0.9076 - val_loss: 0.4865 - val_accuracy: 0.8572\n",
            "Epoch 57/300\n",
            "9/9 [==============================] - 3s 314ms/step - loss: 0.2473 - accuracy: 0.9196 - val_loss: 0.5395 - val_accuracy: 0.8384\n",
            "Epoch 58/300\n",
            "9/9 [==============================] - 3s 347ms/step - loss: 0.2469 - accuracy: 0.9146 - val_loss: 0.5256 - val_accuracy: 0.8514\n",
            "Epoch 59/300\n",
            "9/9 [==============================] - 3s 314ms/step - loss: 0.2569 - accuracy: 0.9175 - val_loss: 0.5100 - val_accuracy: 0.8529\n",
            "Epoch 60/300\n",
            "9/9 [==============================] - 3s 313ms/step - loss: 0.2341 - accuracy: 0.9223 - val_loss: 0.4993 - val_accuracy: 0.8471\n",
            "Epoch 61/300\n",
            "9/9 [==============================] - 3s 307ms/step - loss: 0.2381 - accuracy: 0.9201 - val_loss: 0.5223 - val_accuracy: 0.8442\n",
            "Epoch 62/300\n",
            "9/9 [==============================] - 3s 309ms/step - loss: 0.2303 - accuracy: 0.9191 - val_loss: 0.4991 - val_accuracy: 0.8514\n",
            "Epoch 63/300\n",
            "9/9 [==============================] - 3s 311ms/step - loss: 0.2139 - accuracy: 0.9280 - val_loss: 0.5169 - val_accuracy: 0.8529\n",
            "Epoch 64/300\n",
            "9/9 [==============================] - 3s 313ms/step - loss: 0.2139 - accuracy: 0.9242 - val_loss: 0.5289 - val_accuracy: 0.8457\n",
            "Epoch 65/300\n",
            "9/9 [==============================] - 3s 307ms/step - loss: 0.2229 - accuracy: 0.9233 - val_loss: 0.5021 - val_accuracy: 0.8616\n",
            "Epoch 66/300\n",
            "9/9 [==============================] - 3s 303ms/step - loss: 0.2238 - accuracy: 0.9227 - val_loss: 0.5165 - val_accuracy: 0.8478\n",
            "Epoch 67/300\n",
            "9/9 [==============================] - 3s 314ms/step - loss: 0.2145 - accuracy: 0.9284 - val_loss: 0.4723 - val_accuracy: 0.8616\n",
            "Epoch 68/300\n",
            "9/9 [==============================] - 3s 311ms/step - loss: 0.2006 - accuracy: 0.9335 - val_loss: 0.5162 - val_accuracy: 0.8536\n",
            "Epoch 69/300\n",
            "9/9 [==============================] - 3s 307ms/step - loss: 0.2040 - accuracy: 0.9380 - val_loss: 0.5118 - val_accuracy: 0.8572\n",
            "Epoch 70/300\n",
            "9/9 [==============================] - 3s 306ms/step - loss: 0.2089 - accuracy: 0.9326 - val_loss: 0.5115 - val_accuracy: 0.8558\n",
            "Epoch 71/300\n",
            "9/9 [==============================] - 3s 321ms/step - loss: 0.1826 - accuracy: 0.9391 - val_loss: 0.5148 - val_accuracy: 0.8565\n",
            "Epoch 72/300\n",
            "9/9 [==============================] - 3s 301ms/step - loss: 0.1980 - accuracy: 0.9307 - val_loss: 0.5048 - val_accuracy: 0.8536\n",
            "Epoch 73/300\n",
            "9/9 [==============================] - 3s 308ms/step - loss: 0.1900 - accuracy: 0.9345 - val_loss: 0.4862 - val_accuracy: 0.8580\n",
            "Epoch 74/300\n",
            "9/9 [==============================] - 3s 303ms/step - loss: 0.2012 - accuracy: 0.9367 - val_loss: 0.5285 - val_accuracy: 0.8536\n",
            "Epoch 75/300\n",
            "9/9 [==============================] - 3s 299ms/step - loss: 0.1862 - accuracy: 0.9388 - val_loss: 0.5025 - val_accuracy: 0.8551\n",
            "Epoch 76/300\n",
            "9/9 [==============================] - 3s 300ms/step - loss: 0.1783 - accuracy: 0.9415 - val_loss: 0.5063 - val_accuracy: 0.8543\n",
            "Epoch 77/300\n",
            "9/9 [==============================] - 3s 298ms/step - loss: 0.1754 - accuracy: 0.9401 - val_loss: 0.4863 - val_accuracy: 0.8594\n",
            "Epoch 78/300\n",
            "9/9 [==============================] - 3s 296ms/step - loss: 0.1730 - accuracy: 0.9410 - val_loss: 0.4982 - val_accuracy: 0.8601\n",
            "Epoch 79/300\n",
            "9/9 [==============================] - 3s 304ms/step - loss: 0.1745 - accuracy: 0.9436 - val_loss: 0.5088 - val_accuracy: 0.8580\n",
            "Epoch 80/300\n",
            "9/9 [==============================] - 3s 302ms/step - loss: 0.1589 - accuracy: 0.9481 - val_loss: 0.5351 - val_accuracy: 0.8536\n",
            "Epoch 81/300\n",
            "9/9 [==============================] - 3s 301ms/step - loss: 0.1661 - accuracy: 0.9482 - val_loss: 0.5097 - val_accuracy: 0.8580\n",
            "Epoch 82/300\n",
            "9/9 [==============================] - 3s 304ms/step - loss: 0.1696 - accuracy: 0.9425 - val_loss: 0.5201 - val_accuracy: 0.8529\n",
            "Epoch 83/300\n",
            "9/9 [==============================] - 3s 303ms/step - loss: 0.1686 - accuracy: 0.9425 - val_loss: 0.4880 - val_accuracy: 0.8652\n",
            "Epoch 84/300\n",
            "9/9 [==============================] - 3s 296ms/step - loss: 0.1518 - accuracy: 0.9508 - val_loss: 0.5265 - val_accuracy: 0.8565\n",
            "Epoch 85/300\n",
            "9/9 [==============================] - 3s 297ms/step - loss: 0.1728 - accuracy: 0.9447 - val_loss: 0.5260 - val_accuracy: 0.8565\n",
            "Epoch 86/300\n",
            "9/9 [==============================] - 3s 311ms/step - loss: 0.1619 - accuracy: 0.9486 - val_loss: 0.5123 - val_accuracy: 0.8522\n",
            "Epoch 87/300\n",
            "9/9 [==============================] - 3s 305ms/step - loss: 0.1429 - accuracy: 0.9509 - val_loss: 0.4828 - val_accuracy: 0.8536\n",
            "Epoch 88/300\n",
            "9/9 [==============================] - 3s 303ms/step - loss: 0.1435 - accuracy: 0.9521 - val_loss: 0.5061 - val_accuracy: 0.8514\n",
            "Epoch 89/300\n",
            "9/9 [==============================] - 3s 310ms/step - loss: 0.1532 - accuracy: 0.9487 - val_loss: 0.5101 - val_accuracy: 0.8565\n",
            "Epoch 90/300\n",
            "9/9 [==============================] - 3s 307ms/step - loss: 0.1516 - accuracy: 0.9490 - val_loss: 0.5195 - val_accuracy: 0.8609\n",
            "Epoch 91/300\n",
            "9/9 [==============================] - 3s 305ms/step - loss: 0.1613 - accuracy: 0.9447 - val_loss: 0.5035 - val_accuracy: 0.8565\n",
            "Epoch 92/300\n",
            "9/9 [==============================] - 3s 305ms/step - loss: 0.1540 - accuracy: 0.9480 - val_loss: 0.4998 - val_accuracy: 0.8616\n",
            "Epoch 93/300\n",
            "9/9 [==============================] - 3s 302ms/step - loss: 0.1573 - accuracy: 0.9493 - val_loss: 0.5065 - val_accuracy: 0.8587\n",
            "Epoch 94/300\n",
            "9/9 [==============================] - 3s 306ms/step - loss: 0.1405 - accuracy: 0.9553 - val_loss: 0.5396 - val_accuracy: 0.8638\n",
            "Epoch 95/300\n",
            "9/9 [==============================] - 3s 313ms/step - loss: 0.1387 - accuracy: 0.9506 - val_loss: 0.5416 - val_accuracy: 0.8536\n",
            "Epoch 96/300\n",
            "9/9 [==============================] - 3s 301ms/step - loss: 0.1224 - accuracy: 0.9586 - val_loss: 0.5043 - val_accuracy: 0.8638\n",
            "Epoch 97/300\n",
            "9/9 [==============================] - 3s 308ms/step - loss: 0.1471 - accuracy: 0.9533 - val_loss: 0.5385 - val_accuracy: 0.8587\n",
            "Epoch 98/300\n",
            "9/9 [==============================] - 3s 307ms/step - loss: 0.1371 - accuracy: 0.9547 - val_loss: 0.5246 - val_accuracy: 0.8565\n",
            "Epoch 99/300\n",
            "9/9 [==============================] - 3s 303ms/step - loss: 0.1257 - accuracy: 0.9548 - val_loss: 0.5366 - val_accuracy: 0.8630\n",
            "Epoch 100/300\n",
            "9/9 [==============================] - 3s 303ms/step - loss: 0.1415 - accuracy: 0.9535 - val_loss: 0.5178 - val_accuracy: 0.8587\n",
            "Epoch 101/300\n",
            "9/9 [==============================] - 3s 307ms/step - loss: 0.1235 - accuracy: 0.9577 - val_loss: 0.5472 - val_accuracy: 0.8616\n",
            "Epoch 102/300\n",
            "9/9 [==============================] - 3s 303ms/step - loss: 0.1262 - accuracy: 0.9589 - val_loss: 0.5279 - val_accuracy: 0.8659\n",
            "Epoch 103/300\n",
            "9/9 [==============================] - 3s 300ms/step - loss: 0.1208 - accuracy: 0.9608 - val_loss: 0.5582 - val_accuracy: 0.8478\n",
            "Epoch 104/300\n",
            "9/9 [==============================] - 3s 306ms/step - loss: 0.1138 - accuracy: 0.9633 - val_loss: 0.5474 - val_accuracy: 0.8558\n",
            "Epoch 105/300\n",
            "9/9 [==============================] - 3s 312ms/step - loss: 0.1201 - accuracy: 0.9584 - val_loss: 0.5596 - val_accuracy: 0.8522\n",
            "Epoch 106/300\n",
            "9/9 [==============================] - 3s 313ms/step - loss: 0.1299 - accuracy: 0.9608 - val_loss: 0.5507 - val_accuracy: 0.8572\n",
            "Epoch 107/300\n",
            "9/9 [==============================] - 3s 304ms/step - loss: 0.1247 - accuracy: 0.9583 - val_loss: 0.5328 - val_accuracy: 0.8594\n",
            "model 2\n",
            "Epoch 1/300\n",
            "130/130 [==============================] - 1s 8ms/step - loss: 2.1569 - accuracy: 0.2076 - val_loss: 1.4342 - val_accuracy: 0.5275\n",
            "Epoch 2/300\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 1.4978 - accuracy: 0.4781 - val_loss: 1.2410 - val_accuracy: 0.6145\n",
            "Epoch 3/300\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 1.2595 - accuracy: 0.5882 - val_loss: 1.0769 - val_accuracy: 0.6688\n",
            "Epoch 4/300\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 1.1481 - accuracy: 0.6247 - val_loss: 1.0020 - val_accuracy: 0.6783\n",
            "Epoch 5/300\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 1.0897 - accuracy: 0.6505 - val_loss: 0.8733 - val_accuracy: 0.7239\n",
            "Epoch 6/300\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.9534 - accuracy: 0.6963 - val_loss: 0.8883 - val_accuracy: 0.7123\n",
            "Epoch 7/300\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.9101 - accuracy: 0.7005 - val_loss: 0.8218 - val_accuracy: 0.7464\n",
            "Epoch 8/300\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.8444 - accuracy: 0.7210 - val_loss: 0.8000 - val_accuracy: 0.7420\n",
            "Epoch 9/300\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.8055 - accuracy: 0.7464 - val_loss: 0.7811 - val_accuracy: 0.7580\n",
            "Epoch 10/300\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.7908 - accuracy: 0.7491 - val_loss: 0.7646 - val_accuracy: 0.7580\n",
            "Epoch 11/300\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.7535 - accuracy: 0.7473 - val_loss: 0.7427 - val_accuracy: 0.7659\n",
            "Epoch 12/300\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.7506 - accuracy: 0.7594 - val_loss: 0.7216 - val_accuracy: 0.7717\n",
            "Epoch 13/300\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.7437 - accuracy: 0.7610 - val_loss: 0.7214 - val_accuracy: 0.7775\n",
            "Epoch 14/300\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.6981 - accuracy: 0.7732 - val_loss: 0.6821 - val_accuracy: 0.7884\n",
            "Epoch 15/300\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.6809 - accuracy: 0.7827 - val_loss: 0.7092 - val_accuracy: 0.7746\n",
            "Epoch 16/300\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.6461 - accuracy: 0.7969 - val_loss: 0.6797 - val_accuracy: 0.7870\n",
            "Epoch 17/300\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.6611 - accuracy: 0.7982 - val_loss: 0.7027 - val_accuracy: 0.7870\n",
            "Epoch 18/300\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.6227 - accuracy: 0.7988 - val_loss: 0.6714 - val_accuracy: 0.7949\n",
            "Epoch 19/300\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.5951 - accuracy: 0.8090 - val_loss: 0.7098 - val_accuracy: 0.7797\n",
            "Epoch 20/300\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.5846 - accuracy: 0.8107 - val_loss: 0.6621 - val_accuracy: 0.7913\n",
            "Epoch 21/300\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.6033 - accuracy: 0.8049 - val_loss: 0.6285 - val_accuracy: 0.8152\n",
            "Epoch 22/300\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.5798 - accuracy: 0.8169 - val_loss: 0.6232 - val_accuracy: 0.7978\n",
            "Epoch 23/300\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.5620 - accuracy: 0.8129 - val_loss: 0.6320 - val_accuracy: 0.8065\n",
            "Epoch 24/300\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.5525 - accuracy: 0.8167 - val_loss: 0.6164 - val_accuracy: 0.8109\n",
            "Epoch 25/300\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.5517 - accuracy: 0.8259 - val_loss: 0.6169 - val_accuracy: 0.8152\n",
            "Epoch 26/300\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.5468 - accuracy: 0.8255 - val_loss: 0.6588 - val_accuracy: 0.8000\n",
            "Epoch 27/300\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.5127 - accuracy: 0.8262 - val_loss: 0.6528 - val_accuracy: 0.8000\n",
            "Epoch 28/300\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.5509 - accuracy: 0.8192 - val_loss: 0.6256 - val_accuracy: 0.8145\n",
            "Epoch 29/300\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.5343 - accuracy: 0.8242 - val_loss: 0.6163 - val_accuracy: 0.8167\n",
            "Epoch 30/300\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.5081 - accuracy: 0.8435 - val_loss: 0.6277 - val_accuracy: 0.8138\n",
            "Epoch 31/300\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.5239 - accuracy: 0.8308 - val_loss: 0.6013 - val_accuracy: 0.8065\n",
            "Epoch 32/300\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.4920 - accuracy: 0.8450 - val_loss: 0.6237 - val_accuracy: 0.8109\n",
            "Epoch 33/300\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.5433 - accuracy: 0.8236 - val_loss: 0.6135 - val_accuracy: 0.8174\n",
            "Epoch 34/300\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.4962 - accuracy: 0.8357 - val_loss: 0.6252 - val_accuracy: 0.8167\n",
            "Epoch 35/300\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.5007 - accuracy: 0.8275 - val_loss: 0.6214 - val_accuracy: 0.8196\n",
            "Epoch 36/300\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.4857 - accuracy: 0.8436 - val_loss: 0.6259 - val_accuracy: 0.8065\n",
            "Epoch 37/300\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.4802 - accuracy: 0.8447 - val_loss: 0.6025 - val_accuracy: 0.8225\n",
            "Epoch 38/300\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.4413 - accuracy: 0.8526 - val_loss: 0.6296 - val_accuracy: 0.8109\n",
            "Epoch 39/300\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.4656 - accuracy: 0.8462 - val_loss: 0.6211 - val_accuracy: 0.8138\n",
            "Epoch 40/300\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.4557 - accuracy: 0.8536 - val_loss: 0.6180 - val_accuracy: 0.8109\n",
            "Epoch 41/300\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.4492 - accuracy: 0.8510 - val_loss: 0.6390 - val_accuracy: 0.8116\n",
            "Epoch 42/300\n",
            "130/130 [==============================] - 1s 8ms/step - loss: 0.4340 - accuracy: 0.8533 - val_loss: 0.5886 - val_accuracy: 0.8217\n",
            "Epoch 43/300\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.4404 - accuracy: 0.8476 - val_loss: 0.5944 - val_accuracy: 0.8203\n",
            "Epoch 44/300\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.4552 - accuracy: 0.8510 - val_loss: 0.6168 - val_accuracy: 0.8087\n",
            "Epoch 45/300\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.4298 - accuracy: 0.8641 - val_loss: 0.5894 - val_accuracy: 0.8181\n",
            "Epoch 46/300\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.4267 - accuracy: 0.8580 - val_loss: 0.6186 - val_accuracy: 0.8210\n",
            "Epoch 47/300\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.4462 - accuracy: 0.8544 - val_loss: 0.5955 - val_accuracy: 0.8152\n",
            "Epoch 48/300\n",
            "130/130 [==============================] - 1s 8ms/step - loss: 0.4296 - accuracy: 0.8588 - val_loss: 0.6353 - val_accuracy: 0.8145\n",
            "Epoch 49/300\n",
            "130/130 [==============================] - 1s 8ms/step - loss: 0.4173 - accuracy: 0.8587 - val_loss: 0.6200 - val_accuracy: 0.8254\n",
            "Epoch 50/300\n",
            "130/130 [==============================] - 1s 8ms/step - loss: 0.4057 - accuracy: 0.8578 - val_loss: 0.6025 - val_accuracy: 0.8254\n",
            "Epoch 51/300\n",
            "130/130 [==============================] - 1s 8ms/step - loss: 0.4139 - accuracy: 0.8594 - val_loss: 0.6172 - val_accuracy: 0.8217\n",
            "Epoch 52/300\n",
            "130/130 [==============================] - 1s 8ms/step - loss: 0.4075 - accuracy: 0.8711 - val_loss: 0.5900 - val_accuracy: 0.8304\n",
            "Epoch 53/300\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.3937 - accuracy: 0.8698 - val_loss: 0.6001 - val_accuracy: 0.8297\n",
            "Epoch 54/300\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.4023 - accuracy: 0.8619 - val_loss: 0.6429 - val_accuracy: 0.8152\n",
            "Epoch 55/300\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.4048 - accuracy: 0.8635 - val_loss: 0.5918 - val_accuracy: 0.8217\n",
            "Epoch 56/300\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.4195 - accuracy: 0.8568 - val_loss: 0.6238 - val_accuracy: 0.8225\n",
            "Epoch 57/300\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.3991 - accuracy: 0.8734 - val_loss: 0.5948 - val_accuracy: 0.8239\n",
            "Epoch 58/300\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.3568 - accuracy: 0.8779 - val_loss: 0.6234 - val_accuracy: 0.8312\n",
            "Epoch 59/300\n",
            "130/130 [==============================] - 1s 8ms/step - loss: 0.4060 - accuracy: 0.8631 - val_loss: 0.6416 - val_accuracy: 0.8225\n",
            "Epoch 60/300\n",
            "130/130 [==============================] - 1s 8ms/step - loss: 0.4011 - accuracy: 0.8633 - val_loss: 0.6490 - val_accuracy: 0.8138\n",
            "Epoch 61/300\n",
            "130/130 [==============================] - 1s 8ms/step - loss: 0.4032 - accuracy: 0.8676 - val_loss: 0.6295 - val_accuracy: 0.8261\n",
            "Epoch 62/300\n",
            "130/130 [==============================] - 1s 8ms/step - loss: 0.4308 - accuracy: 0.8629 - val_loss: 0.6100 - val_accuracy: 0.8203\n",
            "Epoch 63/300\n",
            "130/130 [==============================] - 1s 9ms/step - loss: 0.4049 - accuracy: 0.8658 - val_loss: 0.6233 - val_accuracy: 0.8159\n",
            "Epoch 64/300\n",
            "130/130 [==============================] - 1s 10ms/step - loss: 0.3578 - accuracy: 0.8847 - val_loss: 0.6260 - val_accuracy: 0.8246\n",
            "Epoch 65/300\n",
            "130/130 [==============================] - 1s 9ms/step - loss: 0.4014 - accuracy: 0.8609 - val_loss: 0.6505 - val_accuracy: 0.8152\n",
            "Epoch 66/300\n",
            "130/130 [==============================] - 1s 10ms/step - loss: 0.3906 - accuracy: 0.8704 - val_loss: 0.6383 - val_accuracy: 0.8239\n",
            "Epoch 67/300\n",
            "130/130 [==============================] - 1s 9ms/step - loss: 0.3709 - accuracy: 0.8725 - val_loss: 0.6158 - val_accuracy: 0.8225\n",
            "Epoch 68/300\n",
            "130/130 [==============================] - 1s 10ms/step - loss: 0.3950 - accuracy: 0.8661 - val_loss: 0.6347 - val_accuracy: 0.8188\n",
            "Epoch 69/300\n",
            "130/130 [==============================] - 1s 10ms/step - loss: 0.3669 - accuracy: 0.8754 - val_loss: 0.6152 - val_accuracy: 0.8341\n",
            "Epoch 70/300\n",
            "130/130 [==============================] - 1s 10ms/step - loss: 0.3483 - accuracy: 0.8859 - val_loss: 0.6626 - val_accuracy: 0.8217\n",
            "Epoch 71/300\n",
            "130/130 [==============================] - 1s 9ms/step - loss: 0.4031 - accuracy: 0.8768 - val_loss: 0.6261 - val_accuracy: 0.8312\n",
            "Epoch 72/300\n",
            "130/130 [==============================] - 1s 9ms/step - loss: 0.3472 - accuracy: 0.8870 - val_loss: 0.6346 - val_accuracy: 0.8210\n",
            "Epoch 73/300\n",
            "130/130 [==============================] - 1s 10ms/step - loss: 0.3582 - accuracy: 0.8792 - val_loss: 0.6589 - val_accuracy: 0.8159\n",
            "Epoch 74/300\n",
            "130/130 [==============================] - 1s 11ms/step - loss: 0.3523 - accuracy: 0.8780 - val_loss: 0.6370 - val_accuracy: 0.8188\n",
            "Epoch 75/300\n",
            "130/130 [==============================] - 1s 9ms/step - loss: 0.3174 - accuracy: 0.9016 - val_loss: 0.6240 - val_accuracy: 0.8261\n",
            "Epoch 76/300\n",
            "130/130 [==============================] - 1s 9ms/step - loss: 0.3548 - accuracy: 0.8830 - val_loss: 0.6283 - val_accuracy: 0.8232\n",
            "Epoch 77/300\n",
            "130/130 [==============================] - 1s 8ms/step - loss: 0.3395 - accuracy: 0.8867 - val_loss: 0.6353 - val_accuracy: 0.8261\n",
            "Epoch 78/300\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.3404 - accuracy: 0.8799 - val_loss: 0.6157 - val_accuracy: 0.8348\n",
            "Epoch 79/300\n",
            "130/130 [==============================] - 1s 11ms/step - loss: 0.2995 - accuracy: 0.8956 - val_loss: 0.6157 - val_accuracy: 0.8181\n",
            "Epoch 80/300\n",
            "130/130 [==============================] - 1s 9ms/step - loss: 0.3457 - accuracy: 0.8896 - val_loss: 0.6169 - val_accuracy: 0.8333\n",
            "Epoch 81/300\n",
            "130/130 [==============================] - 1s 8ms/step - loss: 0.3279 - accuracy: 0.8914 - val_loss: 0.6144 - val_accuracy: 0.8203\n",
            "Epoch 82/300\n",
            "130/130 [==============================] - 1s 9ms/step - loss: 0.3248 - accuracy: 0.8948 - val_loss: 0.6258 - val_accuracy: 0.8275\n",
            "3\n",
            "model 0\n",
            "Epoch 1/300\n",
            "9/9 [==============================] - 5s 272ms/step - loss: 2.2472 - accuracy: 0.1453 - val_loss: 2.0825 - val_accuracy: 0.2131\n",
            "Epoch 2/300\n",
            "9/9 [==============================] - 2s 235ms/step - loss: 2.0951 - accuracy: 0.2172 - val_loss: 1.9839 - val_accuracy: 0.2625\n",
            "Epoch 3/300\n",
            "9/9 [==============================] - 2s 246ms/step - loss: 1.9724 - accuracy: 0.2679 - val_loss: 1.8755 - val_accuracy: 0.2974\n",
            "Epoch 4/300\n",
            "9/9 [==============================] - 2s 238ms/step - loss: 1.8625 - accuracy: 0.3080 - val_loss: 1.8368 - val_accuracy: 0.3217\n",
            "Epoch 5/300\n",
            "9/9 [==============================] - 2s 235ms/step - loss: 1.8043 - accuracy: 0.3413 - val_loss: 1.7071 - val_accuracy: 0.3607\n",
            "Epoch 6/300\n",
            "9/9 [==============================] - 2s 241ms/step - loss: 1.6910 - accuracy: 0.3747 - val_loss: 1.6577 - val_accuracy: 0.3893\n",
            "Epoch 7/300\n",
            "9/9 [==============================] - 2s 240ms/step - loss: 1.6099 - accuracy: 0.4334 - val_loss: 1.4775 - val_accuracy: 0.4526\n",
            "Epoch 8/300\n",
            "9/9 [==============================] - 2s 223ms/step - loss: 1.4686 - accuracy: 0.4780 - val_loss: 1.3713 - val_accuracy: 0.5244\n",
            "Epoch 9/300\n",
            "9/9 [==============================] - 2s 210ms/step - loss: 1.3160 - accuracy: 0.5370 - val_loss: 1.3396 - val_accuracy: 0.5279\n",
            "Epoch 10/300\n",
            "9/9 [==============================] - 2s 214ms/step - loss: 1.2441 - accuracy: 0.5805 - val_loss: 1.1953 - val_accuracy: 0.5954\n",
            "Epoch 11/300\n",
            "9/9 [==============================] - 2s 219ms/step - loss: 1.0972 - accuracy: 0.6305 - val_loss: 1.0512 - val_accuracy: 0.6602\n",
            "Epoch 12/300\n",
            "9/9 [==============================] - 2s 220ms/step - loss: 1.0197 - accuracy: 0.6580 - val_loss: 1.0160 - val_accuracy: 0.6762\n",
            "Epoch 13/300\n",
            "9/9 [==============================] - 2s 219ms/step - loss: 0.9460 - accuracy: 0.6972 - val_loss: 1.0316 - val_accuracy: 0.6609\n",
            "Epoch 14/300\n",
            "9/9 [==============================] - 2s 209ms/step - loss: 0.8646 - accuracy: 0.7230 - val_loss: 0.8788 - val_accuracy: 0.7298\n",
            "Epoch 15/300\n",
            "9/9 [==============================] - 2s 204ms/step - loss: 0.7867 - accuracy: 0.7556 - val_loss: 0.9062 - val_accuracy: 0.7138\n",
            "Epoch 16/300\n",
            "9/9 [==============================] - 2s 215ms/step - loss: 0.7546 - accuracy: 0.7634 - val_loss: 0.8190 - val_accuracy: 0.7451\n",
            "Epoch 17/300\n",
            "9/9 [==============================] - 2s 204ms/step - loss: 0.6663 - accuracy: 0.8013 - val_loss: 0.8255 - val_accuracy: 0.7535\n",
            "Epoch 18/300\n",
            "9/9 [==============================] - 2s 204ms/step - loss: 0.6551 - accuracy: 0.8036 - val_loss: 0.8182 - val_accuracy: 0.7549\n",
            "Epoch 19/300\n",
            "9/9 [==============================] - 2s 208ms/step - loss: 0.6344 - accuracy: 0.8044 - val_loss: 0.7986 - val_accuracy: 0.7625\n",
            "Epoch 20/300\n",
            "9/9 [==============================] - 2s 218ms/step - loss: 0.5508 - accuracy: 0.8382 - val_loss: 0.7278 - val_accuracy: 0.7862\n",
            "Epoch 21/300\n",
            "9/9 [==============================] - 2s 219ms/step - loss: 0.4929 - accuracy: 0.8544 - val_loss: 0.7424 - val_accuracy: 0.7813\n",
            "Epoch 22/300\n",
            "9/9 [==============================] - 2s 233ms/step - loss: 0.4550 - accuracy: 0.8673 - val_loss: 0.6885 - val_accuracy: 0.7911\n",
            "Epoch 23/300\n",
            "9/9 [==============================] - 2s 215ms/step - loss: 0.4250 - accuracy: 0.8779 - val_loss: 0.7342 - val_accuracy: 0.7813\n",
            "Epoch 24/300\n",
            "9/9 [==============================] - 2s 214ms/step - loss: 0.4153 - accuracy: 0.8766 - val_loss: 0.7012 - val_accuracy: 0.7960\n",
            "Epoch 25/300\n",
            "9/9 [==============================] - 2s 205ms/step - loss: 0.3861 - accuracy: 0.8832 - val_loss: 0.7143 - val_accuracy: 0.8015\n",
            "Epoch 26/300\n",
            "9/9 [==============================] - 2s 205ms/step - loss: 0.3717 - accuracy: 0.8935 - val_loss: 0.6990 - val_accuracy: 0.7974\n",
            "Epoch 27/300\n",
            "9/9 [==============================] - 2s 214ms/step - loss: 0.3083 - accuracy: 0.9087 - val_loss: 0.7231 - val_accuracy: 0.7967\n",
            "Epoch 28/300\n",
            "9/9 [==============================] - 2s 206ms/step - loss: 0.2862 - accuracy: 0.9190 - val_loss: 0.7060 - val_accuracy: 0.7904\n",
            "Epoch 29/300\n",
            "9/9 [==============================] - 2s 205ms/step - loss: 0.2790 - accuracy: 0.9183 - val_loss: 0.7834 - val_accuracy: 0.7827\n",
            "Epoch 30/300\n",
            "9/9 [==============================] - 2s 204ms/step - loss: 0.2720 - accuracy: 0.9153 - val_loss: 0.7652 - val_accuracy: 0.7960\n",
            "Epoch 31/300\n",
            "9/9 [==============================] - 2s 205ms/step - loss: 0.2546 - accuracy: 0.9231 - val_loss: 0.7394 - val_accuracy: 0.7953\n",
            "Epoch 32/300\n",
            "9/9 [==============================] - 2s 209ms/step - loss: 0.2237 - accuracy: 0.9343 - val_loss: 0.7184 - val_accuracy: 0.8001\n",
            "Epoch 33/300\n",
            "9/9 [==============================] - 2s 204ms/step - loss: 0.2029 - accuracy: 0.9424 - val_loss: 0.7463 - val_accuracy: 0.8092\n",
            "Epoch 34/300\n",
            "9/9 [==============================] - 2s 203ms/step - loss: 0.2133 - accuracy: 0.9351 - val_loss: 0.7241 - val_accuracy: 0.8169\n",
            "Epoch 35/300\n",
            "9/9 [==============================] - 2s 203ms/step - loss: 0.1988 - accuracy: 0.9437 - val_loss: 0.7361 - val_accuracy: 0.8134\n",
            "Epoch 36/300\n",
            "9/9 [==============================] - 2s 202ms/step - loss: 0.1515 - accuracy: 0.9604 - val_loss: 0.7477 - val_accuracy: 0.8057\n",
            "Epoch 37/300\n",
            "9/9 [==============================] - 2s 203ms/step - loss: 0.1525 - accuracy: 0.9557 - val_loss: 0.7786 - val_accuracy: 0.8113\n",
            "Epoch 38/300\n",
            "9/9 [==============================] - 2s 205ms/step - loss: 0.1509 - accuracy: 0.9553 - val_loss: 0.7581 - val_accuracy: 0.8092\n",
            "Epoch 39/300\n",
            "9/9 [==============================] - 2s 202ms/step - loss: 0.1144 - accuracy: 0.9708 - val_loss: 0.7423 - val_accuracy: 0.8113\n",
            "Epoch 40/300\n",
            "9/9 [==============================] - 2s 205ms/step - loss: 0.1093 - accuracy: 0.9728 - val_loss: 0.7846 - val_accuracy: 0.8141\n",
            "Epoch 41/300\n",
            "9/9 [==============================] - 2s 203ms/step - loss: 0.1036 - accuracy: 0.9724 - val_loss: 0.8663 - val_accuracy: 0.8001\n",
            "Epoch 42/300\n",
            "9/9 [==============================] - 2s 204ms/step - loss: 0.1093 - accuracy: 0.9714 - val_loss: 0.9031 - val_accuracy: 0.7974\n",
            "Epoch 43/300\n",
            "9/9 [==============================] - 2s 205ms/step - loss: 0.1473 - accuracy: 0.9473 - val_loss: 0.9871 - val_accuracy: 0.7792\n",
            "Epoch 44/300\n",
            "9/9 [==============================] - 2s 203ms/step - loss: 0.1555 - accuracy: 0.9450 - val_loss: 0.8724 - val_accuracy: 0.8057\n",
            "Epoch 45/300\n",
            "9/9 [==============================] - 2s 201ms/step - loss: 0.1299 - accuracy: 0.9602 - val_loss: 0.8314 - val_accuracy: 0.8182\n",
            "Epoch 46/300\n",
            "9/9 [==============================] - 2s 204ms/step - loss: 0.1010 - accuracy: 0.9708 - val_loss: 0.8399 - val_accuracy: 0.8210\n",
            "Epoch 47/300\n",
            "9/9 [==============================] - 2s 205ms/step - loss: 0.0834 - accuracy: 0.9783 - val_loss: 0.8045 - val_accuracy: 0.8196\n",
            "Epoch 48/300\n",
            "9/9 [==============================] - 2s 201ms/step - loss: 0.0679 - accuracy: 0.9835 - val_loss: 0.9049 - val_accuracy: 0.8064\n",
            "Epoch 49/300\n",
            "9/9 [==============================] - 2s 202ms/step - loss: 0.0801 - accuracy: 0.9732 - val_loss: 0.8545 - val_accuracy: 0.8196\n",
            "Epoch 50/300\n",
            "9/9 [==============================] - 2s 204ms/step - loss: 0.0572 - accuracy: 0.9855 - val_loss: 0.8698 - val_accuracy: 0.8182\n",
            "Epoch 51/300\n",
            "9/9 [==============================] - 2s 218ms/step - loss: 0.0446 - accuracy: 0.9896 - val_loss: 0.8945 - val_accuracy: 0.8189\n",
            "Epoch 52/300\n",
            "9/9 [==============================] - 2s 214ms/step - loss: 0.0526 - accuracy: 0.9875 - val_loss: 0.9098 - val_accuracy: 0.8148\n",
            "Epoch 53/300\n",
            "9/9 [==============================] - 2s 206ms/step - loss: 0.0376 - accuracy: 0.9924 - val_loss: 0.9467 - val_accuracy: 0.8148\n",
            "Epoch 54/300\n",
            "9/9 [==============================] - 2s 202ms/step - loss: 0.0394 - accuracy: 0.9909 - val_loss: 0.9192 - val_accuracy: 0.8189\n",
            "Epoch 55/300\n",
            "9/9 [==============================] - 2s 206ms/step - loss: 0.0344 - accuracy: 0.9913 - val_loss: 0.9559 - val_accuracy: 0.8189\n",
            "Epoch 56/300\n",
            "9/9 [==============================] - 2s 206ms/step - loss: 0.0286 - accuracy: 0.9968 - val_loss: 0.9364 - val_accuracy: 0.8175\n",
            "Epoch 57/300\n",
            "9/9 [==============================] - 2s 205ms/step - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.9581 - val_accuracy: 0.8189\n",
            "Epoch 58/300\n",
            "9/9 [==============================] - 2s 204ms/step - loss: 0.0216 - accuracy: 0.9972 - val_loss: 0.9965 - val_accuracy: 0.8141\n",
            "Epoch 59/300\n",
            "9/9 [==============================] - 2s 207ms/step - loss: 0.0238 - accuracy: 0.9964 - val_loss: 0.9945 - val_accuracy: 0.8162\n",
            "Epoch 60/300\n",
            "9/9 [==============================] - 2s 203ms/step - loss: 0.0225 - accuracy: 0.9959 - val_loss: 1.0313 - val_accuracy: 0.8169\n",
            "Epoch 61/300\n",
            "9/9 [==============================] - 2s 217ms/step - loss: 0.0184 - accuracy: 0.9961 - val_loss: 1.0173 - val_accuracy: 0.8182\n",
            "Epoch 62/300\n",
            "9/9 [==============================] - 2s 203ms/step - loss: 0.0194 - accuracy: 0.9963 - val_loss: 1.0443 - val_accuracy: 0.8169\n",
            "model 1\n",
            "Epoch 1/300\n",
            "9/9 [==============================] - 5s 398ms/step - loss: 2.2636 - accuracy: 0.1541 - val_loss: 2.0422 - val_accuracy: 0.2465\n",
            "Epoch 2/300\n",
            "9/9 [==============================] - 3s 326ms/step - loss: 1.9878 - accuracy: 0.3003 - val_loss: 1.7961 - val_accuracy: 0.4053\n",
            "Epoch 3/300\n",
            "9/9 [==============================] - 3s 328ms/step - loss: 1.7621 - accuracy: 0.3923 - val_loss: 1.5550 - val_accuracy: 0.4812\n",
            "Epoch 4/300\n",
            "9/9 [==============================] - 3s 332ms/step - loss: 1.5672 - accuracy: 0.4737 - val_loss: 1.4030 - val_accuracy: 0.5641\n",
            "Epoch 5/300\n",
            "9/9 [==============================] - 3s 313ms/step - loss: 1.4399 - accuracy: 0.5285 - val_loss: 1.2841 - val_accuracy: 0.6052\n",
            "Epoch 6/300\n",
            "9/9 [==============================] - 3s 309ms/step - loss: 1.3222 - accuracy: 0.5656 - val_loss: 1.1937 - val_accuracy: 0.6184\n",
            "Epoch 7/300\n",
            "9/9 [==============================] - 3s 318ms/step - loss: 1.2497 - accuracy: 0.5865 - val_loss: 1.1120 - val_accuracy: 0.6455\n",
            "Epoch 8/300\n",
            "9/9 [==============================] - 3s 312ms/step - loss: 1.1513 - accuracy: 0.6292 - val_loss: 1.0518 - val_accuracy: 0.6825\n",
            "Epoch 9/300\n",
            "9/9 [==============================] - 3s 314ms/step - loss: 1.1164 - accuracy: 0.6417 - val_loss: 1.0503 - val_accuracy: 0.6825\n",
            "Epoch 10/300\n",
            "9/9 [==============================] - 3s 308ms/step - loss: 1.0836 - accuracy: 0.6590 - val_loss: 0.9501 - val_accuracy: 0.7180\n",
            "Epoch 11/300\n",
            "9/9 [==============================] - 3s 313ms/step - loss: 1.0327 - accuracy: 0.6657 - val_loss: 0.9084 - val_accuracy: 0.7270\n",
            "Epoch 12/300\n",
            "9/9 [==============================] - 3s 315ms/step - loss: 0.9879 - accuracy: 0.6821 - val_loss: 0.8760 - val_accuracy: 0.7396\n",
            "Epoch 13/300\n",
            "9/9 [==============================] - 3s 312ms/step - loss: 0.9488 - accuracy: 0.6961 - val_loss: 0.8392 - val_accuracy: 0.7521\n",
            "Epoch 14/300\n",
            "9/9 [==============================] - 3s 321ms/step - loss: 0.8994 - accuracy: 0.7182 - val_loss: 0.8139 - val_accuracy: 0.7667\n",
            "Epoch 15/300\n",
            "9/9 [==============================] - 3s 313ms/step - loss: 0.8954 - accuracy: 0.7152 - val_loss: 0.7696 - val_accuracy: 0.7904\n",
            "Epoch 16/300\n",
            "9/9 [==============================] - 3s 312ms/step - loss: 0.8643 - accuracy: 0.7190 - val_loss: 0.7488 - val_accuracy: 0.7792\n",
            "Epoch 17/300\n",
            "9/9 [==============================] - 3s 312ms/step - loss: 0.8030 - accuracy: 0.7436 - val_loss: 0.7156 - val_accuracy: 0.7918\n",
            "Epoch 18/300\n",
            "9/9 [==============================] - 3s 314ms/step - loss: 0.7856 - accuracy: 0.7487 - val_loss: 0.7097 - val_accuracy: 0.7911\n",
            "Epoch 19/300\n",
            "9/9 [==============================] - 3s 311ms/step - loss: 0.7647 - accuracy: 0.7557 - val_loss: 0.6962 - val_accuracy: 0.7981\n",
            "Epoch 20/300\n",
            "9/9 [==============================] - 3s 312ms/step - loss: 0.7621 - accuracy: 0.7543 - val_loss: 0.6797 - val_accuracy: 0.7981\n",
            "Epoch 21/300\n",
            "9/9 [==============================] - 3s 311ms/step - loss: 0.7187 - accuracy: 0.7732 - val_loss: 0.6477 - val_accuracy: 0.8085\n",
            "Epoch 22/300\n",
            "9/9 [==============================] - 3s 307ms/step - loss: 0.7165 - accuracy: 0.7614 - val_loss: 0.6101 - val_accuracy: 0.8141\n",
            "Epoch 23/300\n",
            "9/9 [==============================] - 3s 308ms/step - loss: 0.6628 - accuracy: 0.7899 - val_loss: 0.6033 - val_accuracy: 0.8148\n",
            "Epoch 24/300\n",
            "9/9 [==============================] - 3s 307ms/step - loss: 0.6516 - accuracy: 0.7874 - val_loss: 0.6013 - val_accuracy: 0.8155\n",
            "Epoch 25/300\n",
            "9/9 [==============================] - 3s 308ms/step - loss: 0.6190 - accuracy: 0.8011 - val_loss: 0.5723 - val_accuracy: 0.8280\n",
            "Epoch 26/300\n",
            "9/9 [==============================] - 3s 308ms/step - loss: 0.5884 - accuracy: 0.8097 - val_loss: 0.5575 - val_accuracy: 0.8280\n",
            "Epoch 27/300\n",
            "9/9 [==============================] - 3s 306ms/step - loss: 0.5811 - accuracy: 0.8132 - val_loss: 0.5563 - val_accuracy: 0.8252\n",
            "Epoch 28/300\n",
            "9/9 [==============================] - 3s 304ms/step - loss: 0.5944 - accuracy: 0.8054 - val_loss: 0.5857 - val_accuracy: 0.8245\n",
            "Epoch 29/300\n",
            "9/9 [==============================] - 3s 307ms/step - loss: 0.5789 - accuracy: 0.8211 - val_loss: 0.5744 - val_accuracy: 0.8259\n",
            "Epoch 30/300\n",
            "9/9 [==============================] - 3s 311ms/step - loss: 0.5650 - accuracy: 0.8183 - val_loss: 0.5475 - val_accuracy: 0.8252\n",
            "Epoch 31/300\n",
            "9/9 [==============================] - 3s 301ms/step - loss: 0.5274 - accuracy: 0.8294 - val_loss: 0.5289 - val_accuracy: 0.8398\n",
            "Epoch 32/300\n",
            "9/9 [==============================] - 3s 302ms/step - loss: 0.5279 - accuracy: 0.8273 - val_loss: 0.5225 - val_accuracy: 0.8398\n",
            "Epoch 33/300\n",
            "9/9 [==============================] - 3s 307ms/step - loss: 0.5105 - accuracy: 0.8354 - val_loss: 0.5054 - val_accuracy: 0.8461\n",
            "Epoch 34/300\n",
            "9/9 [==============================] - 3s 299ms/step - loss: 0.4825 - accuracy: 0.8424 - val_loss: 0.5370 - val_accuracy: 0.8405\n",
            "Epoch 35/300\n",
            "9/9 [==============================] - 3s 307ms/step - loss: 0.4987 - accuracy: 0.8401 - val_loss: 0.4956 - val_accuracy: 0.8531\n",
            "Epoch 36/300\n",
            "9/9 [==============================] - 3s 314ms/step - loss: 0.4706 - accuracy: 0.8444 - val_loss: 0.4798 - val_accuracy: 0.8579\n",
            "Epoch 37/300\n",
            "9/9 [==============================] - 3s 314ms/step - loss: 0.4586 - accuracy: 0.8511 - val_loss: 0.4971 - val_accuracy: 0.8531\n",
            "Epoch 38/300\n",
            "9/9 [==============================] - 3s 305ms/step - loss: 0.4453 - accuracy: 0.8529 - val_loss: 0.4768 - val_accuracy: 0.8586\n",
            "Epoch 39/300\n",
            "9/9 [==============================] - 3s 301ms/step - loss: 0.4286 - accuracy: 0.8567 - val_loss: 0.4879 - val_accuracy: 0.8586\n",
            "Epoch 40/300\n",
            "9/9 [==============================] - 3s 305ms/step - loss: 0.4587 - accuracy: 0.8456 - val_loss: 0.4780 - val_accuracy: 0.8482\n",
            "Epoch 41/300\n",
            "9/9 [==============================] - 3s 302ms/step - loss: 0.4136 - accuracy: 0.8680 - val_loss: 0.4927 - val_accuracy: 0.8503\n",
            "Epoch 42/300\n",
            "9/9 [==============================] - 3s 306ms/step - loss: 0.4187 - accuracy: 0.8620 - val_loss: 0.4798 - val_accuracy: 0.8538\n",
            "Epoch 43/300\n",
            "9/9 [==============================] - 3s 302ms/step - loss: 0.3902 - accuracy: 0.8704 - val_loss: 0.4633 - val_accuracy: 0.8607\n",
            "Epoch 44/300\n",
            "9/9 [==============================] - 3s 303ms/step - loss: 0.4188 - accuracy: 0.8673 - val_loss: 0.4597 - val_accuracy: 0.8607\n",
            "Epoch 45/300\n",
            "9/9 [==============================] - 3s 307ms/step - loss: 0.3759 - accuracy: 0.8738 - val_loss: 0.4597 - val_accuracy: 0.8656\n",
            "Epoch 46/300\n",
            "9/9 [==============================] - 3s 304ms/step - loss: 0.3672 - accuracy: 0.8766 - val_loss: 0.4522 - val_accuracy: 0.8635\n",
            "Epoch 47/300\n",
            "9/9 [==============================] - 3s 307ms/step - loss: 0.3473 - accuracy: 0.8789 - val_loss: 0.4575 - val_accuracy: 0.8579\n",
            "Epoch 48/300\n",
            "9/9 [==============================] - 3s 304ms/step - loss: 0.3410 - accuracy: 0.8844 - val_loss: 0.4419 - val_accuracy: 0.8663\n",
            "Epoch 49/300\n",
            "9/9 [==============================] - 3s 309ms/step - loss: 0.3552 - accuracy: 0.8811 - val_loss: 0.4367 - val_accuracy: 0.8726\n",
            "Epoch 50/300\n",
            "9/9 [==============================] - 3s 313ms/step - loss: 0.3365 - accuracy: 0.8910 - val_loss: 0.4496 - val_accuracy: 0.8586\n",
            "Epoch 51/300\n",
            "9/9 [==============================] - 3s 307ms/step - loss: 0.3098 - accuracy: 0.8942 - val_loss: 0.4526 - val_accuracy: 0.8642\n",
            "Epoch 52/300\n",
            "9/9 [==============================] - 3s 326ms/step - loss: 0.3009 - accuracy: 0.8998 - val_loss: 0.4644 - val_accuracy: 0.8579\n",
            "Epoch 53/300\n",
            "9/9 [==============================] - 3s 303ms/step - loss: 0.3455 - accuracy: 0.8842 - val_loss: 0.4419 - val_accuracy: 0.8677\n",
            "Epoch 54/300\n",
            "9/9 [==============================] - 3s 301ms/step - loss: 0.3019 - accuracy: 0.8997 - val_loss: 0.4423 - val_accuracy: 0.8614\n",
            "Epoch 55/300\n",
            "9/9 [==============================] - 3s 306ms/step - loss: 0.3307 - accuracy: 0.8893 - val_loss: 0.4532 - val_accuracy: 0.8558\n",
            "Epoch 56/300\n",
            "9/9 [==============================] - 3s 308ms/step - loss: 0.3185 - accuracy: 0.8948 - val_loss: 0.4380 - val_accuracy: 0.8684\n",
            "Epoch 57/300\n",
            "9/9 [==============================] - 3s 306ms/step - loss: 0.2773 - accuracy: 0.9065 - val_loss: 0.4537 - val_accuracy: 0.8614\n",
            "Epoch 58/300\n",
            "9/9 [==============================] - 3s 310ms/step - loss: 0.2979 - accuracy: 0.8985 - val_loss: 0.4517 - val_accuracy: 0.8670\n",
            "Epoch 59/300\n",
            "9/9 [==============================] - 3s 314ms/step - loss: 0.2991 - accuracy: 0.8989 - val_loss: 0.4475 - val_accuracy: 0.8670\n",
            "Epoch 60/300\n",
            "9/9 [==============================] - 3s 317ms/step - loss: 0.2840 - accuracy: 0.9066 - val_loss: 0.4539 - val_accuracy: 0.8565\n",
            "Epoch 61/300\n",
            "9/9 [==============================] - 3s 309ms/step - loss: 0.2653 - accuracy: 0.9086 - val_loss: 0.4855 - val_accuracy: 0.8565\n",
            "Epoch 62/300\n",
            "9/9 [==============================] - 3s 309ms/step - loss: 0.2655 - accuracy: 0.9101 - val_loss: 0.4504 - val_accuracy: 0.8705\n",
            "Epoch 63/300\n",
            "9/9 [==============================] - 3s 317ms/step - loss: 0.2425 - accuracy: 0.9157 - val_loss: 0.4597 - val_accuracy: 0.8621\n",
            "Epoch 64/300\n",
            "9/9 [==============================] - 3s 313ms/step - loss: 0.2713 - accuracy: 0.9032 - val_loss: 0.4470 - val_accuracy: 0.8684\n",
            "Epoch 65/300\n",
            "9/9 [==============================] - 3s 312ms/step - loss: 0.2587 - accuracy: 0.9163 - val_loss: 0.4384 - val_accuracy: 0.8684\n",
            "Epoch 66/300\n",
            "9/9 [==============================] - 3s 320ms/step - loss: 0.2384 - accuracy: 0.9195 - val_loss: 0.4707 - val_accuracy: 0.8607\n",
            "Epoch 67/300\n",
            "9/9 [==============================] - 3s 318ms/step - loss: 0.2340 - accuracy: 0.9287 - val_loss: 0.4426 - val_accuracy: 0.8684\n",
            "Epoch 68/300\n",
            "9/9 [==============================] - 3s 328ms/step - loss: 0.2359 - accuracy: 0.9192 - val_loss: 0.4320 - val_accuracy: 0.8740\n",
            "Epoch 69/300\n",
            "9/9 [==============================] - 3s 342ms/step - loss: 0.2489 - accuracy: 0.9170 - val_loss: 0.4558 - val_accuracy: 0.8656\n",
            "Epoch 70/300\n",
            "9/9 [==============================] - 3s 345ms/step - loss: 0.2411 - accuracy: 0.9170 - val_loss: 0.4532 - val_accuracy: 0.8733\n",
            "Epoch 71/300\n",
            "9/9 [==============================] - 3s 366ms/step - loss: 0.2371 - accuracy: 0.9171 - val_loss: 0.4491 - val_accuracy: 0.8698\n",
            "Epoch 72/300\n",
            "9/9 [==============================] - 3s 373ms/step - loss: 0.2349 - accuracy: 0.9226 - val_loss: 0.4405 - val_accuracy: 0.8705\n",
            "Epoch 73/300\n",
            "9/9 [==============================] - 3s 367ms/step - loss: 0.2327 - accuracy: 0.9239 - val_loss: 0.4899 - val_accuracy: 0.8649\n",
            "Epoch 74/300\n",
            "9/9 [==============================] - 3s 373ms/step - loss: 0.2079 - accuracy: 0.9325 - val_loss: 0.4877 - val_accuracy: 0.8663\n",
            "Epoch 75/300\n",
            "9/9 [==============================] - 3s 350ms/step - loss: 0.2231 - accuracy: 0.9266 - val_loss: 0.4747 - val_accuracy: 0.8670\n",
            "Epoch 76/300\n",
            "9/9 [==============================] - 3s 368ms/step - loss: 0.2417 - accuracy: 0.9175 - val_loss: 0.4350 - val_accuracy: 0.8747\n",
            "Epoch 77/300\n",
            "9/9 [==============================] - 3s 342ms/step - loss: 0.2071 - accuracy: 0.9276 - val_loss: 0.4678 - val_accuracy: 0.8656\n",
            "Epoch 78/300\n",
            "9/9 [==============================] - 3s 358ms/step - loss: 0.2168 - accuracy: 0.9239 - val_loss: 0.4542 - val_accuracy: 0.8705\n",
            "Epoch 79/300\n",
            "9/9 [==============================] - 3s 366ms/step - loss: 0.2119 - accuracy: 0.9268 - val_loss: 0.4760 - val_accuracy: 0.8607\n",
            "Epoch 80/300\n",
            "9/9 [==============================] - 3s 376ms/step - loss: 0.1885 - accuracy: 0.9358 - val_loss: 0.4567 - val_accuracy: 0.8747\n",
            "Epoch 81/300\n",
            "9/9 [==============================] - 3s 373ms/step - loss: 0.1962 - accuracy: 0.9329 - val_loss: 0.4689 - val_accuracy: 0.8663\n",
            "Epoch 82/300\n",
            "9/9 [==============================] - 3s 388ms/step - loss: 0.1923 - accuracy: 0.9403 - val_loss: 0.4951 - val_accuracy: 0.8649\n",
            "Epoch 83/300\n",
            "9/9 [==============================] - 3s 350ms/step - loss: 0.2039 - accuracy: 0.9341 - val_loss: 0.4724 - val_accuracy: 0.8684\n",
            "Epoch 84/300\n",
            "9/9 [==============================] - 3s 334ms/step - loss: 0.1785 - accuracy: 0.9410 - val_loss: 0.4573 - val_accuracy: 0.8774\n",
            "Epoch 85/300\n",
            "9/9 [==============================] - 3s 353ms/step - loss: 0.1901 - accuracy: 0.9337 - val_loss: 0.4619 - val_accuracy: 0.8740\n",
            "Epoch 86/300\n",
            "9/9 [==============================] - 3s 365ms/step - loss: 0.1790 - accuracy: 0.9352 - val_loss: 0.4851 - val_accuracy: 0.8691\n",
            "Epoch 87/300\n",
            "9/9 [==============================] - 3s 349ms/step - loss: 0.1793 - accuracy: 0.9414 - val_loss: 0.4602 - val_accuracy: 0.8774\n",
            "Epoch 88/300\n",
            "9/9 [==============================] - 3s 350ms/step - loss: 0.1785 - accuracy: 0.9414 - val_loss: 0.4582 - val_accuracy: 0.8726\n",
            "Epoch 89/300\n",
            "9/9 [==============================] - 3s 324ms/step - loss: 0.1658 - accuracy: 0.9498 - val_loss: 0.4763 - val_accuracy: 0.8760\n",
            "Epoch 90/300\n",
            "9/9 [==============================] - 3s 358ms/step - loss: 0.1664 - accuracy: 0.9439 - val_loss: 0.4763 - val_accuracy: 0.8733\n",
            "Epoch 91/300\n",
            "9/9 [==============================] - 3s 334ms/step - loss: 0.1657 - accuracy: 0.9442 - val_loss: 0.4792 - val_accuracy: 0.8670\n",
            "Epoch 92/300\n",
            "9/9 [==============================] - 3s 351ms/step - loss: 0.1767 - accuracy: 0.9367 - val_loss: 0.4719 - val_accuracy: 0.8677\n",
            "Epoch 93/300\n",
            "9/9 [==============================] - 3s 331ms/step - loss: 0.1714 - accuracy: 0.9405 - val_loss: 0.4532 - val_accuracy: 0.8747\n",
            "Epoch 94/300\n",
            "9/9 [==============================] - 3s 321ms/step - loss: 0.1794 - accuracy: 0.9417 - val_loss: 0.4825 - val_accuracy: 0.8656\n",
            "Epoch 95/300\n",
            "9/9 [==============================] - 3s 326ms/step - loss: 0.1694 - accuracy: 0.9468 - val_loss: 0.4823 - val_accuracy: 0.8649\n",
            "Epoch 96/300\n",
            "9/9 [==============================] - 3s 336ms/step - loss: 0.1557 - accuracy: 0.9462 - val_loss: 0.4926 - val_accuracy: 0.8663\n",
            "Epoch 97/300\n",
            "9/9 [==============================] - 3s 329ms/step - loss: 0.1530 - accuracy: 0.9544 - val_loss: 0.4595 - val_accuracy: 0.8767\n",
            "Epoch 98/300\n",
            "9/9 [==============================] - 3s 340ms/step - loss: 0.1623 - accuracy: 0.9411 - val_loss: 0.4951 - val_accuracy: 0.8663\n",
            "Epoch 99/300\n",
            "9/9 [==============================] - 3s 327ms/step - loss: 0.1511 - accuracy: 0.9501 - val_loss: 0.4651 - val_accuracy: 0.8753\n",
            "Epoch 100/300\n",
            "9/9 [==============================] - 3s 329ms/step - loss: 0.1471 - accuracy: 0.9508 - val_loss: 0.4834 - val_accuracy: 0.8733\n",
            "Epoch 101/300\n",
            "9/9 [==============================] - 3s 326ms/step - loss: 0.1619 - accuracy: 0.9471 - val_loss: 0.4738 - val_accuracy: 0.8823\n",
            "Epoch 102/300\n",
            "9/9 [==============================] - 3s 337ms/step - loss: 0.1526 - accuracy: 0.9501 - val_loss: 0.4853 - val_accuracy: 0.8726\n",
            "Epoch 103/300\n",
            "9/9 [==============================] - 3s 333ms/step - loss: 0.1464 - accuracy: 0.9526 - val_loss: 0.4582 - val_accuracy: 0.8788\n",
            "Epoch 104/300\n",
            "9/9 [==============================] - 3s 321ms/step - loss: 0.1503 - accuracy: 0.9499 - val_loss: 0.4983 - val_accuracy: 0.8684\n",
            "Epoch 105/300\n",
            "9/9 [==============================] - 3s 311ms/step - loss: 0.1558 - accuracy: 0.9483 - val_loss: 0.4754 - val_accuracy: 0.8740\n",
            "Epoch 106/300\n",
            "9/9 [==============================] - 3s 319ms/step - loss: 0.1448 - accuracy: 0.9528 - val_loss: 0.4742 - val_accuracy: 0.8747\n",
            "Epoch 107/300\n",
            "9/9 [==============================] - 3s 316ms/step - loss: 0.1440 - accuracy: 0.9542 - val_loss: 0.4565 - val_accuracy: 0.8788\n",
            "Epoch 108/300\n",
            "9/9 [==============================] - 3s 316ms/step - loss: 0.1434 - accuracy: 0.9496 - val_loss: 0.4874 - val_accuracy: 0.8733\n",
            "model 2\n",
            "Epoch 1/300\n",
            "135/135 [==============================] - 1s 8ms/step - loss: 2.0630 - accuracy: 0.2599 - val_loss: 1.4582 - val_accuracy: 0.4944\n",
            "Epoch 2/300\n",
            "135/135 [==============================] - 1s 7ms/step - loss: 1.4197 - accuracy: 0.5232 - val_loss: 1.1355 - val_accuracy: 0.6309\n",
            "Epoch 3/300\n",
            "135/135 [==============================] - 1s 7ms/step - loss: 1.2045 - accuracy: 0.6018 - val_loss: 1.0141 - val_accuracy: 0.6769\n",
            "Epoch 4/300\n",
            "135/135 [==============================] - 1s 7ms/step - loss: 1.1150 - accuracy: 0.6343 - val_loss: 0.9968 - val_accuracy: 0.6664\n",
            "Epoch 5/300\n",
            "135/135 [==============================] - 1s 7ms/step - loss: 1.0407 - accuracy: 0.6658 - val_loss: 0.9273 - val_accuracy: 0.7194\n",
            "Epoch 6/300\n",
            "135/135 [==============================] - 1s 8ms/step - loss: 0.9355 - accuracy: 0.6897 - val_loss: 0.8373 - val_accuracy: 0.7403\n",
            "Epoch 7/300\n",
            "135/135 [==============================] - 1s 8ms/step - loss: 0.9146 - accuracy: 0.6921 - val_loss: 0.8374 - val_accuracy: 0.7472\n",
            "Epoch 8/300\n",
            "135/135 [==============================] - 1s 7ms/step - loss: 0.8805 - accuracy: 0.7247 - val_loss: 0.7894 - val_accuracy: 0.7611\n",
            "Epoch 9/300\n",
            "135/135 [==============================] - 1s 7ms/step - loss: 0.8156 - accuracy: 0.7443 - val_loss: 0.8015 - val_accuracy: 0.7577\n",
            "Epoch 10/300\n",
            "135/135 [==============================] - 1s 7ms/step - loss: 0.7848 - accuracy: 0.7482 - val_loss: 0.7658 - val_accuracy: 0.7660\n",
            "Epoch 11/300\n",
            "135/135 [==============================] - 1s 7ms/step - loss: 0.7612 - accuracy: 0.7493 - val_loss: 0.7286 - val_accuracy: 0.7876\n",
            "Epoch 12/300\n",
            "135/135 [==============================] - 1s 8ms/step - loss: 0.6979 - accuracy: 0.7745 - val_loss: 0.7256 - val_accuracy: 0.7820\n",
            "Epoch 13/300\n",
            "135/135 [==============================] - 1s 8ms/step - loss: 0.6941 - accuracy: 0.7820 - val_loss: 0.6973 - val_accuracy: 0.7876\n",
            "Epoch 14/300\n",
            "135/135 [==============================] - 1s 7ms/step - loss: 0.6595 - accuracy: 0.7844 - val_loss: 0.6721 - val_accuracy: 0.8015\n",
            "Epoch 15/300\n",
            "135/135 [==============================] - 1s 7ms/step - loss: 0.6766 - accuracy: 0.7800 - val_loss: 0.6697 - val_accuracy: 0.7981\n",
            "Epoch 16/300\n",
            "135/135 [==============================] - 1s 7ms/step - loss: 0.6412 - accuracy: 0.7936 - val_loss: 0.6906 - val_accuracy: 0.7911\n",
            "Epoch 17/300\n",
            "135/135 [==============================] - 1s 7ms/step - loss: 0.5987 - accuracy: 0.8079 - val_loss: 0.6761 - val_accuracy: 0.8071\n",
            "Epoch 18/300\n",
            "135/135 [==============================] - 1s 7ms/step - loss: 0.6214 - accuracy: 0.8047 - val_loss: 0.7106 - val_accuracy: 0.7897\n",
            "Epoch 19/300\n",
            "135/135 [==============================] - 1s 7ms/step - loss: 0.5985 - accuracy: 0.8024 - val_loss: 0.6524 - val_accuracy: 0.8078\n",
            "Epoch 20/300\n",
            "135/135 [==============================] - 1s 8ms/step - loss: 0.5489 - accuracy: 0.8189 - val_loss: 0.6129 - val_accuracy: 0.8169\n",
            "Epoch 21/300\n",
            "135/135 [==============================] - 1s 7ms/step - loss: 0.5508 - accuracy: 0.8196 - val_loss: 0.6795 - val_accuracy: 0.7981\n",
            "Epoch 22/300\n",
            "135/135 [==============================] - 1s 7ms/step - loss: 0.5366 - accuracy: 0.8230 - val_loss: 0.6431 - val_accuracy: 0.8057\n",
            "Epoch 23/300\n",
            "135/135 [==============================] - 1s 7ms/step - loss: 0.5035 - accuracy: 0.8402 - val_loss: 0.6245 - val_accuracy: 0.8148\n",
            "Epoch 24/300\n",
            "135/135 [==============================] - 1s 7ms/step - loss: 0.5156 - accuracy: 0.8306 - val_loss: 0.6190 - val_accuracy: 0.8141\n",
            "Epoch 25/300\n",
            "135/135 [==============================] - 1s 7ms/step - loss: 0.5173 - accuracy: 0.8418 - val_loss: 0.6371 - val_accuracy: 0.8064\n",
            "Epoch 26/300\n",
            "135/135 [==============================] - 1s 8ms/step - loss: 0.4893 - accuracy: 0.8376 - val_loss: 0.6173 - val_accuracy: 0.8169\n",
            "Epoch 27/300\n",
            "135/135 [==============================] - 1s 8ms/step - loss: 0.4894 - accuracy: 0.8426 - val_loss: 0.6175 - val_accuracy: 0.8182\n",
            "Epoch 28/300\n",
            "135/135 [==============================] - 1s 8ms/step - loss: 0.5037 - accuracy: 0.8354 - val_loss: 0.6235 - val_accuracy: 0.8120\n",
            "Epoch 29/300\n",
            "135/135 [==============================] - 1s 7ms/step - loss: 0.5009 - accuracy: 0.8316 - val_loss: 0.6111 - val_accuracy: 0.8196\n",
            "Epoch 30/300\n",
            "135/135 [==============================] - 1s 8ms/step - loss: 0.4811 - accuracy: 0.8322 - val_loss: 0.5946 - val_accuracy: 0.8266\n",
            "Epoch 31/300\n",
            "135/135 [==============================] - 1s 7ms/step - loss: 0.4705 - accuracy: 0.8420 - val_loss: 0.6110 - val_accuracy: 0.8245\n",
            "Epoch 32/300\n",
            "135/135 [==============================] - 1s 8ms/step - loss: 0.3998 - accuracy: 0.8681 - val_loss: 0.6052 - val_accuracy: 0.8252\n",
            "Epoch 33/300\n",
            "135/135 [==============================] - 1s 7ms/step - loss: 0.4437 - accuracy: 0.8561 - val_loss: 0.5939 - val_accuracy: 0.8238\n",
            "Epoch 34/300\n",
            "135/135 [==============================] - 1s 8ms/step - loss: 0.4366 - accuracy: 0.8559 - val_loss: 0.5914 - val_accuracy: 0.8308\n",
            "Epoch 35/300\n",
            "135/135 [==============================] - 1s 8ms/step - loss: 0.4111 - accuracy: 0.8668 - val_loss: 0.6380 - val_accuracy: 0.8169\n",
            "Epoch 36/300\n",
            "135/135 [==============================] - 1s 8ms/step - loss: 0.4363 - accuracy: 0.8621 - val_loss: 0.6268 - val_accuracy: 0.8217\n",
            "Epoch 37/300\n",
            "135/135 [==============================] - 1s 8ms/step - loss: 0.3991 - accuracy: 0.8737 - val_loss: 0.6279 - val_accuracy: 0.8189\n",
            "Epoch 38/300\n",
            "135/135 [==============================] - 1s 7ms/step - loss: 0.4155 - accuracy: 0.8660 - val_loss: 0.6323 - val_accuracy: 0.8384\n",
            "Epoch 39/300\n",
            "135/135 [==============================] - 1s 8ms/step - loss: 0.4012 - accuracy: 0.8628 - val_loss: 0.6221 - val_accuracy: 0.8287\n",
            "Epoch 40/300\n",
            "135/135 [==============================] - 1s 8ms/step - loss: 0.4001 - accuracy: 0.8745 - val_loss: 0.5844 - val_accuracy: 0.8336\n",
            "Epoch 41/300\n",
            "135/135 [==============================] - 1s 8ms/step - loss: 0.4190 - accuracy: 0.8649 - val_loss: 0.5786 - val_accuracy: 0.8419\n",
            "Epoch 42/300\n",
            "135/135 [==============================] - 1s 7ms/step - loss: 0.3486 - accuracy: 0.8818 - val_loss: 0.6465 - val_accuracy: 0.8350\n",
            "Epoch 43/300\n",
            "135/135 [==============================] - 1s 8ms/step - loss: 0.3796 - accuracy: 0.8784 - val_loss: 0.6166 - val_accuracy: 0.8245\n",
            "Epoch 44/300\n",
            "135/135 [==============================] - 1s 7ms/step - loss: 0.3662 - accuracy: 0.8829 - val_loss: 0.6145 - val_accuracy: 0.8329\n",
            "Epoch 45/300\n",
            "135/135 [==============================] - 1s 7ms/step - loss: 0.4103 - accuracy: 0.8609 - val_loss: 0.6013 - val_accuracy: 0.8308\n",
            "Epoch 46/300\n",
            "135/135 [==============================] - 1s 7ms/step - loss: 0.3824 - accuracy: 0.8752 - val_loss: 0.6178 - val_accuracy: 0.8280\n",
            "Epoch 47/300\n",
            "135/135 [==============================] - 1s 7ms/step - loss: 0.4001 - accuracy: 0.8668 - val_loss: 0.6044 - val_accuracy: 0.8308\n",
            "Epoch 48/300\n",
            "135/135 [==============================] - 1s 7ms/step - loss: 0.3217 - accuracy: 0.8982 - val_loss: 0.6058 - val_accuracy: 0.8343\n",
            "Epoch 49/300\n",
            "135/135 [==============================] - 1s 8ms/step - loss: 0.3632 - accuracy: 0.8839 - val_loss: 0.6432 - val_accuracy: 0.8301\n",
            "Epoch 50/300\n",
            "135/135 [==============================] - 1s 8ms/step - loss: 0.3294 - accuracy: 0.8847 - val_loss: 0.6380 - val_accuracy: 0.8217\n",
            "Epoch 51/300\n",
            "135/135 [==============================] - 1s 8ms/step - loss: 0.3654 - accuracy: 0.8763 - val_loss: 0.6311 - val_accuracy: 0.8273\n",
            "Epoch 52/300\n",
            "135/135 [==============================] - 1s 8ms/step - loss: 0.3470 - accuracy: 0.8866 - val_loss: 0.6258 - val_accuracy: 0.8315\n",
            "Epoch 53/300\n",
            "135/135 [==============================] - 1s 8ms/step - loss: 0.3175 - accuracy: 0.8948 - val_loss: 0.6050 - val_accuracy: 0.8336\n",
            "Epoch 54/300\n",
            "135/135 [==============================] - 1s 8ms/step - loss: 0.3145 - accuracy: 0.8949 - val_loss: 0.6475 - val_accuracy: 0.8322\n",
            "Epoch 55/300\n",
            "135/135 [==============================] - 1s 8ms/step - loss: 0.3088 - accuracy: 0.8987 - val_loss: 0.6273 - val_accuracy: 0.8315\n",
            "Epoch 56/300\n",
            "135/135 [==============================] - 1s 8ms/step - loss: 0.3647 - accuracy: 0.8816 - val_loss: 0.6560 - val_accuracy: 0.8287\n",
            "Epoch 57/300\n",
            "135/135 [==============================] - 1s 8ms/step - loss: 0.3217 - accuracy: 0.8923 - val_loss: 0.6245 - val_accuracy: 0.8433\n",
            "Epoch 58/300\n",
            "135/135 [==============================] - 1s 8ms/step - loss: 0.3248 - accuracy: 0.8902 - val_loss: 0.6322 - val_accuracy: 0.8350\n",
            "Epoch 59/300\n",
            "135/135 [==============================] - 1s 8ms/step - loss: 0.3046 - accuracy: 0.8991 - val_loss: 0.6225 - val_accuracy: 0.8350\n",
            "Epoch 60/300\n",
            "135/135 [==============================] - 1s 8ms/step - loss: 0.3258 - accuracy: 0.8991 - val_loss: 0.6507 - val_accuracy: 0.8384\n",
            "Epoch 61/300\n",
            "135/135 [==============================] - 1s 8ms/step - loss: 0.3200 - accuracy: 0.8943 - val_loss: 0.6473 - val_accuracy: 0.8301\n",
            "Epoch 62/300\n",
            "135/135 [==============================] - 1s 8ms/step - loss: 0.3108 - accuracy: 0.8997 - val_loss: 0.6204 - val_accuracy: 0.8357\n",
            "Epoch 63/300\n",
            "135/135 [==============================] - 1s 8ms/step - loss: 0.3113 - accuracy: 0.8924 - val_loss: 0.6243 - val_accuracy: 0.8377\n",
            "Epoch 64/300\n",
            "135/135 [==============================] - 1s 8ms/step - loss: 0.3020 - accuracy: 0.8975 - val_loss: 0.6380 - val_accuracy: 0.8391\n",
            "Epoch 65/300\n",
            "135/135 [==============================] - 1s 7ms/step - loss: 0.2726 - accuracy: 0.9066 - val_loss: 0.6133 - val_accuracy: 0.8357\n",
            "Epoch 66/300\n",
            "135/135 [==============================] - 1s 8ms/step - loss: 0.2962 - accuracy: 0.9013 - val_loss: 0.6276 - val_accuracy: 0.8370\n",
            "Epoch 67/300\n",
            "135/135 [==============================] - 1s 8ms/step - loss: 0.2691 - accuracy: 0.9153 - val_loss: 0.6315 - val_accuracy: 0.8294\n",
            "Epoch 68/300\n",
            "135/135 [==============================] - 1s 8ms/step - loss: 0.2833 - accuracy: 0.9074 - val_loss: 0.6419 - val_accuracy: 0.8426\n",
            "Epoch 69/300\n",
            "135/135 [==============================] - 1s 8ms/step - loss: 0.2642 - accuracy: 0.9181 - val_loss: 0.6340 - val_accuracy: 0.8405\n",
            "Epoch 70/300\n",
            "135/135 [==============================] - 1s 7ms/step - loss: 0.2557 - accuracy: 0.9060 - val_loss: 0.6476 - val_accuracy: 0.8391\n",
            "Epoch 71/300\n",
            "135/135 [==============================] - 1s 8ms/step - loss: 0.2914 - accuracy: 0.9041 - val_loss: 0.6375 - val_accuracy: 0.8357\n",
            "Epoch 72/300\n",
            "135/135 [==============================] - 1s 7ms/step - loss: 0.2674 - accuracy: 0.9099 - val_loss: 0.6539 - val_accuracy: 0.8329\n",
            "Epoch 73/300\n",
            "135/135 [==============================] - 1s 8ms/step - loss: 0.2715 - accuracy: 0.9063 - val_loss: 0.6488 - val_accuracy: 0.8329\n",
            "Epoch 74/300\n",
            "135/135 [==============================] - 1s 7ms/step - loss: 0.2638 - accuracy: 0.9074 - val_loss: 0.6474 - val_accuracy: 0.8294\n",
            "Epoch 75/300\n",
            "135/135 [==============================] - 1s 7ms/step - loss: 0.2946 - accuracy: 0.9009 - val_loss: 0.6610 - val_accuracy: 0.8329\n",
            "Epoch 76/300\n",
            "135/135 [==============================] - 1s 8ms/step - loss: 0.2828 - accuracy: 0.9051 - val_loss: 0.6207 - val_accuracy: 0.8329\n",
            "Epoch 77/300\n",
            "135/135 [==============================] - 1s 8ms/step - loss: 0.2731 - accuracy: 0.9071 - val_loss: 0.6279 - val_accuracy: 0.8308\n",
            "Epoch 78/300\n",
            "135/135 [==============================] - 1s 8ms/step - loss: 0.3022 - accuracy: 0.9019 - val_loss: 0.6319 - val_accuracy: 0.8391\n",
            "Epoch 79/300\n",
            "135/135 [==============================] - 1s 8ms/step - loss: 0.2478 - accuracy: 0.9219 - val_loss: 0.6570 - val_accuracy: 0.8315\n",
            "Epoch 80/300\n",
            "135/135 [==============================] - 1s 8ms/step - loss: 0.2472 - accuracy: 0.9171 - val_loss: 0.6510 - val_accuracy: 0.8273\n",
            "Epoch 81/300\n",
            "135/135 [==============================] - 1s 8ms/step - loss: 0.2684 - accuracy: 0.9103 - val_loss: 0.6647 - val_accuracy: 0.8419\n",
            "4\n",
            "model 0\n",
            "Epoch 1/300\n",
            "9/9 [==============================] - 4s 272ms/step - loss: 2.2620 - accuracy: 0.1268 - val_loss: 2.2397 - val_accuracy: 0.1407\n",
            "Epoch 2/300\n",
            "9/9 [==============================] - 2s 211ms/step - loss: 2.1488 - accuracy: 0.2024 - val_loss: 2.0482 - val_accuracy: 0.2471\n",
            "Epoch 3/300\n",
            "9/9 [==============================] - 2s 208ms/step - loss: 1.9875 - accuracy: 0.2733 - val_loss: 1.9783 - val_accuracy: 0.2416\n",
            "Epoch 4/300\n",
            "9/9 [==============================] - 2s 215ms/step - loss: 1.8763 - accuracy: 0.3029 - val_loss: 1.8619 - val_accuracy: 0.3102\n",
            "Epoch 5/300\n",
            "9/9 [==============================] - 2s 212ms/step - loss: 1.8072 - accuracy: 0.3288 - val_loss: 1.7969 - val_accuracy: 0.3342\n",
            "Epoch 6/300\n",
            "9/9 [==============================] - 2s 210ms/step - loss: 1.7230 - accuracy: 0.3726 - val_loss: 1.8061 - val_accuracy: 0.3665\n",
            "Epoch 7/300\n",
            "9/9 [==============================] - 2s 209ms/step - loss: 1.6684 - accuracy: 0.4011 - val_loss: 1.6784 - val_accuracy: 0.4043\n",
            "Epoch 8/300\n",
            "9/9 [==============================] - 2s 210ms/step - loss: 1.5801 - accuracy: 0.4427 - val_loss: 1.5363 - val_accuracy: 0.4475\n",
            "Epoch 9/300\n",
            "9/9 [==============================] - 2s 211ms/step - loss: 1.4702 - accuracy: 0.4897 - val_loss: 1.4019 - val_accuracy: 0.5120\n",
            "Epoch 10/300\n",
            "9/9 [==============================] - 2s 212ms/step - loss: 1.3204 - accuracy: 0.5493 - val_loss: 1.2989 - val_accuracy: 0.5690\n",
            "Epoch 11/300\n",
            "9/9 [==============================] - 2s 208ms/step - loss: 1.2408 - accuracy: 0.5871 - val_loss: 1.2534 - val_accuracy: 0.5772\n",
            "Epoch 12/300\n",
            "9/9 [==============================] - 2s 210ms/step - loss: 1.1369 - accuracy: 0.6131 - val_loss: 1.1081 - val_accuracy: 0.6349\n",
            "Epoch 13/300\n",
            "9/9 [==============================] - 2s 213ms/step - loss: 1.0216 - accuracy: 0.6648 - val_loss: 1.0247 - val_accuracy: 0.6637\n",
            "Epoch 14/300\n",
            "9/9 [==============================] - 2s 212ms/step - loss: 0.9055 - accuracy: 0.7022 - val_loss: 0.9290 - val_accuracy: 0.7035\n",
            "Epoch 15/300\n",
            "9/9 [==============================] - 2s 213ms/step - loss: 0.8806 - accuracy: 0.7170 - val_loss: 0.9478 - val_accuracy: 0.7001\n",
            "Epoch 16/300\n",
            "9/9 [==============================] - 2s 213ms/step - loss: 0.7975 - accuracy: 0.7529 - val_loss: 0.8391 - val_accuracy: 0.7358\n",
            "Epoch 17/300\n",
            "9/9 [==============================] - 2s 211ms/step - loss: 0.7190 - accuracy: 0.7763 - val_loss: 0.8375 - val_accuracy: 0.7467\n",
            "Epoch 18/300\n",
            "9/9 [==============================] - 2s 212ms/step - loss: 0.6592 - accuracy: 0.7934 - val_loss: 0.7573 - val_accuracy: 0.7714\n",
            "Epoch 19/300\n",
            "9/9 [==============================] - 2s 210ms/step - loss: 0.6059 - accuracy: 0.8115 - val_loss: 0.7381 - val_accuracy: 0.7811\n",
            "Epoch 20/300\n",
            "9/9 [==============================] - 2s 209ms/step - loss: 0.5451 - accuracy: 0.8367 - val_loss: 0.7085 - val_accuracy: 0.7811\n",
            "Epoch 21/300\n",
            "9/9 [==============================] - 2s 212ms/step - loss: 0.5828 - accuracy: 0.8198 - val_loss: 0.7189 - val_accuracy: 0.7811\n",
            "Epoch 22/300\n",
            "9/9 [==============================] - 2s 209ms/step - loss: 0.5187 - accuracy: 0.8392 - val_loss: 0.6672 - val_accuracy: 0.7982\n",
            "Epoch 23/300\n",
            "9/9 [==============================] - 2s 205ms/step - loss: 0.4486 - accuracy: 0.8622 - val_loss: 0.7776 - val_accuracy: 0.7749\n",
            "Epoch 24/300\n",
            "9/9 [==============================] - 2s 208ms/step - loss: 0.4754 - accuracy: 0.8455 - val_loss: 0.6311 - val_accuracy: 0.8161\n",
            "Epoch 25/300\n",
            "9/9 [==============================] - 2s 207ms/step - loss: 0.3982 - accuracy: 0.8760 - val_loss: 0.6326 - val_accuracy: 0.8181\n",
            "Epoch 26/300\n",
            "9/9 [==============================] - 2s 207ms/step - loss: 0.3717 - accuracy: 0.8854 - val_loss: 0.6511 - val_accuracy: 0.8133\n",
            "Epoch 27/300\n",
            "9/9 [==============================] - 2s 212ms/step - loss: 0.3581 - accuracy: 0.8910 - val_loss: 0.6109 - val_accuracy: 0.8202\n",
            "Epoch 28/300\n",
            "9/9 [==============================] - 2s 209ms/step - loss: 0.3180 - accuracy: 0.8988 - val_loss: 0.6927 - val_accuracy: 0.8003\n",
            "Epoch 29/300\n",
            "9/9 [==============================] - 2s 210ms/step - loss: 0.3312 - accuracy: 0.8964 - val_loss: 0.6657 - val_accuracy: 0.8181\n",
            "Epoch 30/300\n",
            "9/9 [==============================] - 2s 209ms/step - loss: 0.2915 - accuracy: 0.9086 - val_loss: 0.6669 - val_accuracy: 0.8243\n",
            "Epoch 31/300\n",
            "9/9 [==============================] - 2s 210ms/step - loss: 0.2632 - accuracy: 0.9220 - val_loss: 0.6142 - val_accuracy: 0.8284\n",
            "Epoch 32/300\n",
            "9/9 [==============================] - 2s 209ms/step - loss: 0.2283 - accuracy: 0.9321 - val_loss: 0.6078 - val_accuracy: 0.8277\n",
            "Epoch 33/300\n",
            "9/9 [==============================] - 2s 213ms/step - loss: 0.2219 - accuracy: 0.9348 - val_loss: 0.6535 - val_accuracy: 0.8270\n",
            "Epoch 34/300\n",
            "9/9 [==============================] - 2s 213ms/step - loss: 0.2067 - accuracy: 0.9389 - val_loss: 0.7018 - val_accuracy: 0.8133\n",
            "Epoch 35/300\n",
            "9/9 [==============================] - 2s 215ms/step - loss: 0.2474 - accuracy: 0.9178 - val_loss: 0.6341 - val_accuracy: 0.8339\n",
            "Epoch 36/300\n",
            "9/9 [==============================] - 2s 211ms/step - loss: 0.1909 - accuracy: 0.9439 - val_loss: 0.6933 - val_accuracy: 0.8188\n",
            "Epoch 37/300\n",
            "9/9 [==============================] - 2s 211ms/step - loss: 0.1974 - accuracy: 0.9408 - val_loss: 0.7510 - val_accuracy: 0.8078\n",
            "Epoch 38/300\n",
            "9/9 [==============================] - 2s 210ms/step - loss: 0.1965 - accuracy: 0.9363 - val_loss: 0.7209 - val_accuracy: 0.8154\n",
            "Epoch 39/300\n",
            "9/9 [==============================] - 2s 206ms/step - loss: 0.1717 - accuracy: 0.9489 - val_loss: 0.6598 - val_accuracy: 0.8318\n",
            "Epoch 40/300\n",
            "9/9 [==============================] - 2s 207ms/step - loss: 0.1438 - accuracy: 0.9607 - val_loss: 0.6631 - val_accuracy: 0.8312\n",
            "Epoch 41/300\n",
            "9/9 [==============================] - 2s 211ms/step - loss: 0.1165 - accuracy: 0.9744 - val_loss: 0.6778 - val_accuracy: 0.8332\n",
            "Epoch 42/300\n",
            "9/9 [==============================] - 2s 213ms/step - loss: 0.1029 - accuracy: 0.9729 - val_loss: 0.7205 - val_accuracy: 0.8380\n",
            "Epoch 43/300\n",
            "9/9 [==============================] - 2s 211ms/step - loss: 0.1034 - accuracy: 0.9731 - val_loss: 0.7482 - val_accuracy: 0.8284\n",
            "Epoch 44/300\n",
            "9/9 [==============================] - 2s 210ms/step - loss: 0.0951 - accuracy: 0.9756 - val_loss: 0.7164 - val_accuracy: 0.8318\n",
            "Epoch 45/300\n",
            "9/9 [==============================] - 2s 211ms/step - loss: 0.0905 - accuracy: 0.9771 - val_loss: 0.7502 - val_accuracy: 0.8284\n",
            "Epoch 46/300\n",
            "9/9 [==============================] - 2s 213ms/step - loss: 0.0947 - accuracy: 0.9739 - val_loss: 0.8135 - val_accuracy: 0.8188\n",
            "Epoch 47/300\n",
            "9/9 [==============================] - 2s 210ms/step - loss: 0.0914 - accuracy: 0.9780 - val_loss: 0.7708 - val_accuracy: 0.8305\n",
            "Epoch 48/300\n",
            "9/9 [==============================] - 2s 208ms/step - loss: 0.0912 - accuracy: 0.9784 - val_loss: 0.7743 - val_accuracy: 0.8346\n",
            "Epoch 49/300\n",
            "9/9 [==============================] - 2s 212ms/step - loss: 0.0752 - accuracy: 0.9776 - val_loss: 0.8216 - val_accuracy: 0.8222\n",
            "Epoch 50/300\n",
            "9/9 [==============================] - 2s 212ms/step - loss: 0.0944 - accuracy: 0.9685 - val_loss: 0.8957 - val_accuracy: 0.8147\n",
            "Epoch 51/300\n",
            "9/9 [==============================] - 2s 210ms/step - loss: 0.0941 - accuracy: 0.9698 - val_loss: 0.8225 - val_accuracy: 0.8270\n",
            "Epoch 52/300\n",
            "9/9 [==============================] - 2s 209ms/step - loss: 0.0793 - accuracy: 0.9755 - val_loss: 0.8252 - val_accuracy: 0.8202\n",
            "Epoch 53/300\n",
            "9/9 [==============================] - 2s 205ms/step - loss: 0.0611 - accuracy: 0.9853 - val_loss: 0.8369 - val_accuracy: 0.8277\n",
            "Epoch 54/300\n",
            "9/9 [==============================] - 2s 213ms/step - loss: 0.0546 - accuracy: 0.9856 - val_loss: 0.8108 - val_accuracy: 0.8360\n",
            "Epoch 55/300\n",
            "9/9 [==============================] - 2s 213ms/step - loss: 0.0390 - accuracy: 0.9917 - val_loss: 0.8880 - val_accuracy: 0.8195\n",
            "Epoch 56/300\n",
            "9/9 [==============================] - 2s 211ms/step - loss: 0.0538 - accuracy: 0.9880 - val_loss: 0.8600 - val_accuracy: 0.8222\n",
            "Epoch 57/300\n",
            "9/9 [==============================] - 2s 208ms/step - loss: 0.0481 - accuracy: 0.9888 - val_loss: 0.8806 - val_accuracy: 0.8270\n",
            "Epoch 58/300\n",
            "9/9 [==============================] - 2s 209ms/step - loss: 0.0433 - accuracy: 0.9910 - val_loss: 0.9097 - val_accuracy: 0.8216\n",
            "Epoch 59/300\n",
            "9/9 [==============================] - 2s 208ms/step - loss: 0.0452 - accuracy: 0.9902 - val_loss: 0.9711 - val_accuracy: 0.8195\n",
            "Epoch 60/300\n",
            "9/9 [==============================] - 2s 210ms/step - loss: 0.0374 - accuracy: 0.9924 - val_loss: 0.9062 - val_accuracy: 0.8312\n",
            "Epoch 61/300\n",
            "9/9 [==============================] - 2s 208ms/step - loss: 0.0354 - accuracy: 0.9915 - val_loss: 0.8927 - val_accuracy: 0.8325\n",
            "Epoch 62/300\n",
            "9/9 [==============================] - 2s 208ms/step - loss: 0.0375 - accuracy: 0.9924 - val_loss: 0.9052 - val_accuracy: 0.8277\n",
            "Epoch 63/300\n",
            "9/9 [==============================] - 2s 206ms/step - loss: 0.0387 - accuracy: 0.9908 - val_loss: 0.9546 - val_accuracy: 0.8222\n",
            "Epoch 64/300\n",
            "9/9 [==============================] - 2s 209ms/step - loss: 0.0279 - accuracy: 0.9955 - val_loss: 0.9324 - val_accuracy: 0.8277\n",
            "Epoch 65/300\n",
            "9/9 [==============================] - 2s 213ms/step - loss: 0.0339 - accuracy: 0.9926 - val_loss: 0.9308 - val_accuracy: 0.8270\n",
            "Epoch 66/300\n",
            "9/9 [==============================] - 2s 210ms/step - loss: 0.0267 - accuracy: 0.9952 - val_loss: 0.9516 - val_accuracy: 0.8229\n",
            "Epoch 67/300\n",
            "9/9 [==============================] - 2s 212ms/step - loss: 0.0258 - accuracy: 0.9946 - val_loss: 0.9413 - val_accuracy: 0.8394\n",
            "Epoch 68/300\n",
            "9/9 [==============================] - 2s 209ms/step - loss: 0.0231 - accuracy: 0.9961 - val_loss: 0.9711 - val_accuracy: 0.8291\n",
            "Epoch 69/300\n",
            "9/9 [==============================] - 2s 212ms/step - loss: 0.0219 - accuracy: 0.9963 - val_loss: 0.9454 - val_accuracy: 0.8298\n",
            "Epoch 70/300\n",
            "9/9 [==============================] - 2s 208ms/step - loss: 0.0222 - accuracy: 0.9969 - val_loss: 0.9641 - val_accuracy: 0.8312\n",
            "Epoch 71/300\n",
            "9/9 [==============================] - 2s 208ms/step - loss: 0.0234 - accuracy: 0.9954 - val_loss: 1.0041 - val_accuracy: 0.8209\n",
            "Epoch 72/300\n",
            "9/9 [==============================] - 2s 211ms/step - loss: 0.0243 - accuracy: 0.9936 - val_loss: 1.0070 - val_accuracy: 0.8229\n",
            "model 1\n",
            "Epoch 1/300\n",
            "9/9 [==============================] - 5s 369ms/step - loss: 2.2546 - accuracy: 0.1575 - val_loss: 2.1126 - val_accuracy: 0.2135\n",
            "Epoch 2/300\n",
            "9/9 [==============================] - 3s 324ms/step - loss: 1.9767 - accuracy: 0.2928 - val_loss: 1.7737 - val_accuracy: 0.4345\n",
            "Epoch 3/300\n",
            "9/9 [==============================] - 3s 315ms/step - loss: 1.6829 - accuracy: 0.4346 - val_loss: 1.5426 - val_accuracy: 0.5058\n",
            "Epoch 4/300\n",
            "9/9 [==============================] - 3s 313ms/step - loss: 1.5258 - accuracy: 0.4908 - val_loss: 1.3438 - val_accuracy: 0.5820\n",
            "Epoch 5/300\n",
            "9/9 [==============================] - 3s 318ms/step - loss: 1.3673 - accuracy: 0.5503 - val_loss: 1.2232 - val_accuracy: 0.6081\n",
            "Epoch 6/300\n",
            "9/9 [==============================] - 3s 319ms/step - loss: 1.2410 - accuracy: 0.5885 - val_loss: 1.1570 - val_accuracy: 0.6342\n",
            "Epoch 7/300\n",
            "9/9 [==============================] - 3s 320ms/step - loss: 1.1949 - accuracy: 0.6111 - val_loss: 1.0779 - val_accuracy: 0.6630\n",
            "Epoch 8/300\n",
            "9/9 [==============================] - 3s 327ms/step - loss: 1.1195 - accuracy: 0.6488 - val_loss: 0.9894 - val_accuracy: 0.6987\n",
            "Epoch 9/300\n",
            "9/9 [==============================] - 3s 323ms/step - loss: 1.0590 - accuracy: 0.6574 - val_loss: 0.9477 - val_accuracy: 0.7069\n",
            "Epoch 10/300\n",
            "9/9 [==============================] - 3s 330ms/step - loss: 1.0116 - accuracy: 0.6796 - val_loss: 0.9210 - val_accuracy: 0.7248\n",
            "Epoch 11/300\n",
            "9/9 [==============================] - 3s 360ms/step - loss: 0.9699 - accuracy: 0.6884 - val_loss: 0.8543 - val_accuracy: 0.7440\n",
            "Epoch 12/300\n",
            "9/9 [==============================] - 3s 359ms/step - loss: 0.9161 - accuracy: 0.6965 - val_loss: 0.8074 - val_accuracy: 0.7577\n",
            "Epoch 13/300\n",
            "9/9 [==============================] - 3s 353ms/step - loss: 0.8771 - accuracy: 0.7208 - val_loss: 0.7827 - val_accuracy: 0.7680\n",
            "Epoch 14/300\n",
            "9/9 [==============================] - 3s 341ms/step - loss: 0.8595 - accuracy: 0.7242 - val_loss: 0.7737 - val_accuracy: 0.7563\n",
            "Epoch 15/300\n",
            "9/9 [==============================] - 3s 353ms/step - loss: 0.8235 - accuracy: 0.7375 - val_loss: 0.7353 - val_accuracy: 0.7893\n",
            "Epoch 16/300\n",
            "9/9 [==============================] - 3s 370ms/step - loss: 0.8083 - accuracy: 0.7396 - val_loss: 0.7397 - val_accuracy: 0.7886\n",
            "Epoch 17/300\n",
            "9/9 [==============================] - 3s 356ms/step - loss: 0.7575 - accuracy: 0.7536 - val_loss: 0.7106 - val_accuracy: 0.7900\n",
            "Epoch 18/300\n",
            "9/9 [==============================] - 3s 373ms/step - loss: 0.7440 - accuracy: 0.7544 - val_loss: 0.7012 - val_accuracy: 0.7893\n",
            "Epoch 19/300\n",
            "9/9 [==============================] - 3s 362ms/step - loss: 0.7055 - accuracy: 0.7681 - val_loss: 0.6576 - val_accuracy: 0.8051\n",
            "Epoch 20/300\n",
            "9/9 [==============================] - 4s 410ms/step - loss: 0.6804 - accuracy: 0.7874 - val_loss: 0.6545 - val_accuracy: 0.7948\n",
            "Epoch 21/300\n",
            "9/9 [==============================] - 4s 438ms/step - loss: 0.6345 - accuracy: 0.7940 - val_loss: 0.6193 - val_accuracy: 0.8099\n",
            "Epoch 22/300\n",
            "9/9 [==============================] - 4s 412ms/step - loss: 0.6301 - accuracy: 0.7972 - val_loss: 0.5964 - val_accuracy: 0.8209\n",
            "Epoch 23/300\n",
            "9/9 [==============================] - 3s 393ms/step - loss: 0.5889 - accuracy: 0.8179 - val_loss: 0.5972 - val_accuracy: 0.8126\n",
            "Epoch 24/300\n",
            "9/9 [==============================] - 4s 401ms/step - loss: 0.6069 - accuracy: 0.8070 - val_loss: 0.5757 - val_accuracy: 0.8277\n",
            "Epoch 25/300\n",
            "9/9 [==============================] - 3s 390ms/step - loss: 0.5867 - accuracy: 0.8101 - val_loss: 0.5693 - val_accuracy: 0.8229\n",
            "Epoch 26/300\n",
            "9/9 [==============================] - 3s 389ms/step - loss: 0.5280 - accuracy: 0.8314 - val_loss: 0.5709 - val_accuracy: 0.8257\n",
            "Epoch 27/300\n",
            "9/9 [==============================] - 3s 387ms/step - loss: 0.5291 - accuracy: 0.8286 - val_loss: 0.5774 - val_accuracy: 0.8257\n",
            "Epoch 28/300\n",
            "9/9 [==============================] - 3s 368ms/step - loss: 0.5191 - accuracy: 0.8289 - val_loss: 0.5559 - val_accuracy: 0.8332\n",
            "Epoch 29/300\n",
            "9/9 [==============================] - 3s 385ms/step - loss: 0.5119 - accuracy: 0.8291 - val_loss: 0.5805 - val_accuracy: 0.8167\n",
            "Epoch 30/300\n",
            "9/9 [==============================] - 3s 367ms/step - loss: 0.4854 - accuracy: 0.8337 - val_loss: 0.5455 - val_accuracy: 0.8277\n",
            "Epoch 31/300\n",
            "9/9 [==============================] - 4s 460ms/step - loss: 0.4857 - accuracy: 0.8420 - val_loss: 0.5246 - val_accuracy: 0.8435\n",
            "Epoch 32/300\n",
            "9/9 [==============================] - 4s 427ms/step - loss: 0.4672 - accuracy: 0.8485 - val_loss: 0.5042 - val_accuracy: 0.8449\n",
            "Epoch 33/300\n",
            "9/9 [==============================] - 4s 410ms/step - loss: 0.4514 - accuracy: 0.8540 - val_loss: 0.5051 - val_accuracy: 0.8463\n",
            "Epoch 34/300\n",
            "9/9 [==============================] - 3s 381ms/step - loss: 0.4527 - accuracy: 0.8463 - val_loss: 0.4877 - val_accuracy: 0.8476\n",
            "Epoch 35/300\n",
            "9/9 [==============================] - 3s 341ms/step - loss: 0.4363 - accuracy: 0.8517 - val_loss: 0.5210 - val_accuracy: 0.8435\n",
            "Epoch 36/300\n",
            "9/9 [==============================] - 3s 337ms/step - loss: 0.4130 - accuracy: 0.8714 - val_loss: 0.5019 - val_accuracy: 0.8442\n",
            "Epoch 37/300\n",
            "9/9 [==============================] - 3s 333ms/step - loss: 0.4037 - accuracy: 0.8724 - val_loss: 0.4812 - val_accuracy: 0.8545\n",
            "Epoch 38/300\n",
            "9/9 [==============================] - 3s 323ms/step - loss: 0.4148 - accuracy: 0.8653 - val_loss: 0.4909 - val_accuracy: 0.8476\n",
            "Epoch 39/300\n",
            "9/9 [==============================] - 3s 318ms/step - loss: 0.3804 - accuracy: 0.8732 - val_loss: 0.5021 - val_accuracy: 0.8518\n",
            "Epoch 40/300\n",
            "9/9 [==============================] - 3s 319ms/step - loss: 0.3887 - accuracy: 0.8681 - val_loss: 0.5047 - val_accuracy: 0.8476\n",
            "Epoch 41/300\n",
            "9/9 [==============================] - 3s 317ms/step - loss: 0.3857 - accuracy: 0.8752 - val_loss: 0.5040 - val_accuracy: 0.8511\n",
            "Epoch 42/300\n",
            "9/9 [==============================] - 3s 323ms/step - loss: 0.3772 - accuracy: 0.8760 - val_loss: 0.4745 - val_accuracy: 0.8579\n",
            "Epoch 43/300\n",
            "9/9 [==============================] - 3s 323ms/step - loss: 0.3470 - accuracy: 0.8828 - val_loss: 0.4841 - val_accuracy: 0.8531\n",
            "Epoch 44/300\n",
            "9/9 [==============================] - 3s 322ms/step - loss: 0.3411 - accuracy: 0.8923 - val_loss: 0.4817 - val_accuracy: 0.8586\n",
            "Epoch 45/300\n",
            "9/9 [==============================] - 3s 324ms/step - loss: 0.3386 - accuracy: 0.8871 - val_loss: 0.4692 - val_accuracy: 0.8483\n",
            "Epoch 46/300\n",
            "9/9 [==============================] - 3s 316ms/step - loss: 0.3444 - accuracy: 0.8803 - val_loss: 0.4647 - val_accuracy: 0.8566\n",
            "Epoch 47/300\n",
            "9/9 [==============================] - 3s 326ms/step - loss: 0.3192 - accuracy: 0.8904 - val_loss: 0.4975 - val_accuracy: 0.8593\n",
            "Epoch 48/300\n",
            "9/9 [==============================] - 3s 322ms/step - loss: 0.2964 - accuracy: 0.9036 - val_loss: 0.4924 - val_accuracy: 0.8524\n",
            "Epoch 49/300\n",
            "9/9 [==============================] - 3s 320ms/step - loss: 0.3322 - accuracy: 0.9008 - val_loss: 0.4861 - val_accuracy: 0.8518\n",
            "Epoch 50/300\n",
            "9/9 [==============================] - 3s 315ms/step - loss: 0.3084 - accuracy: 0.8916 - val_loss: 0.4833 - val_accuracy: 0.8490\n",
            "Epoch 51/300\n",
            "9/9 [==============================] - 3s 318ms/step - loss: 0.2859 - accuracy: 0.9067 - val_loss: 0.4790 - val_accuracy: 0.8586\n",
            "Epoch 52/300\n",
            "9/9 [==============================] - 3s 321ms/step - loss: 0.2900 - accuracy: 0.9005 - val_loss: 0.4868 - val_accuracy: 0.8545\n",
            "Epoch 53/300\n",
            "9/9 [==============================] - 3s 318ms/step - loss: 0.2744 - accuracy: 0.9078 - val_loss: 0.4754 - val_accuracy: 0.8620\n",
            "Epoch 54/300\n",
            "9/9 [==============================] - 3s 314ms/step - loss: 0.2667 - accuracy: 0.9143 - val_loss: 0.4969 - val_accuracy: 0.8531\n",
            "Epoch 55/300\n",
            "9/9 [==============================] - 3s 315ms/step - loss: 0.2680 - accuracy: 0.9133 - val_loss: 0.5055 - val_accuracy: 0.8483\n",
            "Epoch 56/300\n",
            "9/9 [==============================] - 3s 316ms/step - loss: 0.2527 - accuracy: 0.9168 - val_loss: 0.4979 - val_accuracy: 0.8504\n",
            "Epoch 57/300\n",
            "9/9 [==============================] - 3s 310ms/step - loss: 0.2728 - accuracy: 0.9075 - val_loss: 0.4779 - val_accuracy: 0.8538\n",
            "Epoch 58/300\n",
            "9/9 [==============================] - 3s 318ms/step - loss: 0.2439 - accuracy: 0.9205 - val_loss: 0.4581 - val_accuracy: 0.8682\n",
            "Epoch 59/300\n",
            "9/9 [==============================] - 3s 311ms/step - loss: 0.2641 - accuracy: 0.9177 - val_loss: 0.4818 - val_accuracy: 0.8620\n",
            "Epoch 60/300\n",
            "9/9 [==============================] - 3s 319ms/step - loss: 0.2614 - accuracy: 0.9129 - val_loss: 0.4650 - val_accuracy: 0.8675\n",
            "Epoch 61/300\n",
            "9/9 [==============================] - 3s 318ms/step - loss: 0.2331 - accuracy: 0.9220 - val_loss: 0.4749 - val_accuracy: 0.8675\n",
            "Epoch 62/300\n",
            "9/9 [==============================] - 3s 311ms/step - loss: 0.2428 - accuracy: 0.9148 - val_loss: 0.4701 - val_accuracy: 0.8717\n",
            "Epoch 63/300\n",
            "9/9 [==============================] - 3s 310ms/step - loss: 0.2247 - accuracy: 0.9246 - val_loss: 0.4751 - val_accuracy: 0.8614\n",
            "Epoch 64/300\n",
            "9/9 [==============================] - 3s 306ms/step - loss: 0.2364 - accuracy: 0.9187 - val_loss: 0.4749 - val_accuracy: 0.8634\n",
            "Epoch 65/300\n",
            "9/9 [==============================] - 3s 309ms/step - loss: 0.2178 - accuracy: 0.9256 - val_loss: 0.4672 - val_accuracy: 0.8607\n",
            "Epoch 66/300\n",
            "9/9 [==============================] - 3s 317ms/step - loss: 0.2102 - accuracy: 0.9304 - val_loss: 0.4803 - val_accuracy: 0.8648\n",
            "Epoch 67/300\n",
            "9/9 [==============================] - 3s 310ms/step - loss: 0.2307 - accuracy: 0.9270 - val_loss: 0.4946 - val_accuracy: 0.8620\n",
            "Epoch 68/300\n",
            "9/9 [==============================] - 3s 306ms/step - loss: 0.2215 - accuracy: 0.9263 - val_loss: 0.4833 - val_accuracy: 0.8593\n",
            "Epoch 69/300\n",
            "9/9 [==============================] - 3s 305ms/step - loss: 0.2169 - accuracy: 0.9254 - val_loss: 0.4911 - val_accuracy: 0.8641\n",
            "Epoch 70/300\n",
            "9/9 [==============================] - 3s 304ms/step - loss: 0.1954 - accuracy: 0.9365 - val_loss: 0.4829 - val_accuracy: 0.8559\n",
            "Epoch 71/300\n",
            "9/9 [==============================] - 3s 311ms/step - loss: 0.1987 - accuracy: 0.9339 - val_loss: 0.4767 - val_accuracy: 0.8648\n",
            "Epoch 72/300\n",
            "9/9 [==============================] - 3s 309ms/step - loss: 0.1872 - accuracy: 0.9374 - val_loss: 0.5046 - val_accuracy: 0.8627\n",
            "Epoch 73/300\n",
            "9/9 [==============================] - 3s 309ms/step - loss: 0.2020 - accuracy: 0.9378 - val_loss: 0.5183 - val_accuracy: 0.8586\n",
            "Epoch 74/300\n",
            "9/9 [==============================] - 3s 311ms/step - loss: 0.1884 - accuracy: 0.9409 - val_loss: 0.4961 - val_accuracy: 0.8668\n",
            "Epoch 75/300\n",
            "9/9 [==============================] - 3s 313ms/step - loss: 0.1941 - accuracy: 0.9341 - val_loss: 0.4963 - val_accuracy: 0.8614\n",
            "Epoch 76/300\n",
            "9/9 [==============================] - 3s 307ms/step - loss: 0.2078 - accuracy: 0.9323 - val_loss: 0.4815 - val_accuracy: 0.8655\n",
            "Epoch 77/300\n",
            "9/9 [==============================] - 3s 308ms/step - loss: 0.2174 - accuracy: 0.9271 - val_loss: 0.5072 - val_accuracy: 0.8545\n",
            "Epoch 78/300\n",
            "9/9 [==============================] - 3s 310ms/step - loss: 0.1863 - accuracy: 0.9336 - val_loss: 0.4975 - val_accuracy: 0.8641\n",
            "Epoch 79/300\n",
            "9/9 [==============================] - 3s 307ms/step - loss: 0.1798 - accuracy: 0.9412 - val_loss: 0.4848 - val_accuracy: 0.8744\n",
            "Epoch 80/300\n",
            "9/9 [==============================] - 3s 306ms/step - loss: 0.1990 - accuracy: 0.9314 - val_loss: 0.4943 - val_accuracy: 0.8655\n",
            "Epoch 81/300\n",
            "9/9 [==============================] - 3s 306ms/step - loss: 0.1648 - accuracy: 0.9452 - val_loss: 0.4876 - val_accuracy: 0.8675\n",
            "Epoch 82/300\n",
            "9/9 [==============================] - 3s 313ms/step - loss: 0.1619 - accuracy: 0.9450 - val_loss: 0.5152 - val_accuracy: 0.8627\n",
            "Epoch 83/300\n",
            "9/9 [==============================] - 3s 305ms/step - loss: 0.1537 - accuracy: 0.9485 - val_loss: 0.5016 - val_accuracy: 0.8641\n",
            "Epoch 84/300\n",
            "9/9 [==============================] - 3s 306ms/step - loss: 0.1567 - accuracy: 0.9530 - val_loss: 0.4945 - val_accuracy: 0.8614\n",
            "Epoch 85/300\n",
            "9/9 [==============================] - 3s 310ms/step - loss: 0.1582 - accuracy: 0.9449 - val_loss: 0.5048 - val_accuracy: 0.8600\n",
            "Epoch 86/300\n",
            "9/9 [==============================] - 3s 311ms/step - loss: 0.1482 - accuracy: 0.9495 - val_loss: 0.5209 - val_accuracy: 0.8607\n",
            "Epoch 87/300\n",
            "9/9 [==============================] - 3s 309ms/step - loss: 0.1449 - accuracy: 0.9500 - val_loss: 0.4892 - val_accuracy: 0.8751\n",
            "Epoch 88/300\n",
            "9/9 [==============================] - 3s 311ms/step - loss: 0.1501 - accuracy: 0.9472 - val_loss: 0.5181 - val_accuracy: 0.8703\n",
            "Epoch 89/300\n",
            "9/9 [==============================] - 3s 310ms/step - loss: 0.1609 - accuracy: 0.9493 - val_loss: 0.5046 - val_accuracy: 0.8696\n",
            "Epoch 90/300\n",
            "9/9 [==============================] - 3s 315ms/step - loss: 0.1725 - accuracy: 0.9427 - val_loss: 0.4845 - val_accuracy: 0.8668\n",
            "Epoch 91/300\n",
            "9/9 [==============================] - 3s 314ms/step - loss: 0.1570 - accuracy: 0.9457 - val_loss: 0.5214 - val_accuracy: 0.8627\n",
            "Epoch 92/300\n",
            "9/9 [==============================] - 3s 315ms/step - loss: 0.1626 - accuracy: 0.9430 - val_loss: 0.5239 - val_accuracy: 0.8531\n",
            "Epoch 93/300\n",
            "9/9 [==============================] - 3s 313ms/step - loss: 0.1434 - accuracy: 0.9492 - val_loss: 0.5159 - val_accuracy: 0.8593\n",
            "Epoch 94/300\n",
            "9/9 [==============================] - 3s 310ms/step - loss: 0.1455 - accuracy: 0.9508 - val_loss: 0.5177 - val_accuracy: 0.8579\n",
            "Epoch 95/300\n",
            "9/9 [==============================] - 3s 311ms/step - loss: 0.1430 - accuracy: 0.9557 - val_loss: 0.5142 - val_accuracy: 0.8572\n",
            "Epoch 96/300\n",
            "9/9 [==============================] - 3s 314ms/step - loss: 0.1345 - accuracy: 0.9576 - val_loss: 0.5003 - val_accuracy: 0.8668\n",
            "Epoch 97/300\n",
            "9/9 [==============================] - 3s 310ms/step - loss: 0.1444 - accuracy: 0.9511 - val_loss: 0.5209 - val_accuracy: 0.8600\n",
            "Epoch 98/300\n",
            "9/9 [==============================] - 3s 305ms/step - loss: 0.1501 - accuracy: 0.9480 - val_loss: 0.5142 - val_accuracy: 0.8655\n",
            "model 2\n",
            "Epoch 1/300\n",
            "137/137 [==============================] - 2s 8ms/step - loss: 2.0992 - accuracy: 0.2221 - val_loss: 1.3256 - val_accuracy: 0.5676\n",
            "Epoch 2/300\n",
            "137/137 [==============================] - 1s 7ms/step - loss: 1.3863 - accuracy: 0.5287 - val_loss: 1.1394 - val_accuracy: 0.6507\n",
            "Epoch 3/300\n",
            "137/137 [==============================] - 1s 7ms/step - loss: 1.2378 - accuracy: 0.5889 - val_loss: 1.0452 - val_accuracy: 0.6726\n",
            "Epoch 4/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 1.1347 - accuracy: 0.6400 - val_loss: 0.9454 - val_accuracy: 0.7117\n",
            "Epoch 5/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 1.0504 - accuracy: 0.6592 - val_loss: 0.9042 - val_accuracy: 0.7227\n",
            "Epoch 6/300\n",
            "137/137 [==============================] - 1s 7ms/step - loss: 0.9678 - accuracy: 0.6890 - val_loss: 0.9422 - val_accuracy: 0.7042\n",
            "Epoch 7/300\n",
            "137/137 [==============================] - 1s 7ms/step - loss: 0.9224 - accuracy: 0.7076 - val_loss: 0.8215 - val_accuracy: 0.7557\n",
            "Epoch 8/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.8801 - accuracy: 0.7185 - val_loss: 0.8005 - val_accuracy: 0.7639\n",
            "Epoch 9/300\n",
            "137/137 [==============================] - 1s 7ms/step - loss: 0.8575 - accuracy: 0.7218 - val_loss: 0.7701 - val_accuracy: 0.7653\n",
            "Epoch 10/300\n",
            "137/137 [==============================] - 1s 7ms/step - loss: 0.8214 - accuracy: 0.7437 - val_loss: 0.7298 - val_accuracy: 0.7701\n",
            "Epoch 11/300\n",
            "137/137 [==============================] - 1s 7ms/step - loss: 0.7844 - accuracy: 0.7462 - val_loss: 0.7416 - val_accuracy: 0.7804\n",
            "Epoch 12/300\n",
            "137/137 [==============================] - 1s 7ms/step - loss: 0.7555 - accuracy: 0.7603 - val_loss: 0.6992 - val_accuracy: 0.7879\n",
            "Epoch 13/300\n",
            "137/137 [==============================] - 1s 7ms/step - loss: 0.7473 - accuracy: 0.7626 - val_loss: 0.6754 - val_accuracy: 0.7982\n",
            "Epoch 14/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.7256 - accuracy: 0.7778 - val_loss: 0.6750 - val_accuracy: 0.7989\n",
            "Epoch 15/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.6856 - accuracy: 0.7824 - val_loss: 0.6509 - val_accuracy: 0.7975\n",
            "Epoch 16/300\n",
            "137/137 [==============================] - 1s 7ms/step - loss: 0.6842 - accuracy: 0.7774 - val_loss: 0.6928 - val_accuracy: 0.7948\n",
            "Epoch 17/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.6565 - accuracy: 0.7814 - val_loss: 0.6356 - val_accuracy: 0.8188\n",
            "Epoch 18/300\n",
            "137/137 [==============================] - 1s 7ms/step - loss: 0.5924 - accuracy: 0.8076 - val_loss: 0.6289 - val_accuracy: 0.8037\n",
            "Epoch 19/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.6361 - accuracy: 0.7961 - val_loss: 0.6502 - val_accuracy: 0.8085\n",
            "Epoch 20/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.6124 - accuracy: 0.7983 - val_loss: 0.6592 - val_accuracy: 0.8058\n",
            "Epoch 21/300\n",
            "137/137 [==============================] - 1s 7ms/step - loss: 0.5955 - accuracy: 0.8123 - val_loss: 0.6278 - val_accuracy: 0.8085\n",
            "Epoch 22/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.5742 - accuracy: 0.8094 - val_loss: 0.6116 - val_accuracy: 0.8250\n",
            "Epoch 23/300\n",
            "137/137 [==============================] - 1s 7ms/step - loss: 0.5609 - accuracy: 0.8213 - val_loss: 0.6246 - val_accuracy: 0.8312\n",
            "Epoch 24/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.5565 - accuracy: 0.8244 - val_loss: 0.5819 - val_accuracy: 0.8298\n",
            "Epoch 25/300\n",
            "137/137 [==============================] - 1s 7ms/step - loss: 0.5357 - accuracy: 0.8243 - val_loss: 0.5860 - val_accuracy: 0.8305\n",
            "Epoch 26/300\n",
            "137/137 [==============================] - 1s 7ms/step - loss: 0.5749 - accuracy: 0.8098 - val_loss: 0.5957 - val_accuracy: 0.8339\n",
            "Epoch 27/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.5574 - accuracy: 0.8270 - val_loss: 0.5965 - val_accuracy: 0.8250\n",
            "Epoch 28/300\n",
            "137/137 [==============================] - 1s 7ms/step - loss: 0.5165 - accuracy: 0.8309 - val_loss: 0.5677 - val_accuracy: 0.8456\n",
            "Epoch 29/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.5456 - accuracy: 0.8247 - val_loss: 0.5798 - val_accuracy: 0.8305\n",
            "Epoch 30/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.5076 - accuracy: 0.8341 - val_loss: 0.5806 - val_accuracy: 0.8428\n",
            "Epoch 31/300\n",
            "137/137 [==============================] - 1s 7ms/step - loss: 0.5227 - accuracy: 0.8292 - val_loss: 0.5904 - val_accuracy: 0.8325\n",
            "Epoch 32/300\n",
            "137/137 [==============================] - 1s 7ms/step - loss: 0.5059 - accuracy: 0.8334 - val_loss: 0.6008 - val_accuracy: 0.8312\n",
            "Epoch 33/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.4635 - accuracy: 0.8477 - val_loss: 0.5856 - val_accuracy: 0.8353\n",
            "Epoch 34/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.4915 - accuracy: 0.8414 - val_loss: 0.5669 - val_accuracy: 0.8476\n",
            "Epoch 35/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.4844 - accuracy: 0.8429 - val_loss: 0.5900 - val_accuracy: 0.8318\n",
            "Epoch 36/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.5048 - accuracy: 0.8364 - val_loss: 0.5703 - val_accuracy: 0.8394\n",
            "Epoch 37/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.4396 - accuracy: 0.8611 - val_loss: 0.5614 - val_accuracy: 0.8380\n",
            "Epoch 38/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.4653 - accuracy: 0.8385 - val_loss: 0.5677 - val_accuracy: 0.8346\n",
            "Epoch 39/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.4419 - accuracy: 0.8573 - val_loss: 0.5807 - val_accuracy: 0.8318\n",
            "Epoch 40/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.4578 - accuracy: 0.8508 - val_loss: 0.5544 - val_accuracy: 0.8428\n",
            "Epoch 41/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.4412 - accuracy: 0.8519 - val_loss: 0.5939 - val_accuracy: 0.8270\n",
            "Epoch 42/300\n",
            "137/137 [==============================] - 1s 7ms/step - loss: 0.4504 - accuracy: 0.8557 - val_loss: 0.5906 - val_accuracy: 0.8229\n",
            "Epoch 43/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.4233 - accuracy: 0.8629 - val_loss: 0.5717 - val_accuracy: 0.8380\n",
            "Epoch 44/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.4289 - accuracy: 0.8616 - val_loss: 0.5516 - val_accuracy: 0.8442\n",
            "Epoch 45/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.4222 - accuracy: 0.8556 - val_loss: 0.5607 - val_accuracy: 0.8490\n",
            "Epoch 46/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.4074 - accuracy: 0.8614 - val_loss: 0.5960 - val_accuracy: 0.8387\n",
            "Epoch 47/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.4229 - accuracy: 0.8603 - val_loss: 0.5761 - val_accuracy: 0.8380\n",
            "Epoch 48/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.4222 - accuracy: 0.8642 - val_loss: 0.5579 - val_accuracy: 0.8483\n",
            "Epoch 49/300\n",
            "137/137 [==============================] - 1s 7ms/step - loss: 0.3948 - accuracy: 0.8759 - val_loss: 0.5647 - val_accuracy: 0.8511\n",
            "Epoch 50/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.3904 - accuracy: 0.8771 - val_loss: 0.5631 - val_accuracy: 0.8415\n",
            "Epoch 51/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.4168 - accuracy: 0.8605 - val_loss: 0.5720 - val_accuracy: 0.8346\n",
            "Epoch 52/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.3909 - accuracy: 0.8728 - val_loss: 0.5726 - val_accuracy: 0.8463\n",
            "Epoch 53/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.3695 - accuracy: 0.8840 - val_loss: 0.5590 - val_accuracy: 0.8469\n",
            "Epoch 54/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.3870 - accuracy: 0.8721 - val_loss: 0.5706 - val_accuracy: 0.8415\n",
            "Epoch 55/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.3943 - accuracy: 0.8734 - val_loss: 0.5766 - val_accuracy: 0.8442\n",
            "Epoch 56/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.3787 - accuracy: 0.8776 - val_loss: 0.5697 - val_accuracy: 0.8325\n",
            "Epoch 57/300\n",
            "137/137 [==============================] - 1s 7ms/step - loss: 0.3926 - accuracy: 0.8701 - val_loss: 0.5709 - val_accuracy: 0.8456\n",
            "Epoch 58/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.3917 - accuracy: 0.8688 - val_loss: 0.5609 - val_accuracy: 0.8428\n",
            "Epoch 59/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.3657 - accuracy: 0.8701 - val_loss: 0.5615 - val_accuracy: 0.8504\n",
            "Epoch 60/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.3681 - accuracy: 0.8796 - val_loss: 0.5699 - val_accuracy: 0.8353\n",
            "Epoch 61/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.3666 - accuracy: 0.8767 - val_loss: 0.5618 - val_accuracy: 0.8490\n",
            "Epoch 62/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.3529 - accuracy: 0.8793 - val_loss: 0.5496 - val_accuracy: 0.8463\n",
            "Epoch 63/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.3296 - accuracy: 0.8842 - val_loss: 0.5548 - val_accuracy: 0.8373\n",
            "Epoch 64/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.3316 - accuracy: 0.8947 - val_loss: 0.5800 - val_accuracy: 0.8483\n",
            "Epoch 65/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.3420 - accuracy: 0.8802 - val_loss: 0.5352 - val_accuracy: 0.8552\n",
            "Epoch 66/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.3557 - accuracy: 0.8791 - val_loss: 0.5549 - val_accuracy: 0.8531\n",
            "Epoch 67/300\n",
            "137/137 [==============================] - 1s 7ms/step - loss: 0.3541 - accuracy: 0.8839 - val_loss: 0.5732 - val_accuracy: 0.8394\n",
            "Epoch 68/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.3630 - accuracy: 0.8762 - val_loss: 0.5704 - val_accuracy: 0.8435\n",
            "Epoch 69/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.3570 - accuracy: 0.8792 - val_loss: 0.5618 - val_accuracy: 0.8463\n",
            "Epoch 70/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.3788 - accuracy: 0.8728 - val_loss: 0.5473 - val_accuracy: 0.8497\n",
            "Epoch 71/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.3382 - accuracy: 0.8927 - val_loss: 0.5664 - val_accuracy: 0.8504\n",
            "Epoch 72/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.3525 - accuracy: 0.8806 - val_loss: 0.5494 - val_accuracy: 0.8511\n",
            "Epoch 73/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.3349 - accuracy: 0.8923 - val_loss: 0.5886 - val_accuracy: 0.8456\n",
            "Epoch 74/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.3478 - accuracy: 0.8886 - val_loss: 0.5416 - val_accuracy: 0.8524\n",
            "Epoch 75/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.3538 - accuracy: 0.8845 - val_loss: 0.5549 - val_accuracy: 0.8545\n",
            "Epoch 76/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.3531 - accuracy: 0.8837 - val_loss: 0.5428 - val_accuracy: 0.8524\n",
            "Epoch 77/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.3261 - accuracy: 0.8900 - val_loss: 0.5846 - val_accuracy: 0.8463\n",
            "Epoch 78/300\n",
            "137/137 [==============================] - 1s 7ms/step - loss: 0.3058 - accuracy: 0.8994 - val_loss: 0.5748 - val_accuracy: 0.8497\n",
            "Epoch 79/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.3209 - accuracy: 0.8953 - val_loss: 0.5545 - val_accuracy: 0.8490\n",
            "Epoch 80/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.3477 - accuracy: 0.8884 - val_loss: 0.5783 - val_accuracy: 0.8483\n",
            "Epoch 81/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.3129 - accuracy: 0.9036 - val_loss: 0.5480 - val_accuracy: 0.8483\n",
            "Epoch 82/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.3146 - accuracy: 0.9025 - val_loss: 0.5641 - val_accuracy: 0.8463\n",
            "Epoch 83/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.3105 - accuracy: 0.8955 - val_loss: 0.5532 - val_accuracy: 0.8435\n",
            "Epoch 84/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.3263 - accuracy: 0.8976 - val_loss: 0.5560 - val_accuracy: 0.8566\n",
            "Epoch 85/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.2797 - accuracy: 0.9079 - val_loss: 0.5730 - val_accuracy: 0.8607\n",
            "Epoch 86/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.2982 - accuracy: 0.9010 - val_loss: 0.5596 - val_accuracy: 0.8586\n",
            "Epoch 87/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.2832 - accuracy: 0.9047 - val_loss: 0.5383 - val_accuracy: 0.8518\n",
            "Epoch 88/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.2722 - accuracy: 0.9111 - val_loss: 0.5538 - val_accuracy: 0.8559\n",
            "Epoch 89/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.2989 - accuracy: 0.9065 - val_loss: 0.5681 - val_accuracy: 0.8476\n",
            "Epoch 90/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.2866 - accuracy: 0.9096 - val_loss: 0.5623 - val_accuracy: 0.8497\n",
            "Epoch 91/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.2833 - accuracy: 0.9042 - val_loss: 0.5372 - val_accuracy: 0.8490\n",
            "Epoch 92/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.3221 - accuracy: 0.8937 - val_loss: 0.5479 - val_accuracy: 0.8511\n",
            "Epoch 93/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.3278 - accuracy: 0.8926 - val_loss: 0.5428 - val_accuracy: 0.8531\n",
            "Epoch 94/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.2872 - accuracy: 0.9067 - val_loss: 0.5535 - val_accuracy: 0.8524\n",
            "Epoch 95/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.3031 - accuracy: 0.9018 - val_loss: 0.5619 - val_accuracy: 0.8394\n",
            "Epoch 96/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.2961 - accuracy: 0.9080 - val_loss: 0.5702 - val_accuracy: 0.8504\n",
            "Epoch 97/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.3145 - accuracy: 0.9007 - val_loss: 0.5383 - val_accuracy: 0.8538\n",
            "Epoch 98/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.3185 - accuracy: 0.9033 - val_loss: 0.5555 - val_accuracy: 0.8655\n",
            "Epoch 99/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.2892 - accuracy: 0.9055 - val_loss: 0.5669 - val_accuracy: 0.8504\n",
            "Epoch 100/300\n",
            "137/137 [==============================] - 1s 9ms/step - loss: 0.2601 - accuracy: 0.9148 - val_loss: 0.5526 - val_accuracy: 0.8435\n",
            "Epoch 101/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.2945 - accuracy: 0.9067 - val_loss: 0.5661 - val_accuracy: 0.8497\n",
            "Epoch 102/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.2838 - accuracy: 0.9096 - val_loss: 0.5567 - val_accuracy: 0.8511\n",
            "Epoch 103/300\n",
            "137/137 [==============================] - 1s 9ms/step - loss: 0.2752 - accuracy: 0.9027 - val_loss: 0.5796 - val_accuracy: 0.8463\n",
            "Epoch 104/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.3067 - accuracy: 0.9032 - val_loss: 0.5798 - val_accuracy: 0.8559\n",
            "Epoch 105/300\n",
            "137/137 [==============================] - 1s 8ms/step - loss: 0.2761 - accuracy: 0.9106 - val_loss: 0.5397 - val_accuracy: 0.8538\n",
            "5\n",
            "model 0\n",
            "Epoch 1/300\n",
            "9/9 [==============================] - 5s 280ms/step - loss: 2.2542 - accuracy: 0.1178 - val_loss: 2.1757 - val_accuracy: 0.1737\n",
            "Epoch 2/300\n",
            "9/9 [==============================] - 2s 219ms/step - loss: 2.1167 - accuracy: 0.2079 - val_loss: 1.9759 - val_accuracy: 0.2999\n",
            "Epoch 3/300\n",
            "9/9 [==============================] - 2s 218ms/step - loss: 1.9686 - accuracy: 0.2756 - val_loss: 1.8541 - val_accuracy: 0.3246\n",
            "Epoch 4/300\n",
            "9/9 [==============================] - 2s 223ms/step - loss: 1.8896 - accuracy: 0.2978 - val_loss: 1.7798 - val_accuracy: 0.3440\n",
            "Epoch 5/300\n",
            "9/9 [==============================] - 2s 256ms/step - loss: 1.7944 - accuracy: 0.3356 - val_loss: 1.6731 - val_accuracy: 0.4162\n",
            "Epoch 6/300\n",
            "9/9 [==============================] - 2s 228ms/step - loss: 1.6694 - accuracy: 0.3899 - val_loss: 1.5622 - val_accuracy: 0.4462\n",
            "Epoch 7/300\n",
            "9/9 [==============================] - 2s 228ms/step - loss: 1.5602 - accuracy: 0.4275 - val_loss: 1.4170 - val_accuracy: 0.5104\n",
            "Epoch 8/300\n",
            "9/9 [==============================] - 2s 222ms/step - loss: 1.4242 - accuracy: 0.4961 - val_loss: 1.2854 - val_accuracy: 0.5638\n",
            "Epoch 9/300\n",
            "9/9 [==============================] - 2s 222ms/step - loss: 1.2799 - accuracy: 0.5651 - val_loss: 1.1752 - val_accuracy: 0.5999\n",
            "Epoch 10/300\n",
            "9/9 [==============================] - 2s 218ms/step - loss: 1.1589 - accuracy: 0.5992 - val_loss: 1.1247 - val_accuracy: 0.6273\n",
            "Epoch 11/300\n",
            "9/9 [==============================] - 2s 225ms/step - loss: 1.0883 - accuracy: 0.6360 - val_loss: 1.0706 - val_accuracy: 0.6406\n",
            "Epoch 12/300\n",
            "9/9 [==============================] - 2s 222ms/step - loss: 0.9998 - accuracy: 0.6728 - val_loss: 0.9815 - val_accuracy: 0.6754\n",
            "Epoch 13/300\n",
            "9/9 [==============================] - 2s 221ms/step - loss: 0.9143 - accuracy: 0.6982 - val_loss: 0.9311 - val_accuracy: 0.7021\n",
            "Epoch 14/300\n",
            "9/9 [==============================] - 2s 222ms/step - loss: 0.8362 - accuracy: 0.7288 - val_loss: 0.8707 - val_accuracy: 0.7295\n",
            "Epoch 15/300\n",
            "9/9 [==============================] - 2s 224ms/step - loss: 0.7336 - accuracy: 0.7676 - val_loss: 0.8280 - val_accuracy: 0.7442\n",
            "Epoch 16/300\n",
            "9/9 [==============================] - 2s 218ms/step - loss: 0.6513 - accuracy: 0.7991 - val_loss: 0.8060 - val_accuracy: 0.7508\n",
            "Epoch 17/300\n",
            "9/9 [==============================] - 2s 221ms/step - loss: 0.6045 - accuracy: 0.8048 - val_loss: 0.7705 - val_accuracy: 0.7715\n",
            "Epoch 18/300\n",
            "9/9 [==============================] - 2s 217ms/step - loss: 0.5497 - accuracy: 0.8351 - val_loss: 0.7840 - val_accuracy: 0.7568\n",
            "Epoch 19/300\n",
            "9/9 [==============================] - 2s 225ms/step - loss: 0.5300 - accuracy: 0.8383 - val_loss: 0.7331 - val_accuracy: 0.7882\n",
            "Epoch 20/300\n",
            "9/9 [==============================] - 2s 226ms/step - loss: 0.4992 - accuracy: 0.8407 - val_loss: 0.7245 - val_accuracy: 0.7983\n",
            "Epoch 21/300\n",
            "9/9 [==============================] - 2s 221ms/step - loss: 0.4297 - accuracy: 0.8682 - val_loss: 0.7051 - val_accuracy: 0.7876\n",
            "Epoch 22/300\n",
            "9/9 [==============================] - 2s 224ms/step - loss: 0.4124 - accuracy: 0.8700 - val_loss: 0.7179 - val_accuracy: 0.8036\n",
            "Epoch 23/300\n",
            "9/9 [==============================] - 2s 229ms/step - loss: 0.3904 - accuracy: 0.8802 - val_loss: 0.7416 - val_accuracy: 0.7956\n",
            "Epoch 24/300\n",
            "9/9 [==============================] - 2s 218ms/step - loss: 0.3739 - accuracy: 0.8801 - val_loss: 0.7156 - val_accuracy: 0.8049\n",
            "Epoch 25/300\n",
            "9/9 [==============================] - 2s 221ms/step - loss: 0.3255 - accuracy: 0.9006 - val_loss: 0.7444 - val_accuracy: 0.7936\n",
            "Epoch 26/300\n",
            "9/9 [==============================] - 2s 227ms/step - loss: 0.3371 - accuracy: 0.8849 - val_loss: 0.7560 - val_accuracy: 0.7822\n",
            "Epoch 27/300\n",
            "9/9 [==============================] - 2s 219ms/step - loss: 0.3082 - accuracy: 0.9029 - val_loss: 0.7205 - val_accuracy: 0.8029\n",
            "Epoch 28/300\n",
            "9/9 [==============================] - 2s 216ms/step - loss: 0.3072 - accuracy: 0.9010 - val_loss: 0.6613 - val_accuracy: 0.8250\n",
            "Epoch 29/300\n",
            "9/9 [==============================] - 2s 214ms/step - loss: 0.2539 - accuracy: 0.9223 - val_loss: 0.7289 - val_accuracy: 0.8023\n",
            "Epoch 30/300\n",
            "9/9 [==============================] - 2s 215ms/step - loss: 0.2173 - accuracy: 0.9366 - val_loss: 0.6607 - val_accuracy: 0.8290\n",
            "Epoch 31/300\n",
            "9/9 [==============================] - 2s 212ms/step - loss: 0.2026 - accuracy: 0.9403 - val_loss: 0.6921 - val_accuracy: 0.8210\n",
            "Epoch 32/300\n",
            "9/9 [==============================] - 2s 213ms/step - loss: 0.1894 - accuracy: 0.9432 - val_loss: 0.6657 - val_accuracy: 0.8337\n",
            "Epoch 33/300\n",
            "9/9 [==============================] - 2s 218ms/step - loss: 0.1693 - accuracy: 0.9540 - val_loss: 0.6758 - val_accuracy: 0.8310\n",
            "Epoch 34/300\n",
            "9/9 [==============================] - 2s 216ms/step - loss: 0.1528 - accuracy: 0.9531 - val_loss: 0.7135 - val_accuracy: 0.8143\n",
            "Epoch 35/300\n",
            "9/9 [==============================] - 2s 218ms/step - loss: 0.1668 - accuracy: 0.9459 - val_loss: 0.7083 - val_accuracy: 0.8283\n",
            "Epoch 36/300\n",
            "9/9 [==============================] - 2s 219ms/step - loss: 0.1279 - accuracy: 0.9641 - val_loss: 0.7335 - val_accuracy: 0.8277\n",
            "Epoch 37/300\n",
            "9/9 [==============================] - 2s 219ms/step - loss: 0.1290 - accuracy: 0.9584 - val_loss: 0.7497 - val_accuracy: 0.8176\n",
            "Epoch 38/300\n",
            "9/9 [==============================] - 2s 216ms/step - loss: 0.1065 - accuracy: 0.9700 - val_loss: 0.7452 - val_accuracy: 0.8290\n",
            "Epoch 39/300\n",
            "9/9 [==============================] - 2s 217ms/step - loss: 0.0949 - accuracy: 0.9769 - val_loss: 0.7483 - val_accuracy: 0.8323\n",
            "Epoch 40/300\n",
            "9/9 [==============================] - 2s 217ms/step - loss: 0.0829 - accuracy: 0.9779 - val_loss: 0.7565 - val_accuracy: 0.8357\n",
            "Epoch 41/300\n",
            "9/9 [==============================] - 2s 219ms/step - loss: 0.0886 - accuracy: 0.9763 - val_loss: 0.8313 - val_accuracy: 0.8263\n",
            "Epoch 42/300\n",
            "9/9 [==============================] - 2s 221ms/step - loss: 0.1004 - accuracy: 0.9708 - val_loss: 0.8036 - val_accuracy: 0.8317\n",
            "Epoch 43/300\n",
            "9/9 [==============================] - 2s 216ms/step - loss: 0.0803 - accuracy: 0.9789 - val_loss: 0.8024 - val_accuracy: 0.8310\n",
            "Epoch 44/300\n",
            "9/9 [==============================] - 2s 219ms/step - loss: 0.0725 - accuracy: 0.9802 - val_loss: 0.8287 - val_accuracy: 0.8236\n",
            "Epoch 45/300\n",
            "9/9 [==============================] - 2s 219ms/step - loss: 0.0969 - accuracy: 0.9674 - val_loss: 0.8695 - val_accuracy: 0.8163\n",
            "Epoch 46/300\n",
            "9/9 [==============================] - 2s 217ms/step - loss: 0.1231 - accuracy: 0.9575 - val_loss: 0.8545 - val_accuracy: 0.8183\n",
            "Epoch 47/300\n",
            "9/9 [==============================] - 2s 215ms/step - loss: 0.0974 - accuracy: 0.9654 - val_loss: 0.8711 - val_accuracy: 0.8243\n",
            "Epoch 48/300\n",
            "9/9 [==============================] - 2s 217ms/step - loss: 0.0811 - accuracy: 0.9745 - val_loss: 0.8178 - val_accuracy: 0.8397\n",
            "Epoch 49/300\n",
            "9/9 [==============================] - 2s 219ms/step - loss: 0.0602 - accuracy: 0.9843 - val_loss: 0.8351 - val_accuracy: 0.8270\n",
            "Epoch 50/300\n",
            "9/9 [==============================] - 2s 215ms/step - loss: 0.0536 - accuracy: 0.9883 - val_loss: 0.8775 - val_accuracy: 0.8317\n",
            "Epoch 51/300\n",
            "9/9 [==============================] - 2s 214ms/step - loss: 0.0510 - accuracy: 0.9846 - val_loss: 0.9148 - val_accuracy: 0.8343\n",
            "Epoch 52/300\n",
            "9/9 [==============================] - 2s 216ms/step - loss: 0.0396 - accuracy: 0.9910 - val_loss: 0.8561 - val_accuracy: 0.8350\n",
            "Epoch 53/300\n",
            "9/9 [==============================] - 2s 216ms/step - loss: 0.0337 - accuracy: 0.9935 - val_loss: 0.8844 - val_accuracy: 0.8390\n",
            "Epoch 54/300\n",
            "9/9 [==============================] - 2s 215ms/step - loss: 0.0317 - accuracy: 0.9940 - val_loss: 0.9086 - val_accuracy: 0.8290\n",
            "Epoch 55/300\n",
            "9/9 [==============================] - 2s 217ms/step - loss: 0.0259 - accuracy: 0.9958 - val_loss: 0.9491 - val_accuracy: 0.8243\n",
            "Epoch 56/300\n",
            "9/9 [==============================] - 2s 218ms/step - loss: 0.0293 - accuracy: 0.9931 - val_loss: 0.9133 - val_accuracy: 0.8350\n",
            "Epoch 57/300\n",
            "9/9 [==============================] - 2s 216ms/step - loss: 0.0261 - accuracy: 0.9953 - val_loss: 0.9349 - val_accuracy: 0.8390\n",
            "Epoch 58/300\n",
            "9/9 [==============================] - 2s 218ms/step - loss: 0.0183 - accuracy: 0.9983 - val_loss: 0.9358 - val_accuracy: 0.8390\n",
            "Epoch 59/300\n",
            "9/9 [==============================] - 2s 220ms/step - loss: 0.0175 - accuracy: 0.9981 - val_loss: 0.9434 - val_accuracy: 0.8337\n",
            "Epoch 60/300\n",
            "9/9 [==============================] - 2s 221ms/step - loss: 0.0189 - accuracy: 0.9975 - val_loss: 0.9621 - val_accuracy: 0.8337\n",
            "Epoch 61/300\n",
            "9/9 [==============================] - 2s 217ms/step - loss: 0.0160 - accuracy: 0.9973 - val_loss: 0.9681 - val_accuracy: 0.8370\n",
            "Epoch 62/300\n",
            "9/9 [==============================] - 2s 217ms/step - loss: 0.0183 - accuracy: 0.9966 - val_loss: 0.9723 - val_accuracy: 0.8343\n",
            "Epoch 63/300\n",
            "9/9 [==============================] - 2s 216ms/step - loss: 0.0177 - accuracy: 0.9970 - val_loss: 0.9627 - val_accuracy: 0.8397\n",
            "Epoch 64/300\n",
            "9/9 [==============================] - 2s 216ms/step - loss: 0.0229 - accuracy: 0.9948 - val_loss: 1.1008 - val_accuracy: 0.8110\n",
            "Epoch 65/300\n",
            "9/9 [==============================] - 2s 218ms/step - loss: 0.0319 - accuracy: 0.9915 - val_loss: 1.0705 - val_accuracy: 0.8190\n",
            "Epoch 66/300\n",
            "9/9 [==============================] - 2s 216ms/step - loss: 0.0416 - accuracy: 0.9882 - val_loss: 1.0287 - val_accuracy: 0.8290\n",
            "Epoch 67/300\n",
            "9/9 [==============================] - 2s 214ms/step - loss: 0.0311 - accuracy: 0.9912 - val_loss: 0.9786 - val_accuracy: 0.8337\n",
            "Epoch 68/300\n",
            "9/9 [==============================] - 2s 216ms/step - loss: 0.0293 - accuracy: 0.9919 - val_loss: 0.9766 - val_accuracy: 0.8310\n",
            "Epoch 69/300\n",
            "9/9 [==============================] - 2s 215ms/step - loss: 0.0230 - accuracy: 0.9949 - val_loss: 1.0597 - val_accuracy: 0.8270\n",
            "Epoch 70/300\n",
            "9/9 [==============================] - 2s 215ms/step - loss: 0.0143 - accuracy: 0.9980 - val_loss: 1.0373 - val_accuracy: 0.8277\n",
            "model 1\n",
            "Epoch 1/300\n",
            "9/9 [==============================] - 5s 373ms/step - loss: 2.2101 - accuracy: 0.1653 - val_loss: 1.9008 - val_accuracy: 0.3347\n",
            "Epoch 2/300\n",
            "9/9 [==============================] - 3s 325ms/step - loss: 1.8765 - accuracy: 0.3479 - val_loss: 1.6362 - val_accuracy: 0.4729\n",
            "Epoch 3/300\n",
            "9/9 [==============================] - 3s 329ms/step - loss: 1.5901 - accuracy: 0.4666 - val_loss: 1.4249 - val_accuracy: 0.5424\n",
            "Epoch 4/300\n",
            "9/9 [==============================] - 3s 322ms/step - loss: 1.4594 - accuracy: 0.5128 - val_loss: 1.2733 - val_accuracy: 0.5845\n",
            "Epoch 5/300\n",
            "9/9 [==============================] - 3s 314ms/step - loss: 1.3039 - accuracy: 0.5753 - val_loss: 1.1711 - val_accuracy: 0.6353\n",
            "Epoch 6/300\n",
            "9/9 [==============================] - 3s 324ms/step - loss: 1.1909 - accuracy: 0.6152 - val_loss: 1.0800 - val_accuracy: 0.6587\n",
            "Epoch 7/300\n",
            "9/9 [==============================] - 3s 325ms/step - loss: 1.1416 - accuracy: 0.6293 - val_loss: 1.0004 - val_accuracy: 0.7007\n",
            "Epoch 8/300\n",
            "9/9 [==============================] - 3s 322ms/step - loss: 1.0690 - accuracy: 0.6465 - val_loss: 0.9632 - val_accuracy: 0.7148\n",
            "Epoch 9/300\n",
            "9/9 [==============================] - 3s 322ms/step - loss: 1.0171 - accuracy: 0.6816 - val_loss: 0.9255 - val_accuracy: 0.7141\n",
            "Epoch 10/300\n",
            "9/9 [==============================] - 3s 323ms/step - loss: 0.9489 - accuracy: 0.6927 - val_loss: 0.8924 - val_accuracy: 0.7194\n",
            "Epoch 11/300\n",
            "9/9 [==============================] - 3s 325ms/step - loss: 0.9138 - accuracy: 0.7083 - val_loss: 0.8153 - val_accuracy: 0.7568\n",
            "Epoch 12/300\n",
            "9/9 [==============================] - 3s 325ms/step - loss: 0.8670 - accuracy: 0.7219 - val_loss: 0.8043 - val_accuracy: 0.7609\n",
            "Epoch 13/300\n",
            "9/9 [==============================] - 3s 326ms/step - loss: 0.8314 - accuracy: 0.7335 - val_loss: 0.7362 - val_accuracy: 0.7869\n",
            "Epoch 14/300\n",
            "9/9 [==============================] - 3s 329ms/step - loss: 0.7880 - accuracy: 0.7544 - val_loss: 0.7061 - val_accuracy: 0.7969\n",
            "Epoch 15/300\n",
            "9/9 [==============================] - 3s 325ms/step - loss: 0.7292 - accuracy: 0.7624 - val_loss: 0.6859 - val_accuracy: 0.8003\n",
            "Epoch 16/300\n",
            "9/9 [==============================] - 3s 324ms/step - loss: 0.7204 - accuracy: 0.7658 - val_loss: 0.6757 - val_accuracy: 0.8036\n",
            "Epoch 17/300\n",
            "9/9 [==============================] - 3s 325ms/step - loss: 0.6894 - accuracy: 0.7787 - val_loss: 0.6432 - val_accuracy: 0.8170\n",
            "Epoch 18/300\n",
            "9/9 [==============================] - 3s 325ms/step - loss: 0.6571 - accuracy: 0.7890 - val_loss: 0.6302 - val_accuracy: 0.8136\n",
            "Epoch 19/300\n",
            "9/9 [==============================] - 3s 327ms/step - loss: 0.6517 - accuracy: 0.7849 - val_loss: 0.6154 - val_accuracy: 0.8210\n",
            "Epoch 20/300\n",
            "9/9 [==============================] - 3s 326ms/step - loss: 0.5875 - accuracy: 0.8138 - val_loss: 0.5867 - val_accuracy: 0.8310\n",
            "Epoch 21/300\n",
            "9/9 [==============================] - 3s 326ms/step - loss: 0.5846 - accuracy: 0.8125 - val_loss: 0.6119 - val_accuracy: 0.8236\n",
            "Epoch 22/300\n",
            "9/9 [==============================] - 3s 326ms/step - loss: 0.5438 - accuracy: 0.8305 - val_loss: 0.5851 - val_accuracy: 0.8330\n",
            "Epoch 23/300\n",
            "9/9 [==============================] - 3s 331ms/step - loss: 0.5631 - accuracy: 0.8118 - val_loss: 0.5777 - val_accuracy: 0.8397\n",
            "Epoch 24/300\n",
            "9/9 [==============================] - 3s 329ms/step - loss: 0.5341 - accuracy: 0.8286 - val_loss: 0.5731 - val_accuracy: 0.8330\n",
            "Epoch 25/300\n",
            "9/9 [==============================] - 3s 325ms/step - loss: 0.5153 - accuracy: 0.8337 - val_loss: 0.5462 - val_accuracy: 0.8430\n",
            "Epoch 26/300\n",
            "9/9 [==============================] - 3s 327ms/step - loss: 0.4959 - accuracy: 0.8392 - val_loss: 0.5509 - val_accuracy: 0.8450\n",
            "Epoch 27/300\n",
            "9/9 [==============================] - 3s 336ms/step - loss: 0.4721 - accuracy: 0.8464 - val_loss: 0.5587 - val_accuracy: 0.8397\n",
            "Epoch 28/300\n",
            "9/9 [==============================] - 3s 330ms/step - loss: 0.4496 - accuracy: 0.8540 - val_loss: 0.5403 - val_accuracy: 0.8457\n",
            "Epoch 29/300\n",
            "9/9 [==============================] - 3s 332ms/step - loss: 0.4272 - accuracy: 0.8599 - val_loss: 0.5414 - val_accuracy: 0.8530\n",
            "Epoch 30/300\n",
            "9/9 [==============================] - 3s 329ms/step - loss: 0.4395 - accuracy: 0.8534 - val_loss: 0.5406 - val_accuracy: 0.8450\n",
            "Epoch 31/300\n",
            "9/9 [==============================] - 3s 325ms/step - loss: 0.4149 - accuracy: 0.8615 - val_loss: 0.5448 - val_accuracy: 0.8370\n",
            "Epoch 32/300\n",
            "9/9 [==============================] - 3s 325ms/step - loss: 0.3854 - accuracy: 0.8754 - val_loss: 0.5499 - val_accuracy: 0.8497\n",
            "Epoch 33/300\n",
            "9/9 [==============================] - 3s 322ms/step - loss: 0.4043 - accuracy: 0.8699 - val_loss: 0.5497 - val_accuracy: 0.8510\n",
            "Epoch 34/300\n",
            "9/9 [==============================] - 3s 319ms/step - loss: 0.3808 - accuracy: 0.8731 - val_loss: 0.5109 - val_accuracy: 0.8497\n",
            "Epoch 35/300\n",
            "9/9 [==============================] - 3s 319ms/step - loss: 0.3499 - accuracy: 0.8803 - val_loss: 0.5266 - val_accuracy: 0.8530\n",
            "Epoch 36/300\n",
            "9/9 [==============================] - 3s 319ms/step - loss: 0.3340 - accuracy: 0.8940 - val_loss: 0.5645 - val_accuracy: 0.8383\n",
            "Epoch 37/300\n",
            "9/9 [==============================] - 3s 325ms/step - loss: 0.3515 - accuracy: 0.8823 - val_loss: 0.5153 - val_accuracy: 0.8524\n",
            "Epoch 38/300\n",
            "9/9 [==============================] - 3s 336ms/step - loss: 0.3443 - accuracy: 0.8816 - val_loss: 0.5086 - val_accuracy: 0.8584\n",
            "Epoch 39/300\n",
            "9/9 [==============================] - 3s 324ms/step - loss: 0.3278 - accuracy: 0.8913 - val_loss: 0.5633 - val_accuracy: 0.8383\n",
            "Epoch 40/300\n",
            "9/9 [==============================] - 3s 326ms/step - loss: 0.3258 - accuracy: 0.8875 - val_loss: 0.5299 - val_accuracy: 0.8504\n",
            "Epoch 41/300\n",
            "9/9 [==============================] - 3s 325ms/step - loss: 0.3230 - accuracy: 0.8957 - val_loss: 0.5066 - val_accuracy: 0.8570\n",
            "Epoch 42/300\n",
            "9/9 [==============================] - 3s 321ms/step - loss: 0.2976 - accuracy: 0.9037 - val_loss: 0.5232 - val_accuracy: 0.8611\n",
            "Epoch 43/300\n",
            "9/9 [==============================] - 3s 317ms/step - loss: 0.2860 - accuracy: 0.9085 - val_loss: 0.5425 - val_accuracy: 0.8437\n",
            "Epoch 44/300\n",
            "9/9 [==============================] - 3s 319ms/step - loss: 0.2841 - accuracy: 0.9035 - val_loss: 0.5623 - val_accuracy: 0.8343\n",
            "Epoch 45/300\n",
            "9/9 [==============================] - 3s 322ms/step - loss: 0.2914 - accuracy: 0.9032 - val_loss: 0.5275 - val_accuracy: 0.8504\n",
            "Epoch 46/300\n",
            "9/9 [==============================] - 3s 325ms/step - loss: 0.2652 - accuracy: 0.9077 - val_loss: 0.5289 - val_accuracy: 0.8564\n",
            "Epoch 47/300\n",
            "9/9 [==============================] - 3s 323ms/step - loss: 0.2625 - accuracy: 0.9172 - val_loss: 0.5483 - val_accuracy: 0.8444\n",
            "Epoch 48/300\n",
            "9/9 [==============================] - 3s 318ms/step - loss: 0.2778 - accuracy: 0.9089 - val_loss: 0.5395 - val_accuracy: 0.8484\n",
            "Epoch 49/300\n",
            "9/9 [==============================] - 3s 316ms/step - loss: 0.2585 - accuracy: 0.9137 - val_loss: 0.5202 - val_accuracy: 0.8611\n",
            "Epoch 50/300\n",
            "9/9 [==============================] - 3s 321ms/step - loss: 0.2482 - accuracy: 0.9152 - val_loss: 0.5287 - val_accuracy: 0.8584\n",
            "Epoch 51/300\n",
            "9/9 [==============================] - 3s 330ms/step - loss: 0.2478 - accuracy: 0.9199 - val_loss: 0.5616 - val_accuracy: 0.8490\n",
            "Epoch 52/300\n",
            "9/9 [==============================] - 3s 321ms/step - loss: 0.2277 - accuracy: 0.9219 - val_loss: 0.5588 - val_accuracy: 0.8490\n",
            "Epoch 53/300\n",
            "9/9 [==============================] - 3s 320ms/step - loss: 0.2413 - accuracy: 0.9243 - val_loss: 0.5330 - val_accuracy: 0.8550\n",
            "Epoch 54/300\n",
            "9/9 [==============================] - 3s 319ms/step - loss: 0.2351 - accuracy: 0.9242 - val_loss: 0.5275 - val_accuracy: 0.8597\n",
            "Epoch 55/300\n",
            "9/9 [==============================] - 3s 328ms/step - loss: 0.2331 - accuracy: 0.9169 - val_loss: 0.5539 - val_accuracy: 0.8484\n",
            "Epoch 56/300\n",
            "9/9 [==============================] - 3s 323ms/step - loss: 0.2137 - accuracy: 0.9316 - val_loss: 0.5661 - val_accuracy: 0.8444\n",
            "Epoch 57/300\n",
            "9/9 [==============================] - 3s 327ms/step - loss: 0.2128 - accuracy: 0.9277 - val_loss: 0.5313 - val_accuracy: 0.8651\n",
            "Epoch 58/300\n",
            "9/9 [==============================] - 3s 325ms/step - loss: 0.2290 - accuracy: 0.9222 - val_loss: 0.5645 - val_accuracy: 0.8490\n",
            "Epoch 59/300\n",
            "9/9 [==============================] - 3s 330ms/step - loss: 0.2314 - accuracy: 0.9297 - val_loss: 0.5470 - val_accuracy: 0.8577\n",
            "Epoch 60/300\n",
            "9/9 [==============================] - 3s 322ms/step - loss: 0.2135 - accuracy: 0.9277 - val_loss: 0.5381 - val_accuracy: 0.8597\n",
            "Epoch 61/300\n",
            "9/9 [==============================] - 3s 324ms/step - loss: 0.1995 - accuracy: 0.9315 - val_loss: 0.5700 - val_accuracy: 0.8430\n",
            "Epoch 62/300\n",
            "9/9 [==============================] - 3s 334ms/step - loss: 0.2000 - accuracy: 0.9321 - val_loss: 0.5614 - val_accuracy: 0.8617\n",
            "Epoch 63/300\n",
            "9/9 [==============================] - 3s 326ms/step - loss: 0.1982 - accuracy: 0.9376 - val_loss: 0.5724 - val_accuracy: 0.8510\n",
            "Epoch 64/300\n",
            "9/9 [==============================] - 3s 323ms/step - loss: 0.1728 - accuracy: 0.9441 - val_loss: 0.5703 - val_accuracy: 0.8530\n",
            "Epoch 65/300\n",
            "9/9 [==============================] - 3s 324ms/step - loss: 0.1851 - accuracy: 0.9382 - val_loss: 0.5482 - val_accuracy: 0.8631\n",
            "Epoch 66/300\n",
            "9/9 [==============================] - 3s 326ms/step - loss: 0.1876 - accuracy: 0.9377 - val_loss: 0.5589 - val_accuracy: 0.8557\n",
            "Epoch 67/300\n",
            "9/9 [==============================] - 3s 323ms/step - loss: 0.1762 - accuracy: 0.9391 - val_loss: 0.5462 - val_accuracy: 0.8570\n",
            "Epoch 68/300\n",
            "9/9 [==============================] - 3s 321ms/step - loss: 0.1773 - accuracy: 0.9422 - val_loss: 0.5663 - val_accuracy: 0.8557\n",
            "Epoch 69/300\n",
            "9/9 [==============================] - 3s 325ms/step - loss: 0.1832 - accuracy: 0.9398 - val_loss: 0.5524 - val_accuracy: 0.8557\n",
            "Epoch 70/300\n",
            "9/9 [==============================] - 3s 324ms/step - loss: 0.1677 - accuracy: 0.9456 - val_loss: 0.5752 - val_accuracy: 0.8490\n",
            "Epoch 71/300\n",
            "9/9 [==============================] - 3s 323ms/step - loss: 0.1690 - accuracy: 0.9434 - val_loss: 0.5513 - val_accuracy: 0.8624\n",
            "Epoch 72/300\n",
            "9/9 [==============================] - 3s 325ms/step - loss: 0.1519 - accuracy: 0.9520 - val_loss: 0.5431 - val_accuracy: 0.8591\n",
            "Epoch 73/300\n",
            "9/9 [==============================] - 3s 328ms/step - loss: 0.1654 - accuracy: 0.9470 - val_loss: 0.5679 - val_accuracy: 0.8564\n",
            "Epoch 74/300\n",
            "9/9 [==============================] - 3s 318ms/step - loss: 0.1466 - accuracy: 0.9511 - val_loss: 0.5800 - val_accuracy: 0.8550\n",
            "Epoch 75/300\n",
            "9/9 [==============================] - 3s 320ms/step - loss: 0.1659 - accuracy: 0.9424 - val_loss: 0.5801 - val_accuracy: 0.8530\n",
            "Epoch 76/300\n",
            "9/9 [==============================] - 3s 316ms/step - loss: 0.1466 - accuracy: 0.9528 - val_loss: 0.5943 - val_accuracy: 0.8537\n",
            "Epoch 77/300\n",
            "9/9 [==============================] - 3s 320ms/step - loss: 0.1481 - accuracy: 0.9519 - val_loss: 0.5716 - val_accuracy: 0.8584\n",
            "Epoch 78/300\n",
            "9/9 [==============================] - 3s 317ms/step - loss: 0.1429 - accuracy: 0.9500 - val_loss: 0.5951 - val_accuracy: 0.8611\n",
            "Epoch 79/300\n",
            "9/9 [==============================] - 3s 321ms/step - loss: 0.1506 - accuracy: 0.9466 - val_loss: 0.5921 - val_accuracy: 0.8604\n",
            "Epoch 80/300\n",
            "9/9 [==============================] - 3s 328ms/step - loss: 0.1487 - accuracy: 0.9537 - val_loss: 0.5819 - val_accuracy: 0.8597\n",
            "Epoch 81/300\n",
            "9/9 [==============================] - 3s 322ms/step - loss: 0.1485 - accuracy: 0.9485 - val_loss: 0.5799 - val_accuracy: 0.8591\n",
            "model 2\n",
            "Epoch 1/300\n",
            "141/141 [==============================] - 2s 9ms/step - loss: 2.0596 - accuracy: 0.2415 - val_loss: 1.5814 - val_accuracy: 0.4362\n",
            "Epoch 2/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 1.4617 - accuracy: 0.5033 - val_loss: 1.2840 - val_accuracy: 0.5625\n",
            "Epoch 3/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 1.2403 - accuracy: 0.5933 - val_loss: 1.1012 - val_accuracy: 0.6566\n",
            "Epoch 4/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 1.1186 - accuracy: 0.6279 - val_loss: 0.9892 - val_accuracy: 0.6880\n",
            "Epoch 5/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 1.0408 - accuracy: 0.6620 - val_loss: 0.9200 - val_accuracy: 0.7121\n",
            "Epoch 6/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.9534 - accuracy: 0.6989 - val_loss: 0.8751 - val_accuracy: 0.7315\n",
            "Epoch 7/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.8867 - accuracy: 0.7176 - val_loss: 0.8550 - val_accuracy: 0.7415\n",
            "Epoch 8/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.8316 - accuracy: 0.7273 - val_loss: 0.8476 - val_accuracy: 0.7502\n",
            "Epoch 9/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.7891 - accuracy: 0.7501 - val_loss: 0.7738 - val_accuracy: 0.7702\n",
            "Epoch 10/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.7966 - accuracy: 0.7456 - val_loss: 0.7772 - val_accuracy: 0.7655\n",
            "Epoch 11/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.7040 - accuracy: 0.7765 - val_loss: 0.7680 - val_accuracy: 0.7689\n",
            "Epoch 12/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.7454 - accuracy: 0.7550 - val_loss: 0.7785 - val_accuracy: 0.7735\n",
            "Epoch 13/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.7218 - accuracy: 0.7677 - val_loss: 0.7618 - val_accuracy: 0.7809\n",
            "Epoch 14/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.6698 - accuracy: 0.7840 - val_loss: 0.7071 - val_accuracy: 0.7876\n",
            "Epoch 15/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.6390 - accuracy: 0.7966 - val_loss: 0.7106 - val_accuracy: 0.7902\n",
            "Epoch 16/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.6569 - accuracy: 0.7831 - val_loss: 0.7155 - val_accuracy: 0.7976\n",
            "Epoch 17/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.5908 - accuracy: 0.8060 - val_loss: 0.7126 - val_accuracy: 0.7909\n",
            "Epoch 18/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.5869 - accuracy: 0.8108 - val_loss: 0.7151 - val_accuracy: 0.7963\n",
            "Epoch 19/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.6014 - accuracy: 0.8061 - val_loss: 0.6833 - val_accuracy: 0.8069\n",
            "Epoch 20/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.5866 - accuracy: 0.8134 - val_loss: 0.7007 - val_accuracy: 0.8016\n",
            "Epoch 21/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.5577 - accuracy: 0.8149 - val_loss: 0.7009 - val_accuracy: 0.8003\n",
            "Epoch 22/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.5524 - accuracy: 0.8241 - val_loss: 0.6796 - val_accuracy: 0.8116\n",
            "Epoch 23/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.5051 - accuracy: 0.8355 - val_loss: 0.6988 - val_accuracy: 0.8023\n",
            "Epoch 24/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.5255 - accuracy: 0.8251 - val_loss: 0.7009 - val_accuracy: 0.8043\n",
            "Epoch 25/300\n",
            "141/141 [==============================] - 1s 9ms/step - loss: 0.5276 - accuracy: 0.8303 - val_loss: 0.6675 - val_accuracy: 0.8063\n",
            "Epoch 26/300\n",
            "141/141 [==============================] - 1s 9ms/step - loss: 0.5154 - accuracy: 0.8359 - val_loss: 0.6930 - val_accuracy: 0.8043\n",
            "Epoch 27/300\n",
            "141/141 [==============================] - 1s 9ms/step - loss: 0.4925 - accuracy: 0.8341 - val_loss: 0.6846 - val_accuracy: 0.8143\n",
            "Epoch 28/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.4963 - accuracy: 0.8334 - val_loss: 0.6955 - val_accuracy: 0.8110\n",
            "Epoch 29/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.5042 - accuracy: 0.8353 - val_loss: 0.6587 - val_accuracy: 0.8170\n",
            "Epoch 30/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.4917 - accuracy: 0.8435 - val_loss: 0.6636 - val_accuracy: 0.8176\n",
            "Epoch 31/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.4832 - accuracy: 0.8341 - val_loss: 0.6689 - val_accuracy: 0.8216\n",
            "Epoch 32/300\n",
            "141/141 [==============================] - 1s 9ms/step - loss: 0.4536 - accuracy: 0.8492 - val_loss: 0.6622 - val_accuracy: 0.8210\n",
            "Epoch 33/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.4491 - accuracy: 0.8480 - val_loss: 0.6579 - val_accuracy: 0.8263\n",
            "Epoch 34/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.4946 - accuracy: 0.8397 - val_loss: 0.6410 - val_accuracy: 0.8290\n",
            "Epoch 35/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.4494 - accuracy: 0.8680 - val_loss: 0.6483 - val_accuracy: 0.8190\n",
            "Epoch 36/300\n",
            "141/141 [==============================] - 1s 9ms/step - loss: 0.4269 - accuracy: 0.8582 - val_loss: 0.6493 - val_accuracy: 0.8283\n",
            "Epoch 37/300\n",
            "141/141 [==============================] - 1s 9ms/step - loss: 0.4694 - accuracy: 0.8385 - val_loss: 0.6347 - val_accuracy: 0.8270\n",
            "Epoch 38/300\n",
            "141/141 [==============================] - 1s 9ms/step - loss: 0.4354 - accuracy: 0.8578 - val_loss: 0.6472 - val_accuracy: 0.8236\n",
            "Epoch 39/300\n",
            "141/141 [==============================] - 1s 9ms/step - loss: 0.3967 - accuracy: 0.8667 - val_loss: 0.6685 - val_accuracy: 0.8243\n",
            "Epoch 40/300\n",
            "141/141 [==============================] - 1s 9ms/step - loss: 0.4450 - accuracy: 0.8572 - val_loss: 0.6395 - val_accuracy: 0.8277\n",
            "Epoch 41/300\n",
            "141/141 [==============================] - 1s 9ms/step - loss: 0.4203 - accuracy: 0.8582 - val_loss: 0.7117 - val_accuracy: 0.7949\n",
            "Epoch 42/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.4368 - accuracy: 0.8605 - val_loss: 0.6461 - val_accuracy: 0.8350\n",
            "Epoch 43/300\n",
            "141/141 [==============================] - 1s 9ms/step - loss: 0.3677 - accuracy: 0.8820 - val_loss: 0.6447 - val_accuracy: 0.8350\n",
            "Epoch 44/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.4353 - accuracy: 0.8625 - val_loss: 0.6233 - val_accuracy: 0.8257\n",
            "Epoch 45/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.3996 - accuracy: 0.8681 - val_loss: 0.6387 - val_accuracy: 0.8337\n",
            "Epoch 46/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.4244 - accuracy: 0.8634 - val_loss: 0.6660 - val_accuracy: 0.8223\n",
            "Epoch 47/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.3934 - accuracy: 0.8730 - val_loss: 0.6245 - val_accuracy: 0.8277\n",
            "Epoch 48/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.3917 - accuracy: 0.8661 - val_loss: 0.6679 - val_accuracy: 0.8223\n",
            "Epoch 49/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.3348 - accuracy: 0.8867 - val_loss: 0.6513 - val_accuracy: 0.8277\n",
            "Epoch 50/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.3760 - accuracy: 0.8756 - val_loss: 0.6660 - val_accuracy: 0.8250\n",
            "Epoch 51/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.3580 - accuracy: 0.8835 - val_loss: 0.6421 - val_accuracy: 0.8330\n",
            "Epoch 52/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.3674 - accuracy: 0.8790 - val_loss: 0.6884 - val_accuracy: 0.8243\n",
            "Epoch 53/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.3851 - accuracy: 0.8711 - val_loss: 0.6601 - val_accuracy: 0.8297\n",
            "Epoch 54/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.3584 - accuracy: 0.8849 - val_loss: 0.6547 - val_accuracy: 0.8277\n",
            "Epoch 55/300\n",
            "141/141 [==============================] - 1s 9ms/step - loss: 0.3607 - accuracy: 0.8835 - val_loss: 0.6663 - val_accuracy: 0.8317\n",
            "Epoch 56/300\n",
            "141/141 [==============================] - 1s 9ms/step - loss: 0.3516 - accuracy: 0.8825 - val_loss: 0.6283 - val_accuracy: 0.8330\n",
            "Epoch 57/300\n",
            "141/141 [==============================] - 1s 9ms/step - loss: 0.3340 - accuracy: 0.8939 - val_loss: 0.6573 - val_accuracy: 0.8190\n",
            "Epoch 58/300\n",
            "141/141 [==============================] - 1s 9ms/step - loss: 0.3472 - accuracy: 0.8905 - val_loss: 0.6414 - val_accuracy: 0.8290\n",
            "Epoch 59/300\n",
            "141/141 [==============================] - 2s 11ms/step - loss: 0.3329 - accuracy: 0.8927 - val_loss: 0.6497 - val_accuracy: 0.8270\n",
            "Epoch 60/300\n",
            "141/141 [==============================] - 1s 9ms/step - loss: 0.3696 - accuracy: 0.8779 - val_loss: 0.6883 - val_accuracy: 0.8150\n",
            "Epoch 61/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.3360 - accuracy: 0.8901 - val_loss: 0.6525 - val_accuracy: 0.8370\n",
            "Epoch 62/300\n",
            "141/141 [==============================] - 1s 9ms/step - loss: 0.3653 - accuracy: 0.8807 - val_loss: 0.6804 - val_accuracy: 0.8283\n",
            "Epoch 63/300\n",
            "141/141 [==============================] - 1s 9ms/step - loss: 0.3195 - accuracy: 0.8979 - val_loss: 0.6673 - val_accuracy: 0.8357\n",
            "Epoch 64/300\n",
            "141/141 [==============================] - 1s 10ms/step - loss: 0.3243 - accuracy: 0.8968 - val_loss: 0.6813 - val_accuracy: 0.8277\n",
            "Epoch 65/300\n",
            "141/141 [==============================] - 1s 9ms/step - loss: 0.3105 - accuracy: 0.8969 - val_loss: 0.6789 - val_accuracy: 0.8383\n",
            "Epoch 66/300\n",
            "141/141 [==============================] - 1s 9ms/step - loss: 0.3347 - accuracy: 0.8799 - val_loss: 0.6606 - val_accuracy: 0.8417\n",
            "Epoch 67/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.3306 - accuracy: 0.8946 - val_loss: 0.6783 - val_accuracy: 0.8323\n",
            "Epoch 68/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.3493 - accuracy: 0.8825 - val_loss: 0.6615 - val_accuracy: 0.8236\n",
            "Epoch 69/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.3037 - accuracy: 0.9009 - val_loss: 0.6629 - val_accuracy: 0.8390\n",
            "Epoch 70/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.3140 - accuracy: 0.8939 - val_loss: 0.6670 - val_accuracy: 0.8370\n",
            "Epoch 71/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.2925 - accuracy: 0.9007 - val_loss: 0.6671 - val_accuracy: 0.8350\n",
            "Epoch 72/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.3548 - accuracy: 0.8863 - val_loss: 0.6500 - val_accuracy: 0.8377\n",
            "Epoch 73/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.2919 - accuracy: 0.9020 - val_loss: 0.6754 - val_accuracy: 0.8450\n",
            "Epoch 74/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.3248 - accuracy: 0.8883 - val_loss: 0.7443 - val_accuracy: 0.8210\n",
            "Epoch 75/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.3208 - accuracy: 0.8921 - val_loss: 0.6817 - val_accuracy: 0.8297\n",
            "Epoch 76/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.3049 - accuracy: 0.9009 - val_loss: 0.7294 - val_accuracy: 0.8257\n",
            "Epoch 77/300\n",
            "141/141 [==============================] - 1s 9ms/step - loss: 0.3018 - accuracy: 0.8999 - val_loss: 0.7218 - val_accuracy: 0.8277\n",
            "Epoch 78/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.3222 - accuracy: 0.8918 - val_loss: 0.7134 - val_accuracy: 0.8337\n",
            "Epoch 79/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.2774 - accuracy: 0.9115 - val_loss: 0.7112 - val_accuracy: 0.8337\n",
            "Epoch 80/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.2819 - accuracy: 0.9107 - val_loss: 0.6703 - val_accuracy: 0.8317\n",
            "Epoch 81/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.2919 - accuracy: 0.9040 - val_loss: 0.6895 - val_accuracy: 0.8430\n",
            "Epoch 82/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.2925 - accuracy: 0.9044 - val_loss: 0.7110 - val_accuracy: 0.8263\n",
            "Epoch 83/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.3191 - accuracy: 0.9012 - val_loss: 0.6932 - val_accuracy: 0.8337\n",
            "Epoch 84/300\n",
            "141/141 [==============================] - 1s 8ms/step - loss: 0.2686 - accuracy: 0.9139 - val_loss: 0.6702 - val_accuracy: 0.8390\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "873WuhHY8AVA"
      },
      "source": [
        "result = pd.DataFrame()\n",
        "result['num_labled']=num_labled\n",
        "result['num_unlabled']=num_unlabled\n",
        "result['labels_added']=labels_added\n",
        "result['train_acc_CRNN']=train_acc[0]\n",
        "result['val_acc_CRNN']=val_acc[0]\n",
        "result['train_acc_LSTM']=train_acc[1]\n",
        "result['val_acc_LSTM']=val_acc[1]\n",
        "result['train_acc_MLP']=train_acc[2]\n",
        "result['val_acc_MLP']=val_acc[2]\n",
        "result['pseudo_labels_acc']=pseudo_labels_acc\n",
        "result['test_acc']=test_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T32Q4yH44R4a"
      },
      "source": [
        "result.to_csv(\"/content/drive/MyDrive/ML_A/Tri train/result.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRgX69J63BYG"
      },
      "source": [
        "result = pd.read_csv('/content/drive/MyDrive/ML_A/Tri train/result.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "wgWYGH9c3JLs",
        "outputId": "81e722f9-bfe5-4d8e-dd1a-c5db638d0778"
      },
      "source": [
        "result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_labled</th>\n",
              "      <th>num_unlabled</th>\n",
              "      <th>labels_added</th>\n",
              "      <th>train_acc_CRNN</th>\n",
              "      <th>val_acc_CRNN</th>\n",
              "      <th>train_acc_LSTM</th>\n",
              "      <th>val_acc_LSTM</th>\n",
              "      <th>train_acc_MLP</th>\n",
              "      <th>val_acc_MLP</th>\n",
              "      <th>pseudo_labels_acc</th>\n",
              "      <th>test_acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2619</td>\n",
              "      <td>5240</td>\n",
              "      <td>2526</td>\n",
              "      <td>0.883910</td>\n",
              "      <td>0.745038</td>\n",
              "      <td>0.997963</td>\n",
              "      <td>0.862595</td>\n",
              "      <td>0.968432</td>\n",
              "      <td>0.812214</td>\n",
              "      <td>92.201108</td>\n",
              "      <td>0.743414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5145</td>\n",
              "      <td>2714</td>\n",
              "      <td>373</td>\n",
              "      <td>0.917315</td>\n",
              "      <td>0.790210</td>\n",
              "      <td>0.973561</td>\n",
              "      <td>0.860140</td>\n",
              "      <td>0.948678</td>\n",
              "      <td>0.815851</td>\n",
              "      <td>83.378016</td>\n",
              "      <td>0.751432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5518</td>\n",
              "      <td>2341</td>\n",
              "      <td>223</td>\n",
              "      <td>0.935476</td>\n",
              "      <td>0.823188</td>\n",
              "      <td>0.990092</td>\n",
              "      <td>0.861594</td>\n",
              "      <td>0.930159</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>85.650224</td>\n",
              "      <td>0.764032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5741</td>\n",
              "      <td>2118</td>\n",
              "      <td>85</td>\n",
              "      <td>0.887340</td>\n",
              "      <td>0.791086</td>\n",
              "      <td>0.987224</td>\n",
              "      <td>0.873955</td>\n",
              "      <td>0.946109</td>\n",
              "      <td>0.841922</td>\n",
              "      <td>82.352941</td>\n",
              "      <td>0.746850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5826</td>\n",
              "      <td>2033</td>\n",
              "      <td>160</td>\n",
              "      <td>0.942321</td>\n",
              "      <td>0.827728</td>\n",
              "      <td>0.982376</td>\n",
              "      <td>0.868222</td>\n",
              "      <td>0.959030</td>\n",
              "      <td>0.855182</td>\n",
              "      <td>78.125000</td>\n",
              "      <td>0.758305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5986</td>\n",
              "      <td>1873</td>\n",
              "      <td>90</td>\n",
              "      <td>0.953665</td>\n",
              "      <td>0.828991</td>\n",
              "      <td>0.970372</td>\n",
              "      <td>0.857047</td>\n",
              "      <td>0.945645</td>\n",
              "      <td>0.825651</td>\n",
              "      <td>67.777778</td>\n",
              "      <td>0.761741</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   num_labled  num_unlabled  ...  pseudo_labels_acc  test_acc\n",
              "0        2619          5240  ...          92.201108  0.743414\n",
              "1        5145          2714  ...          83.378016  0.751432\n",
              "2        5518          2341  ...          85.650224  0.764032\n",
              "3        5741          2118  ...          82.352941  0.746850\n",
              "4        5826          2033  ...          78.125000  0.758305\n",
              "5        5986          1873  ...          67.777778  0.761741\n",
              "\n",
              "[6 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvadB2thFzVp"
      },
      "source": [
        "### Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqGd-T5qHoBB",
        "outputId": "061f3d28-b852-40e3-c1fc-1837eb417fcd"
      },
      "source": [
        "m1 = keras.models.load_model('/content/drive/MyDrive/ML_A/Tri train/3. Tri-S/CRNN_80.h5')  \n",
        "m2 = keras.models.load_model('/content/drive/MyDrive/ML_A/Tri train/3. Tri-S/MLP_80.h5') \n",
        "m3 = keras.models.load_model('/content/drive/MyDrive/ML_A/Tri train/3. Tri-S/LSTM_80.h5')  \n",
        "y1 = m1.predict(X_test.reshape(len(X_test), 16,8,1))\n",
        "y2 = m2.predict(X_test.reshape(len(X_test), 128))\n",
        "y3 = m3.predict(X_test.reshape(len(X_test), 16,8))\n",
        "y_total_pred=[]\n",
        "\n",
        "y = []\n",
        "for k in range(len(y1)):\n",
        "  p_1 = y1[k][np.argmax(y1[k])]\n",
        "  p_2 = y2[k][np.argmax(y2[k])]\n",
        "  p_3 = y3[k][np.argmax(y3[k])]\n",
        "  p_max = max(max(p_1, p_2), p_3)\n",
        "  if np.argmax(y1[k])==np.argmax(y2[k]) and (p_1>=0.85 or p_2>=0.85):\n",
        "    y.append(y1[k])\n",
        "  elif np.argmax(y2[k])==np.argmax(y3[k]) and (p_2>=0.85 or p_3>=0.85):\n",
        "    y.append(y2[k])\n",
        "  elif np.argmax(y3[k])==np.argmax(y1[k]) and (p_3>=0.85 or p_1>=0.85):\n",
        "    y.append(y3[k])\n",
        "  else:\n",
        "    if p_max==p_1:\n",
        "      y.append(y1[k])\n",
        "    elif p_max==p_2:\n",
        "      y.append(y2[k])\n",
        "    elif p_max==p_3:\n",
        "      y.append(y3[k])\n",
        "\n",
        "\n",
        "y = np.argmax(y, axis=1)\n",
        "y_total_pred=y_total_pred+y.tolist()\n",
        "############################################## Getting no. of correct prediction########################\n",
        "sum=0\n",
        "#y=np.load('/content/drive/MyDrive/ML_N/Real_time_data/y.npy')\n",
        "for i in range(len(y_total_pred)):\n",
        "#  print(y_pred[i],y[i])\n",
        "  if y_total_pred[i]==np.argmax(y_test[i]):\n",
        "    sum=sum+1\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ycJjNTyF3Mu"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "label=[ 'air_conditioner', 'car_horn', 'children_playing','dog_bark', 'drilling', 'engine_idling', 'gun_shot','jackhammer', 'siren', 'street_music']\n",
        "cm = confusion_matrix(np.argmax(y_test, axis=1), y_total_pred, [0,1,2,3,4,5,6,7,8,9])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXwBwNRqJAYN"
      },
      "source": [
        "def plot_confusion_matrix(cm, target_names, title='Confusion matrix of Tri-training', cmap=None, normalize=True):\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "    import itertools\n",
        "\n",
        "    accuracy = np.trace(cm) / np.sum(cm).astype('float')\n",
        "    misclass = 1 - accuracy\n",
        "\n",
        "    if cmap is None:\n",
        "        cmap = plt.get_cmap('Blues')\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "\n",
        "    if target_names is not None:\n",
        "        tick_marks = np.arange(len(target_names))\n",
        "        plt.xticks(tick_marks, target_names, rotation=45)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "\n",
        "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        if normalize:\n",
        "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        else:\n",
        "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
        "    plt.savefig('/content/drive/MyDrive/ML_A/tri train_majority vote.png')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "EHof3NvrJHzB",
        "outputId": "7df8cf32-376b-4ce2-9995-0d0f083dabea"
      },
      "source": [
        "plot_confusion_matrix(cm, label, normalize=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}