{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1. CNN Base_0.9.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6jZWQF9xL8y"
      },
      "source": [
        "### Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btSbyTRLstrc"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "pd.plotting.register_matplotlib_converters()\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import librosa\n",
        "import keras\n",
        "from keras.layers import LSTM, Dense, Dropout, Flatten\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import keras\n",
        "from keras.layers import LSTM, Dense, Dropout, Flatten"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fPs99eIQJc7"
      },
      "source": [
        "X=np.load('/content/drive/MyDrive/ML_S/Tri train/X.npy')\n",
        "Y=np.load('/content/drive/MyDrive/ML_S/Tri train/y.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrU5LhazQM5n"
      },
      "source": [
        "## Splitting the data into 60% unlabeled 10% testing and 30% training\n",
        "## stratify distributes the data into train and test according to class distribution in original dataset \n",
        "X_train, X_un, y_train, y_un = train_test_split(X, Y, test_size=0.6,random_state=1)\n",
        "X_t, X_test, y_t, y_test = train_test_split(X_train, y_train, test_size=0.25,random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ikj3VcLRvLrx"
      },
      "source": [
        "input_dim = (16, 8, 1)\n",
        "dropout=0.1\n",
        "n_classes=10\n",
        "learning_rate = 0.0001"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MXn6zxAvOUh"
      },
      "source": [
        "X_t = X_t.reshape(len(X_t), 16, 8,1)\n",
        "X_test = X_test.reshape(len(X_test), 16, 8,1)\n",
        "X_un= X_un.reshape(len(X_un), 16, 8,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npshDbSSTQIz"
      },
      "source": [
        "### CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2jsvK2suHal"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(64, (3, 3), padding = \"same\", activation = \"tanh\", input_shape = input_dim))\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "#model.add(Dropout(0.1))\n",
        "model.add(Conv2D(128, (3, 3), padding = \"same\", activation = \"tanh\"))\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024, activation = \"tanh\"))\n",
        "model.add(Dense(10, activation = \"softmax\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18_UlHhmvDaY",
        "outputId": "36b5a052-ee22-4a67-f182-ab1cd16bb41b"
      },
      "source": [
        "opt = Adam(lr=learning_rate)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "callbacks = [ModelCheckpoint('/content/drive/MyDrive/CNN_base.h5', monitor='val_loss', mode='min', save_best_only=True),EarlyStopping(monitor = 'val_loss',min_delta = 0,patience = 40,restore_best_weights = True)]\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 16, 8, 64)         640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 8, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 8, 4, 128)         73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 4, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 4, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                10250     \n",
            "=================================================================\n",
            "Total params: 1,134,346\n",
            "Trainable params: 1,134,346\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ci-kbETvmaT"
      },
      "source": [
        "X__train, X__test, y__train, y__test = train_test_split(X_t, y_t, test_size=0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zgl-L_0hwMGp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12e4148d-3c60-4a62-f3e2-019e5a8941f4"
      },
      "source": [
        "history = model.fit(X__train, y__train, epochs = 500, batch_size =200 , validation_data = (X__test, y__test), callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "10/10 [==============================] - 2s 136ms/step - loss: 2.2385 - accuracy: 0.1755 - val_loss: 2.0781 - val_accuracy: 0.3168\n",
            "Epoch 2/500\n",
            "10/10 [==============================] - 1s 114ms/step - loss: 2.0297 - accuracy: 0.3313 - val_loss: 1.9462 - val_accuracy: 0.3346\n",
            "Epoch 3/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 1.9163 - accuracy: 0.3809 - val_loss: 1.8555 - val_accuracy: 0.3906\n",
            "Epoch 4/500\n",
            "10/10 [==============================] - 1s 112ms/step - loss: 1.8222 - accuracy: 0.4202 - val_loss: 1.7930 - val_accuracy: 0.4211\n",
            "Epoch 5/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 1.7601 - accuracy: 0.4327 - val_loss: 1.7577 - val_accuracy: 0.4288\n",
            "Epoch 6/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 1.7017 - accuracy: 0.4506 - val_loss: 1.7153 - val_accuracy: 0.4644\n",
            "Epoch 7/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 1.6470 - accuracy: 0.4601 - val_loss: 1.6930 - val_accuracy: 0.4809\n",
            "Epoch 8/500\n",
            "10/10 [==============================] - 1s 112ms/step - loss: 1.6393 - accuracy: 0.4684 - val_loss: 1.6643 - val_accuracy: 0.4771\n",
            "Epoch 9/500\n",
            "10/10 [==============================] - 1s 112ms/step - loss: 1.5851 - accuracy: 0.4915 - val_loss: 1.6427 - val_accuracy: 0.4898\n",
            "Epoch 10/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 1.5592 - accuracy: 0.4828 - val_loss: 1.6172 - val_accuracy: 0.4898\n",
            "Epoch 11/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 1.5291 - accuracy: 0.5079 - val_loss: 1.5985 - val_accuracy: 0.4987\n",
            "Epoch 12/500\n",
            "10/10 [==============================] - 1s 112ms/step - loss: 1.4727 - accuracy: 0.5223 - val_loss: 1.5819 - val_accuracy: 0.5025\n",
            "Epoch 13/500\n",
            "10/10 [==============================] - 1s 115ms/step - loss: 1.4839 - accuracy: 0.5223 - val_loss: 1.5596 - val_accuracy: 0.5191\n",
            "Epoch 14/500\n",
            "10/10 [==============================] - 1s 117ms/step - loss: 1.4375 - accuracy: 0.5249 - val_loss: 1.5482 - val_accuracy: 0.5127\n",
            "Epoch 15/500\n",
            "10/10 [==============================] - 1s 112ms/step - loss: 1.4099 - accuracy: 0.5324 - val_loss: 1.5248 - val_accuracy: 0.5076\n",
            "Epoch 16/500\n",
            "10/10 [==============================] - 1s 112ms/step - loss: 1.3892 - accuracy: 0.5253 - val_loss: 1.5102 - val_accuracy: 0.5064\n",
            "Epoch 17/500\n",
            "10/10 [==============================] - 1s 112ms/step - loss: 1.3757 - accuracy: 0.5324 - val_loss: 1.5002 - val_accuracy: 0.5089\n",
            "Epoch 18/500\n",
            "10/10 [==============================] - 1s 114ms/step - loss: 1.3551 - accuracy: 0.5406 - val_loss: 1.4821 - val_accuracy: 0.5191\n",
            "Epoch 19/500\n",
            "10/10 [==============================] - 1s 111ms/step - loss: 1.3599 - accuracy: 0.5470 - val_loss: 1.4757 - val_accuracy: 0.5204\n",
            "Epoch 20/500\n",
            "10/10 [==============================] - 1s 117ms/step - loss: 1.3087 - accuracy: 0.5609 - val_loss: 1.4537 - val_accuracy: 0.5280\n",
            "Epoch 21/500\n",
            "10/10 [==============================] - 1s 111ms/step - loss: 1.3059 - accuracy: 0.5679 - val_loss: 1.4483 - val_accuracy: 0.5216\n",
            "Epoch 22/500\n",
            "10/10 [==============================] - 1s 115ms/step - loss: 1.2880 - accuracy: 0.5640 - val_loss: 1.4320 - val_accuracy: 0.5267\n",
            "Epoch 23/500\n",
            "10/10 [==============================] - 1s 111ms/step - loss: 1.2766 - accuracy: 0.5669 - val_loss: 1.4216 - val_accuracy: 0.5471\n",
            "Epoch 24/500\n",
            "10/10 [==============================] - 1s 112ms/step - loss: 1.2692 - accuracy: 0.5709 - val_loss: 1.4117 - val_accuracy: 0.5394\n",
            "Epoch 25/500\n",
            "10/10 [==============================] - 1s 112ms/step - loss: 1.2563 - accuracy: 0.5649 - val_loss: 1.4019 - val_accuracy: 0.5522\n",
            "Epoch 26/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 1.2193 - accuracy: 0.5986 - val_loss: 1.3868 - val_accuracy: 0.5433\n",
            "Epoch 27/500\n",
            "10/10 [==============================] - 1s 111ms/step - loss: 1.2263 - accuracy: 0.5934 - val_loss: 1.3787 - val_accuracy: 0.5471\n",
            "Epoch 28/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 1.1970 - accuracy: 0.6068 - val_loss: 1.3709 - val_accuracy: 0.5509\n",
            "Epoch 29/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 1.1803 - accuracy: 0.5993 - val_loss: 1.3613 - val_accuracy: 0.5522\n",
            "Epoch 30/500\n",
            "10/10 [==============================] - 1s 111ms/step - loss: 1.1743 - accuracy: 0.6019 - val_loss: 1.3551 - val_accuracy: 0.5573\n",
            "Epoch 31/500\n",
            "10/10 [==============================] - 1s 112ms/step - loss: 1.1562 - accuracy: 0.6147 - val_loss: 1.3429 - val_accuracy: 0.5674\n",
            "Epoch 32/500\n",
            "10/10 [==============================] - 1s 111ms/step - loss: 1.1457 - accuracy: 0.6237 - val_loss: 1.3348 - val_accuracy: 0.5560\n",
            "Epoch 33/500\n",
            "10/10 [==============================] - 1s 111ms/step - loss: 1.1267 - accuracy: 0.6176 - val_loss: 1.3290 - val_accuracy: 0.5725\n",
            "Epoch 34/500\n",
            "10/10 [==============================] - 1s 112ms/step - loss: 1.1185 - accuracy: 0.6288 - val_loss: 1.3178 - val_accuracy: 0.5687\n",
            "Epoch 35/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 1.1319 - accuracy: 0.6169 - val_loss: 1.3039 - val_accuracy: 0.5738\n",
            "Epoch 36/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 1.1017 - accuracy: 0.6258 - val_loss: 1.3031 - val_accuracy: 0.5891\n",
            "Epoch 37/500\n",
            "10/10 [==============================] - 1s 112ms/step - loss: 1.0966 - accuracy: 0.6305 - val_loss: 1.2869 - val_accuracy: 0.5789\n",
            "Epoch 38/500\n",
            "10/10 [==============================] - 1s 112ms/step - loss: 1.0914 - accuracy: 0.6424 - val_loss: 1.2899 - val_accuracy: 0.5852\n",
            "Epoch 39/500\n",
            "10/10 [==============================] - 1s 112ms/step - loss: 1.0731 - accuracy: 0.6462 - val_loss: 1.2772 - val_accuracy: 0.5814\n",
            "Epoch 40/500\n",
            "10/10 [==============================] - 1s 114ms/step - loss: 1.0681 - accuracy: 0.6390 - val_loss: 1.2652 - val_accuracy: 0.5903\n",
            "Epoch 41/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 1.0519 - accuracy: 0.6582 - val_loss: 1.2674 - val_accuracy: 0.5878\n",
            "Epoch 42/500\n",
            "10/10 [==============================] - 1s 111ms/step - loss: 1.0367 - accuracy: 0.6510 - val_loss: 1.2607 - val_accuracy: 0.5992\n",
            "Epoch 43/500\n",
            "10/10 [==============================] - 1s 114ms/step - loss: 1.0106 - accuracy: 0.6735 - val_loss: 1.2579 - val_accuracy: 0.5941\n",
            "Epoch 44/500\n",
            "10/10 [==============================] - 1s 112ms/step - loss: 1.0295 - accuracy: 0.6646 - val_loss: 1.2487 - val_accuracy: 0.5852\n",
            "Epoch 45/500\n",
            "10/10 [==============================] - 1s 114ms/step - loss: 1.0204 - accuracy: 0.6650 - val_loss: 1.2504 - val_accuracy: 0.5967\n",
            "Epoch 46/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 1.0206 - accuracy: 0.6629 - val_loss: 1.2429 - val_accuracy: 0.5852\n",
            "Epoch 47/500\n",
            "10/10 [==============================] - 1s 114ms/step - loss: 1.0013 - accuracy: 0.6595 - val_loss: 1.2378 - val_accuracy: 0.5967\n",
            "Epoch 48/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 0.9851 - accuracy: 0.6628 - val_loss: 1.2259 - val_accuracy: 0.6005\n",
            "Epoch 49/500\n",
            "10/10 [==============================] - 1s 114ms/step - loss: 0.9748 - accuracy: 0.6730 - val_loss: 1.2294 - val_accuracy: 0.6005\n",
            "Epoch 50/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 0.9685 - accuracy: 0.6785 - val_loss: 1.2199 - val_accuracy: 0.5980\n",
            "Epoch 51/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 0.9770 - accuracy: 0.6667 - val_loss: 1.2151 - val_accuracy: 0.6031\n",
            "Epoch 52/500\n",
            "10/10 [==============================] - 1s 115ms/step - loss: 0.9273 - accuracy: 0.7020 - val_loss: 1.2069 - val_accuracy: 0.6081\n",
            "Epoch 53/500\n",
            "10/10 [==============================] - 1s 112ms/step - loss: 0.9540 - accuracy: 0.6820 - val_loss: 1.2029 - val_accuracy: 0.6056\n",
            "Epoch 54/500\n",
            "10/10 [==============================] - 1s 111ms/step - loss: 0.9447 - accuracy: 0.6928 - val_loss: 1.1987 - val_accuracy: 0.6247\n",
            "Epoch 55/500\n",
            "10/10 [==============================] - 1s 111ms/step - loss: 0.9317 - accuracy: 0.6977 - val_loss: 1.1954 - val_accuracy: 0.6107\n",
            "Epoch 56/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 0.9497 - accuracy: 0.6824 - val_loss: 1.1936 - val_accuracy: 0.6221\n",
            "Epoch 57/500\n",
            "10/10 [==============================] - 1s 112ms/step - loss: 0.9316 - accuracy: 0.6899 - val_loss: 1.1872 - val_accuracy: 0.6170\n",
            "Epoch 58/500\n",
            "10/10 [==============================] - 1s 115ms/step - loss: 0.8978 - accuracy: 0.7064 - val_loss: 1.1814 - val_accuracy: 0.6221\n",
            "Epoch 59/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 0.9048 - accuracy: 0.6941 - val_loss: 1.1924 - val_accuracy: 0.6183\n",
            "Epoch 60/500\n",
            "10/10 [==============================] - 1s 114ms/step - loss: 0.8922 - accuracy: 0.7084 - val_loss: 1.1782 - val_accuracy: 0.6170\n",
            "Epoch 61/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 0.8972 - accuracy: 0.6956 - val_loss: 1.1810 - val_accuracy: 0.6234\n",
            "Epoch 62/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 0.8986 - accuracy: 0.7100 - val_loss: 1.1646 - val_accuracy: 0.6260\n",
            "Epoch 63/500\n",
            "10/10 [==============================] - 1s 110ms/step - loss: 0.8782 - accuracy: 0.7031 - val_loss: 1.1708 - val_accuracy: 0.6234\n",
            "Epoch 64/500\n",
            "10/10 [==============================] - 1s 114ms/step - loss: 0.8714 - accuracy: 0.7139 - val_loss: 1.1680 - val_accuracy: 0.6183\n",
            "Epoch 65/500\n",
            "10/10 [==============================] - 1s 112ms/step - loss: 0.8484 - accuracy: 0.7237 - val_loss: 1.1633 - val_accuracy: 0.6260\n",
            "Epoch 66/500\n",
            "10/10 [==============================] - 1s 112ms/step - loss: 0.8490 - accuracy: 0.7153 - val_loss: 1.1607 - val_accuracy: 0.6234\n",
            "Epoch 67/500\n",
            "10/10 [==============================] - 1s 114ms/step - loss: 0.8512 - accuracy: 0.7144 - val_loss: 1.1590 - val_accuracy: 0.6285\n",
            "Epoch 68/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 0.8393 - accuracy: 0.7255 - val_loss: 1.1565 - val_accuracy: 0.6221\n",
            "Epoch 69/500\n",
            "10/10 [==============================] - 1s 112ms/step - loss: 0.8543 - accuracy: 0.7081 - val_loss: 1.1479 - val_accuracy: 0.6247\n",
            "Epoch 70/500\n",
            "10/10 [==============================] - 1s 112ms/step - loss: 0.8405 - accuracy: 0.7191 - val_loss: 1.1525 - val_accuracy: 0.6285\n",
            "Epoch 71/500\n",
            "10/10 [==============================] - 1s 112ms/step - loss: 0.8526 - accuracy: 0.7191 - val_loss: 1.1443 - val_accuracy: 0.6349\n",
            "Epoch 72/500\n",
            "10/10 [==============================] - 1s 115ms/step - loss: 0.8157 - accuracy: 0.7256 - val_loss: 1.1453 - val_accuracy: 0.6298\n",
            "Epoch 73/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 0.7983 - accuracy: 0.7470 - val_loss: 1.1473 - val_accuracy: 0.6323\n",
            "Epoch 74/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 0.8105 - accuracy: 0.7416 - val_loss: 1.1349 - val_accuracy: 0.6412\n",
            "Epoch 75/500\n",
            "10/10 [==============================] - 1s 115ms/step - loss: 0.7963 - accuracy: 0.7451 - val_loss: 1.1380 - val_accuracy: 0.6310\n",
            "Epoch 76/500\n",
            "10/10 [==============================] - 1s 115ms/step - loss: 0.8143 - accuracy: 0.7356 - val_loss: 1.1322 - val_accuracy: 0.6336\n",
            "Epoch 77/500\n",
            "10/10 [==============================] - 1s 115ms/step - loss: 0.7949 - accuracy: 0.7351 - val_loss: 1.1297 - val_accuracy: 0.6374\n",
            "Epoch 78/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 0.8074 - accuracy: 0.7311 - val_loss: 1.1320 - val_accuracy: 0.6361\n",
            "Epoch 79/500\n",
            "10/10 [==============================] - 1s 112ms/step - loss: 0.7752 - accuracy: 0.7398 - val_loss: 1.1364 - val_accuracy: 0.6323\n",
            "Epoch 80/500\n",
            "10/10 [==============================] - 1s 111ms/step - loss: 0.8196 - accuracy: 0.7310 - val_loss: 1.1282 - val_accuracy: 0.6336\n",
            "Epoch 81/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 0.7873 - accuracy: 0.7388 - val_loss: 1.1289 - val_accuracy: 0.6336\n",
            "Epoch 82/500\n",
            "10/10 [==============================] - 1s 111ms/step - loss: 0.7712 - accuracy: 0.7471 - val_loss: 1.1295 - val_accuracy: 0.6298\n",
            "Epoch 83/500\n",
            "10/10 [==============================] - 1s 112ms/step - loss: 0.7687 - accuracy: 0.7373 - val_loss: 1.1175 - val_accuracy: 0.6450\n",
            "Epoch 84/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 0.7346 - accuracy: 0.7584 - val_loss: 1.1238 - val_accuracy: 0.6374\n",
            "Epoch 85/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 0.7263 - accuracy: 0.7683 - val_loss: 1.1310 - val_accuracy: 0.6412\n",
            "Epoch 86/500\n",
            "10/10 [==============================] - 1s 114ms/step - loss: 0.7580 - accuracy: 0.7446 - val_loss: 1.1101 - val_accuracy: 0.6425\n",
            "Epoch 87/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 0.7405 - accuracy: 0.7586 - val_loss: 1.1135 - val_accuracy: 0.6387\n",
            "Epoch 88/500\n",
            "10/10 [==============================] - 1s 112ms/step - loss: 0.7394 - accuracy: 0.7637 - val_loss: 1.1187 - val_accuracy: 0.6438\n",
            "Epoch 89/500\n",
            "10/10 [==============================] - 1s 115ms/step - loss: 0.7032 - accuracy: 0.7711 - val_loss: 1.1076 - val_accuracy: 0.6349\n",
            "Epoch 90/500\n",
            "10/10 [==============================] - 1s 115ms/step - loss: 0.7283 - accuracy: 0.7618 - val_loss: 1.1031 - val_accuracy: 0.6450\n",
            "Epoch 91/500\n",
            "10/10 [==============================] - 1s 114ms/step - loss: 0.7053 - accuracy: 0.7688 - val_loss: 1.1123 - val_accuracy: 0.6463\n",
            "Epoch 92/500\n",
            "10/10 [==============================] - 1s 112ms/step - loss: 0.7250 - accuracy: 0.7665 - val_loss: 1.1144 - val_accuracy: 0.6476\n",
            "Epoch 93/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 0.7083 - accuracy: 0.7711 - val_loss: 1.1159 - val_accuracy: 0.6412\n",
            "Epoch 94/500\n",
            "10/10 [==============================] - 1s 115ms/step - loss: 0.6932 - accuracy: 0.7723 - val_loss: 1.1143 - val_accuracy: 0.6489\n",
            "Epoch 95/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 0.7037 - accuracy: 0.7700 - val_loss: 1.1116 - val_accuracy: 0.6425\n",
            "Epoch 96/500\n",
            "10/10 [==============================] - 1s 114ms/step - loss: 0.6942 - accuracy: 0.7792 - val_loss: 1.1131 - val_accuracy: 0.6565\n",
            "Epoch 97/500\n",
            "10/10 [==============================] - 1s 112ms/step - loss: 0.6769 - accuracy: 0.7795 - val_loss: 1.1153 - val_accuracy: 0.6501\n",
            "Epoch 98/500\n",
            "10/10 [==============================] - 1s 114ms/step - loss: 0.6843 - accuracy: 0.7773 - val_loss: 1.1122 - val_accuracy: 0.6463\n",
            "Epoch 99/500\n",
            "10/10 [==============================] - 1s 117ms/step - loss: 0.6935 - accuracy: 0.7860 - val_loss: 1.1185 - val_accuracy: 0.6578\n",
            "Epoch 100/500\n",
            "10/10 [==============================] - 1s 114ms/step - loss: 0.6722 - accuracy: 0.7867 - val_loss: 1.1144 - val_accuracy: 0.6387\n",
            "Epoch 101/500\n",
            "10/10 [==============================] - 1s 112ms/step - loss: 0.6801 - accuracy: 0.7821 - val_loss: 1.1178 - val_accuracy: 0.6438\n",
            "Epoch 102/500\n",
            "10/10 [==============================] - 1s 111ms/step - loss: 0.6626 - accuracy: 0.7933 - val_loss: 1.1122 - val_accuracy: 0.6527\n",
            "Epoch 103/500\n",
            "10/10 [==============================] - 1s 114ms/step - loss: 0.6595 - accuracy: 0.7899 - val_loss: 1.1192 - val_accuracy: 0.6552\n",
            "Epoch 104/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 0.6619 - accuracy: 0.7931 - val_loss: 1.1173 - val_accuracy: 0.6628\n",
            "Epoch 105/500\n",
            "10/10 [==============================] - 1s 112ms/step - loss: 0.6622 - accuracy: 0.7774 - val_loss: 1.1176 - val_accuracy: 0.6514\n",
            "Epoch 106/500\n",
            "10/10 [==============================] - 1s 112ms/step - loss: 0.6847 - accuracy: 0.7930 - val_loss: 1.1242 - val_accuracy: 0.6603\n",
            "Epoch 107/500\n",
            "10/10 [==============================] - 1s 112ms/step - loss: 0.6554 - accuracy: 0.7882 - val_loss: 1.1141 - val_accuracy: 0.6654\n",
            "Epoch 108/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 0.6277 - accuracy: 0.8105 - val_loss: 1.1173 - val_accuracy: 0.6489\n",
            "Epoch 109/500\n",
            "10/10 [==============================] - 1s 114ms/step - loss: 0.6301 - accuracy: 0.8016 - val_loss: 1.1165 - val_accuracy: 0.6552\n",
            "Epoch 110/500\n",
            "10/10 [==============================] - 1s 111ms/step - loss: 0.6099 - accuracy: 0.8066 - val_loss: 1.1083 - val_accuracy: 0.6654\n",
            "Epoch 111/500\n",
            "10/10 [==============================] - 1s 114ms/step - loss: 0.6440 - accuracy: 0.7828 - val_loss: 1.1095 - val_accuracy: 0.6730\n",
            "Epoch 112/500\n",
            "10/10 [==============================] - 1s 114ms/step - loss: 0.6399 - accuracy: 0.7939 - val_loss: 1.1209 - val_accuracy: 0.6565\n",
            "Epoch 113/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 0.6414 - accuracy: 0.7827 - val_loss: 1.1179 - val_accuracy: 0.6527\n",
            "Epoch 114/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 0.6331 - accuracy: 0.8000 - val_loss: 1.1141 - val_accuracy: 0.6590\n",
            "Epoch 115/500\n",
            "10/10 [==============================] - 1s 114ms/step - loss: 0.6243 - accuracy: 0.7942 - val_loss: 1.1153 - val_accuracy: 0.6527\n",
            "Epoch 116/500\n",
            "10/10 [==============================] - 1s 111ms/step - loss: 0.6289 - accuracy: 0.7858 - val_loss: 1.1139 - val_accuracy: 0.6603\n",
            "Epoch 117/500\n",
            "10/10 [==============================] - 1s 115ms/step - loss: 0.5964 - accuracy: 0.8057 - val_loss: 1.1225 - val_accuracy: 0.6450\n",
            "Epoch 118/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 0.6350 - accuracy: 0.7958 - val_loss: 1.1200 - val_accuracy: 0.6628\n",
            "Epoch 119/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 0.6049 - accuracy: 0.8016 - val_loss: 1.1132 - val_accuracy: 0.6590\n",
            "Epoch 120/500\n",
            "10/10 [==============================] - 1s 112ms/step - loss: 0.6043 - accuracy: 0.8032 - val_loss: 1.1226 - val_accuracy: 0.6552\n",
            "Epoch 121/500\n",
            "10/10 [==============================] - 1s 114ms/step - loss: 0.5845 - accuracy: 0.8102 - val_loss: 1.1286 - val_accuracy: 0.6590\n",
            "Epoch 122/500\n",
            "10/10 [==============================] - 1s 114ms/step - loss: 0.6002 - accuracy: 0.8091 - val_loss: 1.1267 - val_accuracy: 0.6565\n",
            "Epoch 123/500\n",
            "10/10 [==============================] - 1s 114ms/step - loss: 0.5716 - accuracy: 0.8190 - val_loss: 1.1209 - val_accuracy: 0.6718\n",
            "Epoch 124/500\n",
            "10/10 [==============================] - 1s 112ms/step - loss: 0.5974 - accuracy: 0.8154 - val_loss: 1.1340 - val_accuracy: 0.6603\n",
            "Epoch 125/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 0.5885 - accuracy: 0.8109 - val_loss: 1.1213 - val_accuracy: 0.6539\n",
            "Epoch 126/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 0.5675 - accuracy: 0.8102 - val_loss: 1.1252 - val_accuracy: 0.6616\n",
            "Epoch 127/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 0.5911 - accuracy: 0.8108 - val_loss: 1.1200 - val_accuracy: 0.6794\n",
            "Epoch 128/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 0.5737 - accuracy: 0.8207 - val_loss: 1.1223 - val_accuracy: 0.6730\n",
            "Epoch 129/500\n",
            "10/10 [==============================] - 1s 112ms/step - loss: 0.5682 - accuracy: 0.8245 - val_loss: 1.1380 - val_accuracy: 0.6743\n",
            "Epoch 130/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 0.5716 - accuracy: 0.8220 - val_loss: 1.1112 - val_accuracy: 0.6628\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gos1aP-VyXfR"
      },
      "source": [
        "### Evaluating baseline CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "le1-x2EzyjlY",
        "outputId": "43408712-4614-42fe-bcdc-0d9bbfaa28ba"
      },
      "source": [
        "model=keras.models.load_model(\"/content/drive/MyDrive/CNN_base.h5\")\n",
        "accuracy=model.evaluate(X_test,y_test)\n",
        "accuracy=model.evaluate(X__train,y__train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "28/28 [==============================] - 0s 7ms/step - loss: 1.1022 - accuracy: 0.6770\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.7002 - accuracy: 0.7687\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYNomn0CVnsY"
      },
      "source": [
        "### Correct predicted above threshold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kn-K0vDOV9yP"
      },
      "source": [
        "threshold =[0.9,0.99]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHi_6TwvccIY",
        "outputId": "3fd8a67c-4863-4fc7-c43b-7a581c1bd386"
      },
      "source": [
        "  y_un_pred = model.predict(X_un)\n",
        "  l = np.argmax(y_un_pred, axis=1)\n",
        "  l_correct = []\n",
        "  total=0\n",
        "  correct=0\n",
        "  for i in range(len(l)):\n",
        "    if y_un_pred[i][l[i]]>=threshold[0]: \n",
        "        total=total+1\n",
        "        if l[i]==np.argmax(y_un[i]):\n",
        "          correct+=1\n",
        "  print(correct*100/total)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "93.8157894736842\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHOyXYtAjYA2",
        "outputId": "40d3827c-e06c-4574-cf7e-d7d21d224b4a"
      },
      "source": [
        "  y_un_pred = model.predict(X_un)\n",
        "  l = np.argmax(y_un_pred, axis=1)\n",
        "  l_correct = []\n",
        "  total=0\n",
        "  correct=0\n",
        "  for i in range(len(l)):\n",
        "    if y_un_pred[i][l[i]]>=threshold[1]: \n",
        "        total=total+1\n",
        "        if l[i]==np.argmax(y_un[i]):\n",
        "          correct+=1\n",
        "  print(correct*100/total)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "96.96969696969697\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMGPBEGCyI5v"
      },
      "source": [
        "### Self Training CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsvGjhzOwOdu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1344a0c-278d-43ea-9171-70ade888769a"
      },
      "source": [
        "iteration=1\n",
        "x_new=[0]*30\n",
        "s=pd.DataFrame([])\n",
        "iter=[]\n",
        "labels_tobe_added=[]\n",
        "val_acc=[]\n",
        "labeled=[]\n",
        "#rem_unlabeled=[]\n",
        "unlabeled=[]\n",
        "train_acc=[]\n",
        "\n",
        "while len(x_new)>10 and len(X_un)>0 and iteration<6:\n",
        "\n",
        "  X__train, X__val, y__train, y__val = train_test_split(X_t, y_t, test_size=0.3)\n",
        "  labeled.append(len(X_t))\n",
        "  unlabeled.append(len(X_un))\n",
        "  print(\"labeled at start of iteration:\",iteration,\" is \",len(X__train), \"and unlabeled is\",len(X_un))\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(64, (3, 3), padding = \"same\", activation = \"tanh\", input_shape = input_dim))\n",
        "  model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "  model.add(Conv2D(128, (3, 3), padding = \"same\", activation = \"tanh\"))\n",
        "  model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1024, activation = \"tanh\"))\n",
        "  model.add(Dense(10, activation = \"softmax\"))\n",
        "  opt = Adam(lr=learning_rate)\n",
        "  model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "  callbacks = [ModelCheckpoint('/content/drive/MyDrive/ML_S/CNN_self_train_0.9.h5', monitor='val_loss', mode='min', save_best_only=True),EarlyStopping(monitor = 'val_loss',min_delta = 0,patience = 25,restore_best_weights = True)]\n",
        "\n",
        "  history = model.fit(X__train, y__train, epochs = 300, batch_size = 500, validation_data = (X__val, y__val), callbacks=callbacks)\n",
        "  \n",
        "  accuracy1=model.evaluate(X__val,y__val)\n",
        "  print(\"val_accuracy=\",accuracy1)\n",
        "  iter.append(iteration)\n",
        "  val_acc.append(accuracy1[1]*100)\n",
        "  accuracy2=model.evaluate(X__train,y__train)\n",
        "  train_acc.append(accuracy2[1]*100)\n",
        "  print(\"train accuracy=\",accuracy2)\n",
        "\n",
        "  y_un_pred = model.predict(X_un)\n",
        "  l = np.argmax(y_un_pred, axis=1)\n",
        "  l_correct = []\n",
        "  x_new = []\n",
        "  y_new = []\n",
        "  for i in range(len(y_un)):\n",
        "    if y_un_pred[i][l[i]]>=0.9: \n",
        "      x_new.append(X_un[i])\n",
        "      y_new.append(l[i])\n",
        "      l_correct.append(i)\n",
        "  y_new2 = to_categorical(y_new, num_classes=10)\n",
        "  y_new=np.array(y_new2)\n",
        "  x_new=np.array(x_new)\n",
        "  if x_new.shape==(0,): break\n",
        "\n",
        "  X_t = np.append(X_t, x_new, axis=0)\n",
        "  y_t = np.append(y_t, y_new, axis=0)\n",
        "  X_un = np.delete(X_un, l_correct, axis = 0)\n",
        "  y_un = np.delete(y_un, l_correct, axis=0)\n",
        "  print(\"unlabeled remaining=\",len(X_un),\" labels added=\",len(x_new))\n",
        "  labels_tobe_added.append(len(x_new))\n",
        "  #rem_unlabeled.append(len(X_un))\n",
        "  iteration=iteration+1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "labeled at start of iteration: 1  is  1833 and unlabeled is 5240\n",
            "Epoch 1/300\n",
            "4/4 [==============================] - 2s 303ms/step - loss: 2.3182 - accuracy: 0.1165 - val_loss: 2.1753 - val_accuracy: 0.2557\n",
            "Epoch 2/300\n",
            "4/4 [==============================] - 1s 259ms/step - loss: 2.1601 - accuracy: 0.2563 - val_loss: 2.0752 - val_accuracy: 0.3130\n",
            "Epoch 3/300\n",
            "4/4 [==============================] - 1s 252ms/step - loss: 2.0682 - accuracy: 0.3102 - val_loss: 1.9938 - val_accuracy: 0.3321\n",
            "Epoch 4/300\n",
            "4/4 [==============================] - 1s 245ms/step - loss: 1.9863 - accuracy: 0.3359 - val_loss: 1.9306 - val_accuracy: 0.3677\n",
            "Epoch 5/300\n",
            "4/4 [==============================] - 1s 248ms/step - loss: 1.9282 - accuracy: 0.3622 - val_loss: 1.8837 - val_accuracy: 0.3880\n",
            "Epoch 6/300\n",
            "4/4 [==============================] - 1s 253ms/step - loss: 1.8798 - accuracy: 0.3872 - val_loss: 1.8410 - val_accuracy: 0.3995\n",
            "Epoch 7/300\n",
            "4/4 [==============================] - 1s 247ms/step - loss: 1.8268 - accuracy: 0.4005 - val_loss: 1.8035 - val_accuracy: 0.4109\n",
            "Epoch 8/300\n",
            "4/4 [==============================] - 1s 258ms/step - loss: 1.8035 - accuracy: 0.3994 - val_loss: 1.7738 - val_accuracy: 0.4211\n",
            "Epoch 9/300\n",
            "4/4 [==============================] - 1s 263ms/step - loss: 1.7639 - accuracy: 0.4173 - val_loss: 1.7450 - val_accuracy: 0.4478\n",
            "Epoch 10/300\n",
            "4/4 [==============================] - 1s 245ms/step - loss: 1.7135 - accuracy: 0.4369 - val_loss: 1.7183 - val_accuracy: 0.4656\n",
            "Epoch 11/300\n",
            "4/4 [==============================] - 1s 251ms/step - loss: 1.7209 - accuracy: 0.4428 - val_loss: 1.6943 - val_accuracy: 0.4758\n",
            "Epoch 12/300\n",
            "4/4 [==============================] - 1s 257ms/step - loss: 1.6924 - accuracy: 0.4507 - val_loss: 1.6742 - val_accuracy: 0.4784\n",
            "Epoch 13/300\n",
            "4/4 [==============================] - 1s 253ms/step - loss: 1.6545 - accuracy: 0.4745 - val_loss: 1.6533 - val_accuracy: 0.4835\n",
            "Epoch 14/300\n",
            "4/4 [==============================] - 1s 249ms/step - loss: 1.6746 - accuracy: 0.4544 - val_loss: 1.6323 - val_accuracy: 0.4936\n",
            "Epoch 15/300\n",
            "4/4 [==============================] - 1s 262ms/step - loss: 1.6145 - accuracy: 0.4740 - val_loss: 1.6129 - val_accuracy: 0.5025\n",
            "Epoch 16/300\n",
            "4/4 [==============================] - 1s 251ms/step - loss: 1.6066 - accuracy: 0.4774 - val_loss: 1.5956 - val_accuracy: 0.5025\n",
            "Epoch 17/300\n",
            "4/4 [==============================] - 1s 253ms/step - loss: 1.5966 - accuracy: 0.4796 - val_loss: 1.5796 - val_accuracy: 0.5089\n",
            "Epoch 18/300\n",
            "4/4 [==============================] - 1s 251ms/step - loss: 1.5650 - accuracy: 0.5023 - val_loss: 1.5636 - val_accuracy: 0.5076\n",
            "Epoch 19/300\n",
            "4/4 [==============================] - 1s 250ms/step - loss: 1.5585 - accuracy: 0.4920 - val_loss: 1.5466 - val_accuracy: 0.5127\n",
            "Epoch 20/300\n",
            "4/4 [==============================] - 1s 250ms/step - loss: 1.5492 - accuracy: 0.4895 - val_loss: 1.5316 - val_accuracy: 0.5140\n",
            "Epoch 21/300\n",
            "4/4 [==============================] - 1s 246ms/step - loss: 1.5134 - accuracy: 0.5048 - val_loss: 1.5183 - val_accuracy: 0.5076\n",
            "Epoch 22/300\n",
            "4/4 [==============================] - 1s 247ms/step - loss: 1.5103 - accuracy: 0.4917 - val_loss: 1.5035 - val_accuracy: 0.5076\n",
            "Epoch 23/300\n",
            "4/4 [==============================] - 1s 246ms/step - loss: 1.4743 - accuracy: 0.5092 - val_loss: 1.4900 - val_accuracy: 0.5153\n",
            "Epoch 24/300\n",
            "4/4 [==============================] - 1s 245ms/step - loss: 1.4531 - accuracy: 0.5211 - val_loss: 1.4774 - val_accuracy: 0.5165\n",
            "Epoch 25/300\n",
            "4/4 [==============================] - 1s 252ms/step - loss: 1.4629 - accuracy: 0.5078 - val_loss: 1.4646 - val_accuracy: 0.5216\n",
            "Epoch 26/300\n",
            "4/4 [==============================] - 1s 250ms/step - loss: 1.4468 - accuracy: 0.5182 - val_loss: 1.4506 - val_accuracy: 0.5331\n",
            "Epoch 27/300\n",
            "4/4 [==============================] - 1s 247ms/step - loss: 1.4323 - accuracy: 0.5204 - val_loss: 1.4398 - val_accuracy: 0.5267\n",
            "Epoch 28/300\n",
            "4/4 [==============================] - 1s 255ms/step - loss: 1.4119 - accuracy: 0.5319 - val_loss: 1.4285 - val_accuracy: 0.5293\n",
            "Epoch 29/300\n",
            "4/4 [==============================] - 1s 254ms/step - loss: 1.3997 - accuracy: 0.5333 - val_loss: 1.4174 - val_accuracy: 0.5318\n",
            "Epoch 30/300\n",
            "4/4 [==============================] - 1s 255ms/step - loss: 1.3928 - accuracy: 0.5382 - val_loss: 1.4064 - val_accuracy: 0.5356\n",
            "Epoch 31/300\n",
            "4/4 [==============================] - 1s 252ms/step - loss: 1.3804 - accuracy: 0.5317 - val_loss: 1.3948 - val_accuracy: 0.5344\n",
            "Epoch 32/300\n",
            "4/4 [==============================] - 1s 253ms/step - loss: 1.3622 - accuracy: 0.5440 - val_loss: 1.3858 - val_accuracy: 0.5433\n",
            "Epoch 33/300\n",
            "4/4 [==============================] - 1s 251ms/step - loss: 1.3689 - accuracy: 0.5389 - val_loss: 1.3754 - val_accuracy: 0.5394\n",
            "Epoch 34/300\n",
            "4/4 [==============================] - 1s 252ms/step - loss: 1.3437 - accuracy: 0.5474 - val_loss: 1.3665 - val_accuracy: 0.5496\n",
            "Epoch 35/300\n",
            "4/4 [==============================] - 1s 250ms/step - loss: 1.3349 - accuracy: 0.5496 - val_loss: 1.3582 - val_accuracy: 0.5547\n",
            "Epoch 36/300\n",
            "4/4 [==============================] - 1s 256ms/step - loss: 1.3186 - accuracy: 0.5580 - val_loss: 1.3506 - val_accuracy: 0.5522\n",
            "Epoch 37/300\n",
            "4/4 [==============================] - 1s 249ms/step - loss: 1.3166 - accuracy: 0.5632 - val_loss: 1.3402 - val_accuracy: 0.5560\n",
            "Epoch 38/300\n",
            "4/4 [==============================] - 1s 259ms/step - loss: 1.3099 - accuracy: 0.5592 - val_loss: 1.3312 - val_accuracy: 0.5573\n",
            "Epoch 39/300\n",
            "4/4 [==============================] - 1s 259ms/step - loss: 1.2967 - accuracy: 0.5610 - val_loss: 1.3274 - val_accuracy: 0.5598\n",
            "Epoch 40/300\n",
            "4/4 [==============================] - 1s 252ms/step - loss: 1.2862 - accuracy: 0.5655 - val_loss: 1.3173 - val_accuracy: 0.5623\n",
            "Epoch 41/300\n",
            "4/4 [==============================] - 1s 248ms/step - loss: 1.2611 - accuracy: 0.5827 - val_loss: 1.3092 - val_accuracy: 0.5662\n",
            "Epoch 42/300\n",
            "4/4 [==============================] - 1s 252ms/step - loss: 1.2719 - accuracy: 0.5838 - val_loss: 1.3024 - val_accuracy: 0.5712\n",
            "Epoch 43/300\n",
            "4/4 [==============================] - 1s 254ms/step - loss: 1.2326 - accuracy: 0.5962 - val_loss: 1.2954 - val_accuracy: 0.5674\n",
            "Epoch 44/300\n",
            "4/4 [==============================] - 1s 253ms/step - loss: 1.2444 - accuracy: 0.5886 - val_loss: 1.2870 - val_accuracy: 0.5662\n",
            "Epoch 45/300\n",
            "4/4 [==============================] - 1s 252ms/step - loss: 1.2237 - accuracy: 0.5893 - val_loss: 1.2802 - val_accuracy: 0.5649\n",
            "Epoch 46/300\n",
            "4/4 [==============================] - 1s 251ms/step - loss: 1.2412 - accuracy: 0.5797 - val_loss: 1.2756 - val_accuracy: 0.5751\n",
            "Epoch 47/300\n",
            "4/4 [==============================] - 1s 253ms/step - loss: 1.2105 - accuracy: 0.5876 - val_loss: 1.2678 - val_accuracy: 0.5827\n",
            "Epoch 48/300\n",
            "4/4 [==============================] - 1s 268ms/step - loss: 1.2027 - accuracy: 0.5983 - val_loss: 1.2625 - val_accuracy: 0.5840\n",
            "Epoch 49/300\n",
            "4/4 [==============================] - 1s 252ms/step - loss: 1.2167 - accuracy: 0.6032 - val_loss: 1.2556 - val_accuracy: 0.5802\n",
            "Epoch 50/300\n",
            "4/4 [==============================] - 1s 258ms/step - loss: 1.1964 - accuracy: 0.6050 - val_loss: 1.2514 - val_accuracy: 0.5852\n",
            "Epoch 51/300\n",
            "4/4 [==============================] - 1s 252ms/step - loss: 1.1749 - accuracy: 0.6119 - val_loss: 1.2441 - val_accuracy: 0.5916\n",
            "Epoch 52/300\n",
            "4/4 [==============================] - 1s 251ms/step - loss: 1.1780 - accuracy: 0.6105 - val_loss: 1.2380 - val_accuracy: 0.5891\n",
            "Epoch 53/300\n",
            "4/4 [==============================] - 1s 252ms/step - loss: 1.1639 - accuracy: 0.6085 - val_loss: 1.2335 - val_accuracy: 0.5929\n",
            "Epoch 54/300\n",
            "4/4 [==============================] - 1s 251ms/step - loss: 1.1434 - accuracy: 0.6144 - val_loss: 1.2270 - val_accuracy: 0.5941\n",
            "Epoch 55/300\n",
            "4/4 [==============================] - 1s 251ms/step - loss: 1.1550 - accuracy: 0.6167 - val_loss: 1.2198 - val_accuracy: 0.5967\n",
            "Epoch 56/300\n",
            "4/4 [==============================] - 1s 252ms/step - loss: 1.1172 - accuracy: 0.6278 - val_loss: 1.2162 - val_accuracy: 0.6018\n",
            "Epoch 57/300\n",
            "4/4 [==============================] - 1s 256ms/step - loss: 1.1112 - accuracy: 0.6233 - val_loss: 1.2094 - val_accuracy: 0.6031\n",
            "Epoch 58/300\n",
            "4/4 [==============================] - 1s 259ms/step - loss: 1.1145 - accuracy: 0.6312 - val_loss: 1.2034 - val_accuracy: 0.6056\n",
            "Epoch 59/300\n",
            "4/4 [==============================] - 1s 247ms/step - loss: 1.1253 - accuracy: 0.6189 - val_loss: 1.2027 - val_accuracy: 0.5980\n",
            "Epoch 60/300\n",
            "4/4 [==============================] - 1s 245ms/step - loss: 1.1208 - accuracy: 0.6264 - val_loss: 1.1958 - val_accuracy: 0.6031\n",
            "Epoch 61/300\n",
            "4/4 [==============================] - 1s 249ms/step - loss: 1.1176 - accuracy: 0.6334 - val_loss: 1.1912 - val_accuracy: 0.6031\n",
            "Epoch 62/300\n",
            "4/4 [==============================] - 1s 256ms/step - loss: 1.0880 - accuracy: 0.6363 - val_loss: 1.1874 - val_accuracy: 0.6043\n",
            "Epoch 63/300\n",
            "4/4 [==============================] - 1s 249ms/step - loss: 1.0855 - accuracy: 0.6318 - val_loss: 1.1832 - val_accuracy: 0.6018\n",
            "Epoch 64/300\n",
            "4/4 [==============================] - 1s 260ms/step - loss: 1.0716 - accuracy: 0.6375 - val_loss: 1.1779 - val_accuracy: 0.6043\n",
            "Epoch 65/300\n",
            "4/4 [==============================] - 1s 253ms/step - loss: 1.0779 - accuracy: 0.6382 - val_loss: 1.1744 - val_accuracy: 0.6094\n",
            "Epoch 66/300\n",
            "4/4 [==============================] - 1s 256ms/step - loss: 1.0454 - accuracy: 0.6531 - val_loss: 1.1701 - val_accuracy: 0.6132\n",
            "Epoch 67/300\n",
            "4/4 [==============================] - 1s 257ms/step - loss: 1.0550 - accuracy: 0.6480 - val_loss: 1.1625 - val_accuracy: 0.6145\n",
            "Epoch 68/300\n",
            "4/4 [==============================] - 1s 252ms/step - loss: 1.0508 - accuracy: 0.6467 - val_loss: 1.1614 - val_accuracy: 0.6183\n",
            "Epoch 69/300\n",
            "4/4 [==============================] - 1s 253ms/step - loss: 1.0548 - accuracy: 0.6451 - val_loss: 1.1593 - val_accuracy: 0.6158\n",
            "Epoch 70/300\n",
            "4/4 [==============================] - 1s 252ms/step - loss: 1.0595 - accuracy: 0.6455 - val_loss: 1.1533 - val_accuracy: 0.6183\n",
            "Epoch 71/300\n",
            "4/4 [==============================] - 1s 257ms/step - loss: 1.0353 - accuracy: 0.6504 - val_loss: 1.1491 - val_accuracy: 0.6221\n",
            "Epoch 72/300\n",
            "4/4 [==============================] - 1s 254ms/step - loss: 1.0247 - accuracy: 0.6577 - val_loss: 1.1438 - val_accuracy: 0.6234\n",
            "Epoch 73/300\n",
            "4/4 [==============================] - 1s 248ms/step - loss: 1.0099 - accuracy: 0.6573 - val_loss: 1.1396 - val_accuracy: 0.6247\n",
            "Epoch 74/300\n",
            "4/4 [==============================] - 1s 251ms/step - loss: 1.0348 - accuracy: 0.6513 - val_loss: 1.1415 - val_accuracy: 0.6234\n",
            "Epoch 75/300\n",
            "4/4 [==============================] - 1s 245ms/step - loss: 1.0118 - accuracy: 0.6659 - val_loss: 1.1347 - val_accuracy: 0.6234\n",
            "Epoch 76/300\n",
            "4/4 [==============================] - 1s 254ms/step - loss: 0.9992 - accuracy: 0.6648 - val_loss: 1.1293 - val_accuracy: 0.6323\n",
            "Epoch 77/300\n",
            "4/4 [==============================] - 1s 258ms/step - loss: 0.9937 - accuracy: 0.6635 - val_loss: 1.1312 - val_accuracy: 0.6336\n",
            "Epoch 78/300\n",
            "4/4 [==============================] - 1s 253ms/step - loss: 0.9881 - accuracy: 0.6683 - val_loss: 1.1304 - val_accuracy: 0.6310\n",
            "Epoch 79/300\n",
            "4/4 [==============================] - 1s 246ms/step - loss: 0.9699 - accuracy: 0.6769 - val_loss: 1.1183 - val_accuracy: 0.6310\n",
            "Epoch 80/300\n",
            "4/4 [==============================] - 1s 252ms/step - loss: 0.9889 - accuracy: 0.6707 - val_loss: 1.1177 - val_accuracy: 0.6374\n",
            "Epoch 81/300\n",
            "4/4 [==============================] - 1s 252ms/step - loss: 0.9752 - accuracy: 0.6723 - val_loss: 1.1176 - val_accuracy: 0.6298\n",
            "Epoch 82/300\n",
            "4/4 [==============================] - 1s 249ms/step - loss: 0.9746 - accuracy: 0.6652 - val_loss: 1.1118 - val_accuracy: 0.6425\n",
            "Epoch 83/300\n",
            "4/4 [==============================] - 1s 253ms/step - loss: 0.9567 - accuracy: 0.6865 - val_loss: 1.1075 - val_accuracy: 0.6438\n",
            "Epoch 84/300\n",
            "4/4 [==============================] - 1s 249ms/step - loss: 0.9404 - accuracy: 0.6840 - val_loss: 1.1070 - val_accuracy: 0.6438\n",
            "Epoch 85/300\n",
            "4/4 [==============================] - 1s 257ms/step - loss: 0.9794 - accuracy: 0.6682 - val_loss: 1.1006 - val_accuracy: 0.6438\n",
            "Epoch 86/300\n",
            "4/4 [==============================] - 1s 251ms/step - loss: 0.9437 - accuracy: 0.6781 - val_loss: 1.0966 - val_accuracy: 0.6489\n",
            "Epoch 87/300\n",
            "4/4 [==============================] - 1s 257ms/step - loss: 0.9519 - accuracy: 0.6839 - val_loss: 1.0967 - val_accuracy: 0.6489\n",
            "Epoch 88/300\n",
            "4/4 [==============================] - 1s 253ms/step - loss: 0.9410 - accuracy: 0.6883 - val_loss: 1.0991 - val_accuracy: 0.6438\n",
            "Epoch 89/300\n",
            "4/4 [==============================] - 1s 250ms/step - loss: 0.9173 - accuracy: 0.6934 - val_loss: 1.0914 - val_accuracy: 0.6463\n",
            "Epoch 90/300\n",
            "4/4 [==============================] - 1s 253ms/step - loss: 0.9299 - accuracy: 0.6912 - val_loss: 1.0866 - val_accuracy: 0.6514\n",
            "Epoch 91/300\n",
            "4/4 [==============================] - 1s 251ms/step - loss: 0.9163 - accuracy: 0.6998 - val_loss: 1.0903 - val_accuracy: 0.6450\n",
            "Epoch 92/300\n",
            "4/4 [==============================] - 1s 253ms/step - loss: 0.9318 - accuracy: 0.6900 - val_loss: 1.0839 - val_accuracy: 0.6463\n",
            "Epoch 93/300\n",
            "4/4 [==============================] - 1s 254ms/step - loss: 0.9197 - accuracy: 0.6884 - val_loss: 1.0796 - val_accuracy: 0.6489\n",
            "Epoch 94/300\n",
            "4/4 [==============================] - 1s 253ms/step - loss: 0.9030 - accuracy: 0.6988 - val_loss: 1.0807 - val_accuracy: 0.6489\n",
            "Epoch 95/300\n",
            "4/4 [==============================] - 1s 253ms/step - loss: 0.8979 - accuracy: 0.6982 - val_loss: 1.0757 - val_accuracy: 0.6489\n",
            "Epoch 96/300\n",
            "4/4 [==============================] - 1s 251ms/step - loss: 0.8910 - accuracy: 0.7005 - val_loss: 1.0732 - val_accuracy: 0.6578\n",
            "Epoch 97/300\n",
            "4/4 [==============================] - 1s 259ms/step - loss: 0.9013 - accuracy: 0.7052 - val_loss: 1.0719 - val_accuracy: 0.6552\n",
            "Epoch 98/300\n",
            "4/4 [==============================] - 1s 256ms/step - loss: 0.8821 - accuracy: 0.7168 - val_loss: 1.0757 - val_accuracy: 0.6514\n",
            "Epoch 99/300\n",
            "4/4 [==============================] - 1s 252ms/step - loss: 0.8812 - accuracy: 0.7041 - val_loss: 1.0732 - val_accuracy: 0.6552\n",
            "Epoch 100/300\n",
            "4/4 [==============================] - 1s 249ms/step - loss: 0.8660 - accuracy: 0.7059 - val_loss: 1.0669 - val_accuracy: 0.6565\n",
            "Epoch 101/300\n",
            "4/4 [==============================] - 1s 255ms/step - loss: 0.8668 - accuracy: 0.7099 - val_loss: 1.0670 - val_accuracy: 0.6514\n",
            "Epoch 102/300\n",
            "4/4 [==============================] - 1s 252ms/step - loss: 0.8615 - accuracy: 0.7158 - val_loss: 1.0666 - val_accuracy: 0.6552\n",
            "Epoch 103/300\n",
            "4/4 [==============================] - 1s 254ms/step - loss: 0.8629 - accuracy: 0.7168 - val_loss: 1.0588 - val_accuracy: 0.6514\n",
            "Epoch 104/300\n",
            "4/4 [==============================] - 1s 259ms/step - loss: 0.8400 - accuracy: 0.7236 - val_loss: 1.0572 - val_accuracy: 0.6552\n",
            "Epoch 105/300\n",
            "4/4 [==============================] - 1s 251ms/step - loss: 0.8564 - accuracy: 0.7130 - val_loss: 1.0615 - val_accuracy: 0.6590\n",
            "Epoch 106/300\n",
            "4/4 [==============================] - 1s 252ms/step - loss: 0.8417 - accuracy: 0.7250 - val_loss: 1.0563 - val_accuracy: 0.6514\n",
            "Epoch 107/300\n",
            "4/4 [==============================] - 1s 263ms/step - loss: 0.8371 - accuracy: 0.7265 - val_loss: 1.0513 - val_accuracy: 0.6565\n",
            "Epoch 108/300\n",
            "4/4 [==============================] - 1s 246ms/step - loss: 0.8465 - accuracy: 0.7237 - val_loss: 1.0561 - val_accuracy: 0.6565\n",
            "Epoch 109/300\n",
            "4/4 [==============================] - 1s 257ms/step - loss: 0.8517 - accuracy: 0.7257 - val_loss: 1.0522 - val_accuracy: 0.6628\n",
            "Epoch 110/300\n",
            "4/4 [==============================] - 1s 251ms/step - loss: 0.8291 - accuracy: 0.7368 - val_loss: 1.0459 - val_accuracy: 0.6578\n",
            "Epoch 111/300\n",
            "4/4 [==============================] - 1s 251ms/step - loss: 0.8277 - accuracy: 0.7348 - val_loss: 1.0487 - val_accuracy: 0.6590\n",
            "Epoch 112/300\n",
            "4/4 [==============================] - 1s 248ms/step - loss: 0.8350 - accuracy: 0.7395 - val_loss: 1.0503 - val_accuracy: 0.6667\n",
            "Epoch 113/300\n",
            "4/4 [==============================] - 1s 248ms/step - loss: 0.8146 - accuracy: 0.7359 - val_loss: 1.0433 - val_accuracy: 0.6616\n",
            "Epoch 114/300\n",
            "4/4 [==============================] - 1s 252ms/step - loss: 0.8221 - accuracy: 0.7308 - val_loss: 1.0448 - val_accuracy: 0.6654\n",
            "Epoch 115/300\n",
            "4/4 [==============================] - 1s 250ms/step - loss: 0.8140 - accuracy: 0.7376 - val_loss: 1.0480 - val_accuracy: 0.6692\n",
            "Epoch 116/300\n",
            "4/4 [==============================] - 1s 257ms/step - loss: 0.8084 - accuracy: 0.7398 - val_loss: 1.0421 - val_accuracy: 0.6705\n",
            "Epoch 117/300\n",
            "4/4 [==============================] - 1s 255ms/step - loss: 0.7802 - accuracy: 0.7556 - val_loss: 1.0352 - val_accuracy: 0.6654\n",
            "Epoch 118/300\n",
            "4/4 [==============================] - 1s 253ms/step - loss: 0.7755 - accuracy: 0.7466 - val_loss: 1.0347 - val_accuracy: 0.6705\n",
            "Epoch 119/300\n",
            "4/4 [==============================] - 1s 250ms/step - loss: 0.8045 - accuracy: 0.7397 - val_loss: 1.0360 - val_accuracy: 0.6654\n",
            "Epoch 120/300\n",
            "4/4 [==============================] - 1s 252ms/step - loss: 0.7943 - accuracy: 0.7420 - val_loss: 1.0321 - val_accuracy: 0.6718\n",
            "Epoch 121/300\n",
            "4/4 [==============================] - 1s 258ms/step - loss: 0.7951 - accuracy: 0.7465 - val_loss: 1.0336 - val_accuracy: 0.6718\n",
            "Epoch 122/300\n",
            "4/4 [==============================] - 1s 256ms/step - loss: 0.7664 - accuracy: 0.7571 - val_loss: 1.0339 - val_accuracy: 0.6692\n",
            "Epoch 123/300\n",
            "4/4 [==============================] - 1s 250ms/step - loss: 0.7926 - accuracy: 0.7396 - val_loss: 1.0313 - val_accuracy: 0.6654\n",
            "Epoch 124/300\n",
            "4/4 [==============================] - 1s 254ms/step - loss: 0.7922 - accuracy: 0.7504 - val_loss: 1.0275 - val_accuracy: 0.6641\n",
            "Epoch 125/300\n",
            "4/4 [==============================] - 1s 251ms/step - loss: 0.7610 - accuracy: 0.7543 - val_loss: 1.0266 - val_accuracy: 0.6718\n",
            "Epoch 126/300\n",
            "4/4 [==============================] - 1s 251ms/step - loss: 0.7524 - accuracy: 0.7684 - val_loss: 1.0279 - val_accuracy: 0.6692\n",
            "Epoch 127/300\n",
            "4/4 [==============================] - 1s 260ms/step - loss: 0.7762 - accuracy: 0.7645 - val_loss: 1.0235 - val_accuracy: 0.6705\n",
            "Epoch 128/300\n",
            "4/4 [==============================] - 1s 260ms/step - loss: 0.7448 - accuracy: 0.7601 - val_loss: 1.0210 - val_accuracy: 0.6743\n",
            "Epoch 129/300\n",
            "4/4 [==============================] - 1s 262ms/step - loss: 0.7636 - accuracy: 0.7478 - val_loss: 1.0208 - val_accuracy: 0.6730\n",
            "Epoch 130/300\n",
            "4/4 [==============================] - 1s 256ms/step - loss: 0.7513 - accuracy: 0.7588 - val_loss: 1.0264 - val_accuracy: 0.6628\n",
            "Epoch 131/300\n",
            "4/4 [==============================] - 1s 254ms/step - loss: 0.7485 - accuracy: 0.7543 - val_loss: 1.0207 - val_accuracy: 0.6718\n",
            "Epoch 132/300\n",
            "4/4 [==============================] - 1s 254ms/step - loss: 0.7513 - accuracy: 0.7651 - val_loss: 1.0157 - val_accuracy: 0.6718\n",
            "Epoch 133/300\n",
            "4/4 [==============================] - 1s 258ms/step - loss: 0.7318 - accuracy: 0.7679 - val_loss: 1.0190 - val_accuracy: 0.6718\n",
            "Epoch 134/300\n",
            "4/4 [==============================] - 1s 248ms/step - loss: 0.7346 - accuracy: 0.7643 - val_loss: 1.0198 - val_accuracy: 0.6718\n",
            "Epoch 135/300\n",
            "4/4 [==============================] - 1s 252ms/step - loss: 0.7287 - accuracy: 0.7678 - val_loss: 1.0143 - val_accuracy: 0.6794\n",
            "Epoch 136/300\n",
            "4/4 [==============================] - 1s 248ms/step - loss: 0.7215 - accuracy: 0.7668 - val_loss: 1.0188 - val_accuracy: 0.6756\n",
            "Epoch 137/300\n",
            "4/4 [==============================] - 1s 261ms/step - loss: 0.7342 - accuracy: 0.7741 - val_loss: 1.0163 - val_accuracy: 0.6730\n",
            "Epoch 138/300\n",
            "4/4 [==============================] - 1s 255ms/step - loss: 0.7284 - accuracy: 0.7690 - val_loss: 1.0129 - val_accuracy: 0.6807\n",
            "Epoch 139/300\n",
            "4/4 [==============================] - 1s 253ms/step - loss: 0.7132 - accuracy: 0.7774 - val_loss: 1.0111 - val_accuracy: 0.6781\n",
            "Epoch 140/300\n",
            "4/4 [==============================] - 1s 250ms/step - loss: 0.7164 - accuracy: 0.7799 - val_loss: 1.0128 - val_accuracy: 0.6743\n",
            "Epoch 141/300\n",
            "4/4 [==============================] - 1s 250ms/step - loss: 0.7057 - accuracy: 0.7795 - val_loss: 1.0114 - val_accuracy: 0.6794\n",
            "Epoch 142/300\n",
            "4/4 [==============================] - 1s 255ms/step - loss: 0.7025 - accuracy: 0.7799 - val_loss: 1.0094 - val_accuracy: 0.6819\n",
            "Epoch 143/300\n",
            "4/4 [==============================] - 1s 253ms/step - loss: 0.7172 - accuracy: 0.7698 - val_loss: 1.0115 - val_accuracy: 0.6794\n",
            "Epoch 144/300\n",
            "4/4 [==============================] - 1s 255ms/step - loss: 0.7072 - accuracy: 0.7743 - val_loss: 1.0105 - val_accuracy: 0.6819\n",
            "Epoch 145/300\n",
            "4/4 [==============================] - 1s 254ms/step - loss: 0.7218 - accuracy: 0.7686 - val_loss: 1.0054 - val_accuracy: 0.6845\n",
            "Epoch 146/300\n",
            "4/4 [==============================] - 1s 253ms/step - loss: 0.6930 - accuracy: 0.7826 - val_loss: 1.0057 - val_accuracy: 0.6807\n",
            "Epoch 147/300\n",
            "4/4 [==============================] - 1s 252ms/step - loss: 0.7058 - accuracy: 0.7742 - val_loss: 1.0084 - val_accuracy: 0.6730\n",
            "Epoch 148/300\n",
            "4/4 [==============================] - 1s 261ms/step - loss: 0.7112 - accuracy: 0.7685 - val_loss: 1.0054 - val_accuracy: 0.6743\n",
            "Epoch 149/300\n",
            "4/4 [==============================] - 1s 253ms/step - loss: 0.7151 - accuracy: 0.7691 - val_loss: 1.0038 - val_accuracy: 0.6819\n",
            "Epoch 150/300\n",
            "4/4 [==============================] - 1s 254ms/step - loss: 0.6797 - accuracy: 0.7805 - val_loss: 0.9997 - val_accuracy: 0.6781\n",
            "Epoch 151/300\n",
            "4/4 [==============================] - 1s 250ms/step - loss: 0.6693 - accuracy: 0.7961 - val_loss: 1.0040 - val_accuracy: 0.6794\n",
            "Epoch 152/300\n",
            "4/4 [==============================] - 1s 262ms/step - loss: 0.6752 - accuracy: 0.7819 - val_loss: 1.0007 - val_accuracy: 0.6819\n",
            "Epoch 153/300\n",
            "4/4 [==============================] - 1s 254ms/step - loss: 0.6648 - accuracy: 0.7893 - val_loss: 1.0019 - val_accuracy: 0.6768\n",
            "Epoch 154/300\n",
            "4/4 [==============================] - 1s 253ms/step - loss: 0.6789 - accuracy: 0.7871 - val_loss: 1.0021 - val_accuracy: 0.6743\n",
            "Epoch 155/300\n",
            "4/4 [==============================] - 1s 252ms/step - loss: 0.6886 - accuracy: 0.7790 - val_loss: 1.0050 - val_accuracy: 0.6832\n",
            "Epoch 156/300\n",
            "4/4 [==============================] - 1s 253ms/step - loss: 0.6564 - accuracy: 0.7999 - val_loss: 1.0049 - val_accuracy: 0.6756\n",
            "Epoch 157/300\n",
            "4/4 [==============================] - 1s 253ms/step - loss: 0.6800 - accuracy: 0.7814 - val_loss: 1.0038 - val_accuracy: 0.6768\n",
            "Epoch 158/300\n",
            "4/4 [==============================] - 1s 261ms/step - loss: 0.6613 - accuracy: 0.7896 - val_loss: 1.0012 - val_accuracy: 0.6858\n",
            "Epoch 159/300\n",
            "4/4 [==============================] - 1s 254ms/step - loss: 0.6588 - accuracy: 0.8003 - val_loss: 1.0039 - val_accuracy: 0.6819\n",
            "Epoch 160/300\n",
            "4/4 [==============================] - 1s 251ms/step - loss: 0.6550 - accuracy: 0.7884 - val_loss: 1.0034 - val_accuracy: 0.6781\n",
            "Epoch 161/300\n",
            "4/4 [==============================] - 1s 254ms/step - loss: 0.6483 - accuracy: 0.8041 - val_loss: 0.9965 - val_accuracy: 0.6896\n",
            "Epoch 162/300\n",
            "4/4 [==============================] - 1s 252ms/step - loss: 0.6589 - accuracy: 0.7865 - val_loss: 1.0043 - val_accuracy: 0.6794\n",
            "Epoch 163/300\n",
            "4/4 [==============================] - 1s 255ms/step - loss: 0.6416 - accuracy: 0.8013 - val_loss: 1.0075 - val_accuracy: 0.6743\n",
            "Epoch 164/300\n",
            "4/4 [==============================] - 1s 255ms/step - loss: 0.6372 - accuracy: 0.7979 - val_loss: 0.9942 - val_accuracy: 0.6819\n",
            "Epoch 165/300\n",
            "4/4 [==============================] - 1s 255ms/step - loss: 0.6413 - accuracy: 0.8055 - val_loss: 0.9974 - val_accuracy: 0.6921\n",
            "Epoch 166/300\n",
            "4/4 [==============================] - 1s 254ms/step - loss: 0.6333 - accuracy: 0.8089 - val_loss: 1.0018 - val_accuracy: 0.6781\n",
            "Epoch 167/300\n",
            "4/4 [==============================] - 1s 262ms/step - loss: 0.6229 - accuracy: 0.8027 - val_loss: 0.9994 - val_accuracy: 0.6794\n",
            "Epoch 168/300\n",
            "4/4 [==============================] - 1s 253ms/step - loss: 0.6229 - accuracy: 0.8103 - val_loss: 0.9977 - val_accuracy: 0.6819\n",
            "Epoch 169/300\n",
            "4/4 [==============================] - 1s 256ms/step - loss: 0.6548 - accuracy: 0.7942 - val_loss: 0.9936 - val_accuracy: 0.6768\n",
            "Epoch 170/300\n",
            "4/4 [==============================] - 1s 254ms/step - loss: 0.6441 - accuracy: 0.8016 - val_loss: 0.9917 - val_accuracy: 0.6794\n",
            "Epoch 171/300\n",
            "4/4 [==============================] - 1s 261ms/step - loss: 0.6309 - accuracy: 0.8043 - val_loss: 0.9940 - val_accuracy: 0.6768\n",
            "Epoch 172/300\n",
            "4/4 [==============================] - 1s 257ms/step - loss: 0.6194 - accuracy: 0.8125 - val_loss: 0.9983 - val_accuracy: 0.6794\n",
            "Epoch 173/300\n",
            "4/4 [==============================] - 1s 255ms/step - loss: 0.6200 - accuracy: 0.8110 - val_loss: 0.9937 - val_accuracy: 0.6807\n",
            "Epoch 174/300\n",
            "4/4 [==============================] - 1s 256ms/step - loss: 0.6355 - accuracy: 0.8014 - val_loss: 0.9977 - val_accuracy: 0.6807\n",
            "Epoch 175/300\n",
            "4/4 [==============================] - 1s 253ms/step - loss: 0.6045 - accuracy: 0.8199 - val_loss: 1.0004 - val_accuracy: 0.6794\n",
            "Epoch 176/300\n",
            "4/4 [==============================] - 1s 274ms/step - loss: 0.6169 - accuracy: 0.8122 - val_loss: 0.9954 - val_accuracy: 0.6832\n",
            "Epoch 177/300\n",
            "4/4 [==============================] - 1s 254ms/step - loss: 0.6155 - accuracy: 0.8044 - val_loss: 0.9947 - val_accuracy: 0.6832\n",
            "Epoch 178/300\n",
            "4/4 [==============================] - 1s 255ms/step - loss: 0.5997 - accuracy: 0.8130 - val_loss: 0.9940 - val_accuracy: 0.6883\n",
            "Epoch 179/300\n",
            "4/4 [==============================] - 1s 257ms/step - loss: 0.6141 - accuracy: 0.8106 - val_loss: 0.9914 - val_accuracy: 0.6883\n",
            "Epoch 180/300\n",
            "4/4 [==============================] - 1s 253ms/step - loss: 0.6140 - accuracy: 0.8039 - val_loss: 0.9977 - val_accuracy: 0.6807\n",
            "Epoch 181/300\n",
            "4/4 [==============================] - 1s 251ms/step - loss: 0.5913 - accuracy: 0.8207 - val_loss: 0.9953 - val_accuracy: 0.6832\n",
            "Epoch 182/300\n",
            "4/4 [==============================] - 1s 254ms/step - loss: 0.6003 - accuracy: 0.8140 - val_loss: 0.9942 - val_accuracy: 0.6870\n",
            "Epoch 183/300\n",
            "4/4 [==============================] - 1s 251ms/step - loss: 0.6090 - accuracy: 0.8150 - val_loss: 0.9960 - val_accuracy: 0.6819\n",
            "Epoch 184/300\n",
            "4/4 [==============================] - 1s 263ms/step - loss: 0.5900 - accuracy: 0.8175 - val_loss: 0.9995 - val_accuracy: 0.6832\n",
            "Epoch 185/300\n",
            "4/4 [==============================] - 1s 255ms/step - loss: 0.5957 - accuracy: 0.8164 - val_loss: 0.9980 - val_accuracy: 0.6832\n",
            "Epoch 186/300\n",
            "4/4 [==============================] - 1s 255ms/step - loss: 0.5825 - accuracy: 0.8260 - val_loss: 0.9920 - val_accuracy: 0.6832\n",
            "Epoch 187/300\n",
            "4/4 [==============================] - 1s 258ms/step - loss: 0.5778 - accuracy: 0.8206 - val_loss: 0.9914 - val_accuracy: 0.6883\n",
            "Epoch 188/300\n",
            "4/4 [==============================] - 1s 256ms/step - loss: 0.6109 - accuracy: 0.8062 - val_loss: 0.9946 - val_accuracy: 0.6819\n",
            "Epoch 189/300\n",
            "4/4 [==============================] - 1s 253ms/step - loss: 0.5888 - accuracy: 0.8177 - val_loss: 0.9962 - val_accuracy: 0.6870\n",
            "Epoch 190/300\n",
            "4/4 [==============================] - 1s 253ms/step - loss: 0.5876 - accuracy: 0.8252 - val_loss: 0.9972 - val_accuracy: 0.6870\n",
            "Epoch 191/300\n",
            "4/4 [==============================] - 1s 256ms/step - loss: 0.5715 - accuracy: 0.8231 - val_loss: 1.0028 - val_accuracy: 0.6845\n",
            "Epoch 192/300\n",
            "4/4 [==============================] - 1s 257ms/step - loss: 0.5958 - accuracy: 0.8109 - val_loss: 0.9960 - val_accuracy: 0.6832\n",
            "Epoch 193/300\n",
            "4/4 [==============================] - 1s 257ms/step - loss: 0.5896 - accuracy: 0.8160 - val_loss: 0.9904 - val_accuracy: 0.6858\n",
            "Epoch 194/300\n",
            "4/4 [==============================] - 1s 259ms/step - loss: 0.5741 - accuracy: 0.8267 - val_loss: 0.9942 - val_accuracy: 0.6858\n",
            "Epoch 195/300\n",
            "4/4 [==============================] - 1s 264ms/step - loss: 0.5589 - accuracy: 0.8334 - val_loss: 0.9966 - val_accuracy: 0.6845\n",
            "Epoch 196/300\n",
            "4/4 [==============================] - 1s 255ms/step - loss: 0.5751 - accuracy: 0.8234 - val_loss: 0.9929 - val_accuracy: 0.6845\n",
            "Epoch 197/300\n",
            "4/4 [==============================] - 1s 257ms/step - loss: 0.5587 - accuracy: 0.8290 - val_loss: 0.9962 - val_accuracy: 0.6870\n",
            "Epoch 198/300\n",
            "4/4 [==============================] - 1s 258ms/step - loss: 0.5608 - accuracy: 0.8296 - val_loss: 0.9955 - val_accuracy: 0.6896\n",
            "Epoch 199/300\n",
            "4/4 [==============================] - 1s 255ms/step - loss: 0.5774 - accuracy: 0.8206 - val_loss: 0.9951 - val_accuracy: 0.6858\n",
            "Epoch 200/300\n",
            "4/4 [==============================] - 1s 254ms/step - loss: 0.5715 - accuracy: 0.8227 - val_loss: 0.9957 - val_accuracy: 0.6883\n",
            "Epoch 201/300\n",
            "4/4 [==============================] - 1s 256ms/step - loss: 0.5680 - accuracy: 0.8250 - val_loss: 1.0000 - val_accuracy: 0.6807\n",
            "Epoch 202/300\n",
            "4/4 [==============================] - 1s 253ms/step - loss: 0.5631 - accuracy: 0.8239 - val_loss: 1.0042 - val_accuracy: 0.6870\n",
            "Epoch 203/300\n",
            "4/4 [==============================] - 1s 252ms/step - loss: 0.5511 - accuracy: 0.8325 - val_loss: 1.0008 - val_accuracy: 0.6845\n",
            "Epoch 204/300\n",
            "4/4 [==============================] - 1s 260ms/step - loss: 0.5737 - accuracy: 0.8195 - val_loss: 1.0018 - val_accuracy: 0.6845\n",
            "Epoch 205/300\n",
            "4/4 [==============================] - 1s 254ms/step - loss: 0.5334 - accuracy: 0.8372 - val_loss: 1.0010 - val_accuracy: 0.6870\n",
            "Epoch 206/300\n",
            "4/4 [==============================] - 1s 267ms/step - loss: 0.5352 - accuracy: 0.8386 - val_loss: 1.0098 - val_accuracy: 0.6845\n",
            "Epoch 207/300\n",
            "4/4 [==============================] - 1s 259ms/step - loss: 0.5482 - accuracy: 0.8345 - val_loss: 1.0015 - val_accuracy: 0.6858\n",
            "Epoch 208/300\n",
            "4/4 [==============================] - 1s 258ms/step - loss: 0.5308 - accuracy: 0.8512 - val_loss: 0.9986 - val_accuracy: 0.6883\n",
            "Epoch 209/300\n",
            "4/4 [==============================] - 1s 255ms/step - loss: 0.5390 - accuracy: 0.8332 - val_loss: 0.9937 - val_accuracy: 0.6870\n",
            "Epoch 210/300\n",
            "4/4 [==============================] - 1s 257ms/step - loss: 0.5312 - accuracy: 0.8449 - val_loss: 1.0005 - val_accuracy: 0.6858\n",
            "Epoch 211/300\n",
            "4/4 [==============================] - 1s 255ms/step - loss: 0.5240 - accuracy: 0.8455 - val_loss: 0.9975 - val_accuracy: 0.6908\n",
            "Epoch 212/300\n",
            "4/4 [==============================] - 1s 253ms/step - loss: 0.5382 - accuracy: 0.8319 - val_loss: 0.9988 - val_accuracy: 0.6921\n",
            "Epoch 213/300\n",
            "4/4 [==============================] - 1s 257ms/step - loss: 0.5266 - accuracy: 0.8377 - val_loss: 1.0074 - val_accuracy: 0.6845\n",
            "Epoch 214/300\n",
            "4/4 [==============================] - 1s 258ms/step - loss: 0.5491 - accuracy: 0.8330 - val_loss: 1.0012 - val_accuracy: 0.6883\n",
            "Epoch 215/300\n",
            "4/4 [==============================] - 1s 254ms/step - loss: 0.5456 - accuracy: 0.8323 - val_loss: 0.9965 - val_accuracy: 0.6947\n",
            "Epoch 216/300\n",
            "4/4 [==============================] - 1s 261ms/step - loss: 0.5366 - accuracy: 0.8336 - val_loss: 0.9979 - val_accuracy: 0.6959\n",
            "Epoch 217/300\n",
            "4/4 [==============================] - 1s 253ms/step - loss: 0.5262 - accuracy: 0.8484 - val_loss: 1.0030 - val_accuracy: 0.6908\n",
            "Epoch 218/300\n",
            "4/4 [==============================] - 1s 254ms/step - loss: 0.5262 - accuracy: 0.8447 - val_loss: 1.0001 - val_accuracy: 0.6908\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.9904 - accuracy: 0.6858\n",
            "val_accuracy= [0.9903735518455505, 0.6857506632804871]\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.5506 - accuracy: 0.8320\n",
            "train accuracy= [0.5506041646003723, 0.8319694399833679]\n",
            "unlabeled remaining= 3205  labels added= 2035\n",
            "labeled at start of iteration: 2  is  3257 and unlabeled is 3205\n",
            "Epoch 1/300\n",
            "7/7 [==============================] - 2s 273ms/step - loss: 2.2427 - accuracy: 0.1967 - val_loss: 2.0043 - val_accuracy: 0.3436\n",
            "Epoch 2/300\n",
            "7/7 [==============================] - 2s 250ms/step - loss: 1.9538 - accuracy: 0.3507 - val_loss: 1.8003 - val_accuracy: 0.4603\n",
            "Epoch 3/300\n",
            "7/7 [==============================] - 2s 250ms/step - loss: 1.7608 - accuracy: 0.4596 - val_loss: 1.6759 - val_accuracy: 0.4631\n",
            "Epoch 4/300\n",
            "7/7 [==============================] - 2s 251ms/step - loss: 1.6265 - accuracy: 0.4734 - val_loss: 1.5790 - val_accuracy: 0.5097\n",
            "Epoch 5/300\n",
            "7/7 [==============================] - 2s 249ms/step - loss: 1.5521 - accuracy: 0.5082 - val_loss: 1.5160 - val_accuracy: 0.5426\n",
            "Epoch 6/300\n",
            "7/7 [==============================] - 2s 250ms/step - loss: 1.4911 - accuracy: 0.5424 - val_loss: 1.4617 - val_accuracy: 0.5505\n",
            "Epoch 7/300\n",
            "7/7 [==============================] - 2s 251ms/step - loss: 1.4246 - accuracy: 0.5510 - val_loss: 1.4123 - val_accuracy: 0.5719\n",
            "Epoch 8/300\n",
            "7/7 [==============================] - 2s 252ms/step - loss: 1.3870 - accuracy: 0.5687 - val_loss: 1.3716 - val_accuracy: 0.5755\n",
            "Epoch 9/300\n",
            "7/7 [==============================] - 2s 253ms/step - loss: 1.3418 - accuracy: 0.5870 - val_loss: 1.3318 - val_accuracy: 0.5863\n",
            "Epoch 10/300\n",
            "7/7 [==============================] - 2s 252ms/step - loss: 1.3075 - accuracy: 0.5948 - val_loss: 1.2986 - val_accuracy: 0.5977\n",
            "Epoch 11/300\n",
            "7/7 [==============================] - 2s 252ms/step - loss: 1.2622 - accuracy: 0.6120 - val_loss: 1.2647 - val_accuracy: 0.6049\n",
            "Epoch 12/300\n",
            "7/7 [==============================] - 2s 251ms/step - loss: 1.2490 - accuracy: 0.6153 - val_loss: 1.2340 - val_accuracy: 0.6156\n",
            "Epoch 13/300\n",
            "7/7 [==============================] - 2s 252ms/step - loss: 1.1987 - accuracy: 0.6249 - val_loss: 1.2034 - val_accuracy: 0.6178\n",
            "Epoch 14/300\n",
            "7/7 [==============================] - 2s 250ms/step - loss: 1.1652 - accuracy: 0.6396 - val_loss: 1.1786 - val_accuracy: 0.6321\n",
            "Epoch 15/300\n",
            "7/7 [==============================] - 2s 255ms/step - loss: 1.1466 - accuracy: 0.6440 - val_loss: 1.1529 - val_accuracy: 0.6428\n",
            "Epoch 16/300\n",
            "7/7 [==============================] - 2s 257ms/step - loss: 1.1188 - accuracy: 0.6526 - val_loss: 1.1289 - val_accuracy: 0.6478\n",
            "Epoch 17/300\n",
            "7/7 [==============================] - 2s 250ms/step - loss: 1.0738 - accuracy: 0.6748 - val_loss: 1.1058 - val_accuracy: 0.6528\n",
            "Epoch 18/300\n",
            "7/7 [==============================] - 2s 250ms/step - loss: 1.0501 - accuracy: 0.6737 - val_loss: 1.0814 - val_accuracy: 0.6643\n",
            "Epoch 19/300\n",
            "7/7 [==============================] - 2s 252ms/step - loss: 1.0368 - accuracy: 0.6751 - val_loss: 1.0616 - val_accuracy: 0.6643\n",
            "Epoch 20/300\n",
            "7/7 [==============================] - 2s 249ms/step - loss: 1.0157 - accuracy: 0.6919 - val_loss: 1.0436 - val_accuracy: 0.6729\n",
            "Epoch 21/300\n",
            "7/7 [==============================] - 2s 249ms/step - loss: 0.9906 - accuracy: 0.6893 - val_loss: 1.0251 - val_accuracy: 0.6764\n",
            "Epoch 22/300\n",
            "7/7 [==============================] - 2s 251ms/step - loss: 0.9815 - accuracy: 0.6972 - val_loss: 1.0073 - val_accuracy: 0.6800\n",
            "Epoch 23/300\n",
            "7/7 [==============================] - 2s 252ms/step - loss: 0.9664 - accuracy: 0.6917 - val_loss: 0.9907 - val_accuracy: 0.6800\n",
            "Epoch 24/300\n",
            "7/7 [==============================] - 2s 252ms/step - loss: 0.9241 - accuracy: 0.7090 - val_loss: 0.9791 - val_accuracy: 0.6893\n",
            "Epoch 25/300\n",
            "7/7 [==============================] - 2s 248ms/step - loss: 0.9119 - accuracy: 0.7233 - val_loss: 0.9613 - val_accuracy: 0.6922\n",
            "Epoch 26/300\n",
            "7/7 [==============================] - 2s 255ms/step - loss: 0.8992 - accuracy: 0.7211 - val_loss: 0.9512 - val_accuracy: 0.6958\n",
            "Epoch 27/300\n",
            "7/7 [==============================] - 2s 255ms/step - loss: 0.8677 - accuracy: 0.7367 - val_loss: 0.9348 - val_accuracy: 0.7015\n",
            "Epoch 28/300\n",
            "7/7 [==============================] - 2s 249ms/step - loss: 0.8576 - accuracy: 0.7367 - val_loss: 0.9226 - val_accuracy: 0.7058\n",
            "Epoch 29/300\n",
            "7/7 [==============================] - 2s 252ms/step - loss: 0.8434 - accuracy: 0.7405 - val_loss: 0.9117 - val_accuracy: 0.7022\n",
            "Epoch 30/300\n",
            "7/7 [==============================] - 2s 251ms/step - loss: 0.8305 - accuracy: 0.7425 - val_loss: 0.8995 - val_accuracy: 0.7115\n",
            "Epoch 31/300\n",
            "7/7 [==============================] - 2s 252ms/step - loss: 0.8087 - accuracy: 0.7483 - val_loss: 0.8875 - val_accuracy: 0.7130\n",
            "Epoch 32/300\n",
            "7/7 [==============================] - 2s 252ms/step - loss: 0.8093 - accuracy: 0.7507 - val_loss: 0.8774 - val_accuracy: 0.7165\n",
            "Epoch 33/300\n",
            "7/7 [==============================] - 2s 249ms/step - loss: 0.7677 - accuracy: 0.7638 - val_loss: 0.8684 - val_accuracy: 0.7194\n",
            "Epoch 34/300\n",
            "7/7 [==============================] - 2s 253ms/step - loss: 0.7895 - accuracy: 0.7645 - val_loss: 0.8597 - val_accuracy: 0.7237\n",
            "Epoch 35/300\n",
            "7/7 [==============================] - 2s 250ms/step - loss: 0.7757 - accuracy: 0.7665 - val_loss: 0.8486 - val_accuracy: 0.7316\n",
            "Epoch 36/300\n",
            "7/7 [==============================] - 2s 253ms/step - loss: 0.7507 - accuracy: 0.7702 - val_loss: 0.8410 - val_accuracy: 0.7330\n",
            "Epoch 37/300\n",
            "7/7 [==============================] - 2s 255ms/step - loss: 0.7435 - accuracy: 0.7710 - val_loss: 0.8329 - val_accuracy: 0.7366\n",
            "Epoch 38/300\n",
            "7/7 [==============================] - 2s 257ms/step - loss: 0.7386 - accuracy: 0.7725 - val_loss: 0.8245 - val_accuracy: 0.7380\n",
            "Epoch 39/300\n",
            "7/7 [==============================] - 2s 248ms/step - loss: 0.7134 - accuracy: 0.7853 - val_loss: 0.8187 - val_accuracy: 0.7387\n",
            "Epoch 40/300\n",
            "7/7 [==============================] - 2s 255ms/step - loss: 0.7214 - accuracy: 0.7767 - val_loss: 0.8087 - val_accuracy: 0.7423\n",
            "Epoch 41/300\n",
            "7/7 [==============================] - 2s 257ms/step - loss: 0.7008 - accuracy: 0.7882 - val_loss: 0.8034 - val_accuracy: 0.7459\n",
            "Epoch 42/300\n",
            "7/7 [==============================] - 2s 256ms/step - loss: 0.6891 - accuracy: 0.7948 - val_loss: 0.7982 - val_accuracy: 0.7516\n",
            "Epoch 43/300\n",
            "7/7 [==============================] - 2s 251ms/step - loss: 0.6755 - accuracy: 0.7919 - val_loss: 0.7893 - val_accuracy: 0.7509\n",
            "Epoch 44/300\n",
            "7/7 [==============================] - 2s 253ms/step - loss: 0.6718 - accuracy: 0.8019 - val_loss: 0.7839 - val_accuracy: 0.7523\n",
            "Epoch 45/300\n",
            "7/7 [==============================] - 2s 251ms/step - loss: 0.6519 - accuracy: 0.8075 - val_loss: 0.7809 - val_accuracy: 0.7559\n",
            "Epoch 46/300\n",
            "7/7 [==============================] - 2s 255ms/step - loss: 0.6372 - accuracy: 0.8035 - val_loss: 0.7749 - val_accuracy: 0.7595\n",
            "Epoch 47/300\n",
            "7/7 [==============================] - 2s 252ms/step - loss: 0.6526 - accuracy: 0.8007 - val_loss: 0.7694 - val_accuracy: 0.7595\n",
            "Epoch 48/300\n",
            "7/7 [==============================] - 2s 250ms/step - loss: 0.6319 - accuracy: 0.8072 - val_loss: 0.7624 - val_accuracy: 0.7638\n",
            "Epoch 49/300\n",
            "7/7 [==============================] - 2s 253ms/step - loss: 0.6353 - accuracy: 0.8094 - val_loss: 0.7588 - val_accuracy: 0.7645\n",
            "Epoch 50/300\n",
            "7/7 [==============================] - 2s 249ms/step - loss: 0.6294 - accuracy: 0.8045 - val_loss: 0.7545 - val_accuracy: 0.7674\n",
            "Epoch 51/300\n",
            "7/7 [==============================] - 2s 250ms/step - loss: 0.6236 - accuracy: 0.8056 - val_loss: 0.7502 - val_accuracy: 0.7681\n",
            "Epoch 52/300\n",
            "7/7 [==============================] - 2s 255ms/step - loss: 0.6117 - accuracy: 0.8071 - val_loss: 0.7467 - val_accuracy: 0.7702\n",
            "Epoch 53/300\n",
            "7/7 [==============================] - 2s 253ms/step - loss: 0.5882 - accuracy: 0.8193 - val_loss: 0.7386 - val_accuracy: 0.7652\n",
            "Epoch 54/300\n",
            "7/7 [==============================] - 2s 254ms/step - loss: 0.6072 - accuracy: 0.8113 - val_loss: 0.7394 - val_accuracy: 0.7717\n",
            "Epoch 55/300\n",
            "7/7 [==============================] - 2s 256ms/step - loss: 0.5876 - accuracy: 0.8164 - val_loss: 0.7336 - val_accuracy: 0.7681\n",
            "Epoch 56/300\n",
            "7/7 [==============================] - 2s 257ms/step - loss: 0.6005 - accuracy: 0.8199 - val_loss: 0.7282 - val_accuracy: 0.7724\n",
            "Epoch 57/300\n",
            "7/7 [==============================] - 2s 256ms/step - loss: 0.5759 - accuracy: 0.8243 - val_loss: 0.7268 - val_accuracy: 0.7724\n",
            "Epoch 58/300\n",
            "7/7 [==============================] - 2s 248ms/step - loss: 0.5851 - accuracy: 0.8193 - val_loss: 0.7226 - val_accuracy: 0.7702\n",
            "Epoch 59/300\n",
            "7/7 [==============================] - 2s 255ms/step - loss: 0.5695 - accuracy: 0.8248 - val_loss: 0.7204 - val_accuracy: 0.7731\n",
            "Epoch 60/300\n",
            "7/7 [==============================] - 2s 252ms/step - loss: 0.5725 - accuracy: 0.8155 - val_loss: 0.7161 - val_accuracy: 0.7702\n",
            "Epoch 61/300\n",
            "7/7 [==============================] - 2s 256ms/step - loss: 0.5681 - accuracy: 0.8268 - val_loss: 0.7149 - val_accuracy: 0.7752\n",
            "Epoch 62/300\n",
            "7/7 [==============================] - 2s 251ms/step - loss: 0.5649 - accuracy: 0.8227 - val_loss: 0.7124 - val_accuracy: 0.7752\n",
            "Epoch 63/300\n",
            "7/7 [==============================] - 2s 253ms/step - loss: 0.5491 - accuracy: 0.8263 - val_loss: 0.7063 - val_accuracy: 0.7709\n",
            "Epoch 64/300\n",
            "7/7 [==============================] - 2s 251ms/step - loss: 0.5446 - accuracy: 0.8281 - val_loss: 0.7084 - val_accuracy: 0.7745\n",
            "Epoch 65/300\n",
            "7/7 [==============================] - 2s 252ms/step - loss: 0.5448 - accuracy: 0.8328 - val_loss: 0.7032 - val_accuracy: 0.7767\n",
            "Epoch 66/300\n",
            "7/7 [==============================] - 2s 254ms/step - loss: 0.5392 - accuracy: 0.8330 - val_loss: 0.6978 - val_accuracy: 0.7781\n",
            "Epoch 67/300\n",
            "7/7 [==============================] - 2s 257ms/step - loss: 0.5363 - accuracy: 0.8345 - val_loss: 0.6955 - val_accuracy: 0.7774\n",
            "Epoch 68/300\n",
            "7/7 [==============================] - 2s 250ms/step - loss: 0.5360 - accuracy: 0.8371 - val_loss: 0.6919 - val_accuracy: 0.7788\n",
            "Epoch 69/300\n",
            "7/7 [==============================] - 2s 250ms/step - loss: 0.5358 - accuracy: 0.8292 - val_loss: 0.6926 - val_accuracy: 0.7802\n",
            "Epoch 70/300\n",
            "7/7 [==============================] - 2s 254ms/step - loss: 0.5129 - accuracy: 0.8336 - val_loss: 0.6884 - val_accuracy: 0.7774\n",
            "Epoch 71/300\n",
            "7/7 [==============================] - 2s 255ms/step - loss: 0.5015 - accuracy: 0.8465 - val_loss: 0.6861 - val_accuracy: 0.7774\n",
            "Epoch 72/300\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.5173 - accuracy: 0.8335 - val_loss: 0.6868 - val_accuracy: 0.7838\n",
            "Epoch 73/300\n",
            "7/7 [==============================] - 2s 255ms/step - loss: 0.5026 - accuracy: 0.8409 - val_loss: 0.6802 - val_accuracy: 0.7802\n",
            "Epoch 74/300\n",
            "7/7 [==============================] - 2s 255ms/step - loss: 0.5058 - accuracy: 0.8431 - val_loss: 0.6817 - val_accuracy: 0.7810\n",
            "Epoch 75/300\n",
            "7/7 [==============================] - 2s 255ms/step - loss: 0.4895 - accuracy: 0.8450 - val_loss: 0.6807 - val_accuracy: 0.7810\n",
            "Epoch 76/300\n",
            "7/7 [==============================] - 2s 251ms/step - loss: 0.4875 - accuracy: 0.8485 - val_loss: 0.6767 - val_accuracy: 0.7831\n",
            "Epoch 77/300\n",
            "7/7 [==============================] - 2s 254ms/step - loss: 0.4736 - accuracy: 0.8503 - val_loss: 0.6754 - val_accuracy: 0.7853\n",
            "Epoch 78/300\n",
            "7/7 [==============================] - 2s 256ms/step - loss: 0.4871 - accuracy: 0.8447 - val_loss: 0.6715 - val_accuracy: 0.7860\n",
            "Epoch 79/300\n",
            "7/7 [==============================] - 2s 251ms/step - loss: 0.4818 - accuracy: 0.8513 - val_loss: 0.6716 - val_accuracy: 0.7831\n",
            "Epoch 80/300\n",
            "7/7 [==============================] - 2s 252ms/step - loss: 0.4893 - accuracy: 0.8427 - val_loss: 0.6685 - val_accuracy: 0.7838\n",
            "Epoch 81/300\n",
            "7/7 [==============================] - 2s 253ms/step - loss: 0.4746 - accuracy: 0.8458 - val_loss: 0.6674 - val_accuracy: 0.7867\n",
            "Epoch 82/300\n",
            "7/7 [==============================] - 2s 249ms/step - loss: 0.4753 - accuracy: 0.8448 - val_loss: 0.6667 - val_accuracy: 0.7881\n",
            "Epoch 83/300\n",
            "7/7 [==============================] - 2s 253ms/step - loss: 0.4604 - accuracy: 0.8490 - val_loss: 0.6618 - val_accuracy: 0.7867\n",
            "Epoch 84/300\n",
            "7/7 [==============================] - 2s 257ms/step - loss: 0.4514 - accuracy: 0.8571 - val_loss: 0.6608 - val_accuracy: 0.7881\n",
            "Epoch 85/300\n",
            "7/7 [==============================] - 2s 250ms/step - loss: 0.4647 - accuracy: 0.8477 - val_loss: 0.6623 - val_accuracy: 0.7910\n",
            "Epoch 86/300\n",
            "7/7 [==============================] - 2s 251ms/step - loss: 0.4509 - accuracy: 0.8574 - val_loss: 0.6589 - val_accuracy: 0.7853\n",
            "Epoch 87/300\n",
            "7/7 [==============================] - 2s 253ms/step - loss: 0.4614 - accuracy: 0.8506 - val_loss: 0.6611 - val_accuracy: 0.7874\n",
            "Epoch 88/300\n",
            "7/7 [==============================] - 2s 253ms/step - loss: 0.4522 - accuracy: 0.8542 - val_loss: 0.6580 - val_accuracy: 0.7910\n",
            "Epoch 89/300\n",
            "7/7 [==============================] - 2s 252ms/step - loss: 0.4525 - accuracy: 0.8574 - val_loss: 0.6580 - val_accuracy: 0.7888\n",
            "Epoch 90/300\n",
            "7/7 [==============================] - 2s 254ms/step - loss: 0.4430 - accuracy: 0.8585 - val_loss: 0.6567 - val_accuracy: 0.7867\n",
            "Epoch 91/300\n",
            "7/7 [==============================] - 2s 251ms/step - loss: 0.4456 - accuracy: 0.8593 - val_loss: 0.6510 - val_accuracy: 0.7931\n",
            "Epoch 92/300\n",
            "7/7 [==============================] - 2s 255ms/step - loss: 0.4247 - accuracy: 0.8623 - val_loss: 0.6516 - val_accuracy: 0.7910\n",
            "Epoch 93/300\n",
            "7/7 [==============================] - 2s 250ms/step - loss: 0.4325 - accuracy: 0.8622 - val_loss: 0.6525 - val_accuracy: 0.7910\n",
            "Epoch 94/300\n",
            "7/7 [==============================] - 2s 250ms/step - loss: 0.4434 - accuracy: 0.8574 - val_loss: 0.6488 - val_accuracy: 0.7946\n",
            "Epoch 95/300\n",
            "7/7 [==============================] - 2s 251ms/step - loss: 0.4461 - accuracy: 0.8512 - val_loss: 0.6466 - val_accuracy: 0.7924\n",
            "Epoch 96/300\n",
            "7/7 [==============================] - 2s 252ms/step - loss: 0.4178 - accuracy: 0.8649 - val_loss: 0.6464 - val_accuracy: 0.7910\n",
            "Epoch 97/300\n",
            "7/7 [==============================] - 2s 257ms/step - loss: 0.4250 - accuracy: 0.8606 - val_loss: 0.6485 - val_accuracy: 0.7895\n",
            "Epoch 98/300\n",
            "7/7 [==============================] - 2s 250ms/step - loss: 0.4374 - accuracy: 0.8588 - val_loss: 0.6441 - val_accuracy: 0.7924\n",
            "Epoch 99/300\n",
            "7/7 [==============================] - 2s 252ms/step - loss: 0.4223 - accuracy: 0.8636 - val_loss: 0.6419 - val_accuracy: 0.7931\n",
            "Epoch 100/300\n",
            "7/7 [==============================] - 2s 254ms/step - loss: 0.4229 - accuracy: 0.8666 - val_loss: 0.6437 - val_accuracy: 0.7931\n",
            "Epoch 101/300\n",
            "7/7 [==============================] - 2s 254ms/step - loss: 0.4231 - accuracy: 0.8675 - val_loss: 0.6414 - val_accuracy: 0.7946\n",
            "Epoch 102/300\n",
            "7/7 [==============================] - 2s 254ms/step - loss: 0.4292 - accuracy: 0.8570 - val_loss: 0.6390 - val_accuracy: 0.7981\n",
            "Epoch 103/300\n",
            "7/7 [==============================] - 2s 254ms/step - loss: 0.4196 - accuracy: 0.8657 - val_loss: 0.6386 - val_accuracy: 0.7960\n",
            "Epoch 104/300\n",
            "7/7 [==============================] - 2s 252ms/step - loss: 0.4201 - accuracy: 0.8660 - val_loss: 0.6414 - val_accuracy: 0.7946\n",
            "Epoch 105/300\n",
            "7/7 [==============================] - 2s 252ms/step - loss: 0.4151 - accuracy: 0.8601 - val_loss: 0.6378 - val_accuracy: 0.7953\n",
            "Epoch 106/300\n",
            "7/7 [==============================] - 2s 255ms/step - loss: 0.4191 - accuracy: 0.8641 - val_loss: 0.6396 - val_accuracy: 0.7924\n",
            "Epoch 107/300\n",
            "7/7 [==============================] - 2s 258ms/step - loss: 0.4059 - accuracy: 0.8700 - val_loss: 0.6336 - val_accuracy: 0.8003\n",
            "Epoch 108/300\n",
            "7/7 [==============================] - 2s 250ms/step - loss: 0.4044 - accuracy: 0.8681 - val_loss: 0.6358 - val_accuracy: 0.7981\n",
            "Epoch 109/300\n",
            "7/7 [==============================] - 2s 251ms/step - loss: 0.4017 - accuracy: 0.8668 - val_loss: 0.6340 - val_accuracy: 0.7967\n",
            "Epoch 110/300\n",
            "7/7 [==============================] - 2s 251ms/step - loss: 0.4001 - accuracy: 0.8675 - val_loss: 0.6326 - val_accuracy: 0.7989\n",
            "Epoch 111/300\n",
            "7/7 [==============================] - 2s 255ms/step - loss: 0.3859 - accuracy: 0.8814 - val_loss: 0.6317 - val_accuracy: 0.8039\n",
            "Epoch 112/300\n",
            "7/7 [==============================] - 2s 251ms/step - loss: 0.4041 - accuracy: 0.8687 - val_loss: 0.6324 - val_accuracy: 0.8024\n",
            "Epoch 113/300\n",
            "7/7 [==============================] - 2s 253ms/step - loss: 0.3737 - accuracy: 0.8857 - val_loss: 0.6265 - val_accuracy: 0.8017\n",
            "Epoch 114/300\n",
            "7/7 [==============================] - 2s 252ms/step - loss: 0.3891 - accuracy: 0.8761 - val_loss: 0.6317 - val_accuracy: 0.8039\n",
            "Epoch 115/300\n",
            "7/7 [==============================] - 2s 252ms/step - loss: 0.3733 - accuracy: 0.8808 - val_loss: 0.6287 - val_accuracy: 0.8031\n",
            "Epoch 116/300\n",
            "7/7 [==============================] - 2s 250ms/step - loss: 0.3762 - accuracy: 0.8822 - val_loss: 0.6293 - val_accuracy: 0.8060\n",
            "Epoch 117/300\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.3880 - accuracy: 0.8793 - val_loss: 0.6267 - val_accuracy: 0.8031\n",
            "Epoch 118/300\n",
            "7/7 [==============================] - 2s 252ms/step - loss: 0.3744 - accuracy: 0.8806 - val_loss: 0.6230 - val_accuracy: 0.8053\n",
            "Epoch 119/300\n",
            "7/7 [==============================] - 2s 251ms/step - loss: 0.3886 - accuracy: 0.8748 - val_loss: 0.6274 - val_accuracy: 0.8039\n",
            "Epoch 120/300\n",
            "7/7 [==============================] - 2s 251ms/step - loss: 0.3789 - accuracy: 0.8787 - val_loss: 0.6237 - val_accuracy: 0.8031\n",
            "Epoch 121/300\n",
            "7/7 [==============================] - 2s 257ms/step - loss: 0.3713 - accuracy: 0.8850 - val_loss: 0.6225 - val_accuracy: 0.8067\n",
            "Epoch 122/300\n",
            "7/7 [==============================] - 2s 253ms/step - loss: 0.3737 - accuracy: 0.8774 - val_loss: 0.6263 - val_accuracy: 0.8067\n",
            "Epoch 123/300\n",
            "7/7 [==============================] - 2s 253ms/step - loss: 0.3765 - accuracy: 0.8796 - val_loss: 0.6238 - val_accuracy: 0.8053\n",
            "Epoch 124/300\n",
            "7/7 [==============================] - 2s 259ms/step - loss: 0.3704 - accuracy: 0.8819 - val_loss: 0.6185 - val_accuracy: 0.8096\n",
            "Epoch 125/300\n",
            "7/7 [==============================] - 2s 255ms/step - loss: 0.3605 - accuracy: 0.8839 - val_loss: 0.6208 - val_accuracy: 0.8103\n",
            "Epoch 126/300\n",
            "7/7 [==============================] - 2s 252ms/step - loss: 0.3602 - accuracy: 0.8878 - val_loss: 0.6251 - val_accuracy: 0.8096\n",
            "Epoch 127/300\n",
            "7/7 [==============================] - 2s 257ms/step - loss: 0.3474 - accuracy: 0.8887 - val_loss: 0.6180 - val_accuracy: 0.8103\n",
            "Epoch 128/300\n",
            "7/7 [==============================] - 2s 254ms/step - loss: 0.3579 - accuracy: 0.8907 - val_loss: 0.6199 - val_accuracy: 0.8096\n",
            "Epoch 129/300\n",
            "7/7 [==============================] - 2s 252ms/step - loss: 0.3676 - accuracy: 0.8860 - val_loss: 0.6195 - val_accuracy: 0.8067\n",
            "Epoch 130/300\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.3509 - accuracy: 0.8878 - val_loss: 0.6164 - val_accuracy: 0.8074\n",
            "Epoch 131/300\n",
            "7/7 [==============================] - 2s 251ms/step - loss: 0.3613 - accuracy: 0.8853 - val_loss: 0.6165 - val_accuracy: 0.8096\n",
            "Epoch 132/300\n",
            "7/7 [==============================] - 2s 252ms/step - loss: 0.3460 - accuracy: 0.8895 - val_loss: 0.6169 - val_accuracy: 0.8096\n",
            "Epoch 133/300\n",
            "7/7 [==============================] - 2s 260ms/step - loss: 0.3489 - accuracy: 0.8918 - val_loss: 0.6171 - val_accuracy: 0.8117\n",
            "Epoch 134/300\n",
            "7/7 [==============================] - 2s 252ms/step - loss: 0.3574 - accuracy: 0.8873 - val_loss: 0.6174 - val_accuracy: 0.8117\n",
            "Epoch 135/300\n",
            "7/7 [==============================] - 2s 251ms/step - loss: 0.3367 - accuracy: 0.8933 - val_loss: 0.6125 - val_accuracy: 0.8110\n",
            "Epoch 136/300\n",
            "7/7 [==============================] - 2s 255ms/step - loss: 0.3331 - accuracy: 0.8987 - val_loss: 0.6178 - val_accuracy: 0.8139\n",
            "Epoch 137/300\n",
            "7/7 [==============================] - 2s 255ms/step - loss: 0.3338 - accuracy: 0.8905 - val_loss: 0.6161 - val_accuracy: 0.8146\n",
            "Epoch 138/300\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.3270 - accuracy: 0.8942 - val_loss: 0.6118 - val_accuracy: 0.8139\n",
            "Epoch 139/300\n",
            "7/7 [==============================] - 2s 256ms/step - loss: 0.3267 - accuracy: 0.8959 - val_loss: 0.6155 - val_accuracy: 0.8082\n",
            "Epoch 140/300\n",
            "7/7 [==============================] - 2s 256ms/step - loss: 0.3488 - accuracy: 0.8863 - val_loss: 0.6144 - val_accuracy: 0.8103\n",
            "Epoch 141/300\n",
            "7/7 [==============================] - 2s 268ms/step - loss: 0.3281 - accuracy: 0.8988 - val_loss: 0.6125 - val_accuracy: 0.8125\n",
            "Epoch 142/300\n",
            "7/7 [==============================] - 2s 255ms/step - loss: 0.3342 - accuracy: 0.8954 - val_loss: 0.6138 - val_accuracy: 0.8110\n",
            "Epoch 143/300\n",
            "7/7 [==============================] - 2s 253ms/step - loss: 0.3291 - accuracy: 0.8927 - val_loss: 0.6097 - val_accuracy: 0.8132\n",
            "Epoch 144/300\n",
            "7/7 [==============================] - 2s 256ms/step - loss: 0.3249 - accuracy: 0.8957 - val_loss: 0.6124 - val_accuracy: 0.8160\n",
            "Epoch 145/300\n",
            "7/7 [==============================] - 2s 252ms/step - loss: 0.3346 - accuracy: 0.8956 - val_loss: 0.6149 - val_accuracy: 0.8139\n",
            "Epoch 146/300\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.3253 - accuracy: 0.8999 - val_loss: 0.6090 - val_accuracy: 0.8139\n",
            "Epoch 147/300\n",
            "7/7 [==============================] - 2s 256ms/step - loss: 0.3353 - accuracy: 0.8945 - val_loss: 0.6077 - val_accuracy: 0.8139\n",
            "Epoch 148/300\n",
            "7/7 [==============================] - 2s 254ms/step - loss: 0.3280 - accuracy: 0.8932 - val_loss: 0.6104 - val_accuracy: 0.8160\n",
            "Epoch 149/300\n",
            "7/7 [==============================] - 2s 254ms/step - loss: 0.3248 - accuracy: 0.8971 - val_loss: 0.6105 - val_accuracy: 0.8160\n",
            "Epoch 150/300\n",
            "7/7 [==============================] - 2s 254ms/step - loss: 0.3363 - accuracy: 0.8956 - val_loss: 0.6122 - val_accuracy: 0.8175\n",
            "Epoch 151/300\n",
            "7/7 [==============================] - 2s 255ms/step - loss: 0.3147 - accuracy: 0.9012 - val_loss: 0.6100 - val_accuracy: 0.8182\n",
            "Epoch 152/300\n",
            "7/7 [==============================] - 2s 260ms/step - loss: 0.3177 - accuracy: 0.9008 - val_loss: 0.6111 - val_accuracy: 0.8182\n",
            "Epoch 153/300\n",
            "7/7 [==============================] - 2s 253ms/step - loss: 0.3244 - accuracy: 0.8956 - val_loss: 0.6108 - val_accuracy: 0.8182\n",
            "Epoch 154/300\n",
            "7/7 [==============================] - 2s 253ms/step - loss: 0.3230 - accuracy: 0.8988 - val_loss: 0.6060 - val_accuracy: 0.8153\n",
            "Epoch 155/300\n",
            "7/7 [==============================] - 2s 255ms/step - loss: 0.3124 - accuracy: 0.9021 - val_loss: 0.6089 - val_accuracy: 0.8182\n",
            "Epoch 156/300\n",
            "7/7 [==============================] - 2s 254ms/step - loss: 0.3168 - accuracy: 0.8949 - val_loss: 0.6120 - val_accuracy: 0.8182\n",
            "Epoch 157/300\n",
            "7/7 [==============================] - 2s 263ms/step - loss: 0.3027 - accuracy: 0.9022 - val_loss: 0.6098 - val_accuracy: 0.8160\n",
            "Epoch 158/300\n",
            "7/7 [==============================] - 2s 258ms/step - loss: 0.3175 - accuracy: 0.9013 - val_loss: 0.6111 - val_accuracy: 0.8146\n",
            "Epoch 159/300\n",
            "7/7 [==============================] - 2s 251ms/step - loss: 0.3091 - accuracy: 0.9055 - val_loss: 0.6089 - val_accuracy: 0.8175\n",
            "Epoch 160/300\n",
            "7/7 [==============================] - 2s 254ms/step - loss: 0.3081 - accuracy: 0.8998 - val_loss: 0.6112 - val_accuracy: 0.8146\n",
            "Epoch 161/300\n",
            "7/7 [==============================] - 2s 255ms/step - loss: 0.3031 - accuracy: 0.9062 - val_loss: 0.6091 - val_accuracy: 0.8160\n",
            "Epoch 162/300\n",
            "7/7 [==============================] - 2s 257ms/step - loss: 0.3147 - accuracy: 0.8971 - val_loss: 0.6072 - val_accuracy: 0.8139\n",
            "Epoch 163/300\n",
            "7/7 [==============================] - 2s 252ms/step - loss: 0.3075 - accuracy: 0.9037 - val_loss: 0.6123 - val_accuracy: 0.8168\n",
            "Epoch 164/300\n",
            "7/7 [==============================] - 2s 258ms/step - loss: 0.2997 - accuracy: 0.9081 - val_loss: 0.6116 - val_accuracy: 0.8210\n",
            "Epoch 165/300\n",
            "7/7 [==============================] - 2s 258ms/step - loss: 0.3048 - accuracy: 0.9047 - val_loss: 0.6047 - val_accuracy: 0.8203\n",
            "Epoch 166/300\n",
            "7/7 [==============================] - 2s 256ms/step - loss: 0.3020 - accuracy: 0.9032 - val_loss: 0.6079 - val_accuracy: 0.8182\n",
            "Epoch 167/300\n",
            "7/7 [==============================] - 2s 253ms/step - loss: 0.3039 - accuracy: 0.9018 - val_loss: 0.6055 - val_accuracy: 0.8210\n",
            "Epoch 168/300\n",
            "7/7 [==============================] - 2s 260ms/step - loss: 0.2905 - accuracy: 0.9063 - val_loss: 0.6083 - val_accuracy: 0.8153\n",
            "Epoch 169/300\n",
            "7/7 [==============================] - 2s 257ms/step - loss: 0.2934 - accuracy: 0.9085 - val_loss: 0.6087 - val_accuracy: 0.8196\n",
            "Epoch 170/300\n",
            "7/7 [==============================] - 2s 252ms/step - loss: 0.3090 - accuracy: 0.9016 - val_loss: 0.6047 - val_accuracy: 0.8182\n",
            "Epoch 171/300\n",
            "7/7 [==============================] - 2s 258ms/step - loss: 0.2981 - accuracy: 0.9091 - val_loss: 0.6083 - val_accuracy: 0.8182\n",
            "Epoch 172/300\n",
            "7/7 [==============================] - 2s 259ms/step - loss: 0.2930 - accuracy: 0.9072 - val_loss: 0.6105 - val_accuracy: 0.8203\n",
            "Epoch 173/300\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.2902 - accuracy: 0.9116 - val_loss: 0.6090 - val_accuracy: 0.8232\n",
            "Epoch 174/300\n",
            "7/7 [==============================] - 2s 256ms/step - loss: 0.2836 - accuracy: 0.9110 - val_loss: 0.6063 - val_accuracy: 0.8232\n",
            "Epoch 175/300\n",
            "7/7 [==============================] - 2s 256ms/step - loss: 0.2712 - accuracy: 0.9168 - val_loss: 0.6092 - val_accuracy: 0.8196\n",
            "Epoch 176/300\n",
            "7/7 [==============================] - 2s 257ms/step - loss: 0.2925 - accuracy: 0.9055 - val_loss: 0.6091 - val_accuracy: 0.8253\n",
            "Epoch 177/300\n",
            "7/7 [==============================] - 2s 255ms/step - loss: 0.2842 - accuracy: 0.9105 - val_loss: 0.6060 - val_accuracy: 0.8225\n",
            "Epoch 178/300\n",
            "7/7 [==============================] - 2s 252ms/step - loss: 0.2640 - accuracy: 0.9167 - val_loss: 0.6079 - val_accuracy: 0.8261\n",
            "Epoch 179/300\n",
            "7/7 [==============================] - 2s 258ms/step - loss: 0.2847 - accuracy: 0.9143 - val_loss: 0.6066 - val_accuracy: 0.8218\n",
            "Epoch 180/300\n",
            "7/7 [==============================] - 2s 255ms/step - loss: 0.2868 - accuracy: 0.9083 - val_loss: 0.6053 - val_accuracy: 0.8210\n",
            "Epoch 181/300\n",
            "7/7 [==============================] - 2s 255ms/step - loss: 0.2712 - accuracy: 0.9179 - val_loss: 0.6047 - val_accuracy: 0.8232\n",
            "Epoch 182/300\n",
            "7/7 [==============================] - 2s 254ms/step - loss: 0.2792 - accuracy: 0.9132 - val_loss: 0.6094 - val_accuracy: 0.8239\n",
            "Epoch 183/300\n",
            "7/7 [==============================] - 2s 256ms/step - loss: 0.2703 - accuracy: 0.9185 - val_loss: 0.6062 - val_accuracy: 0.8261\n",
            "Epoch 184/300\n",
            "7/7 [==============================] - 2s 264ms/step - loss: 0.2796 - accuracy: 0.9130 - val_loss: 0.6085 - val_accuracy: 0.8253\n",
            "Epoch 185/300\n",
            "7/7 [==============================] - 2s 253ms/step - loss: 0.2729 - accuracy: 0.9149 - val_loss: 0.6102 - val_accuracy: 0.8232\n",
            "Epoch 186/300\n",
            "7/7 [==============================] - 2s 254ms/step - loss: 0.2777 - accuracy: 0.9133 - val_loss: 0.6026 - val_accuracy: 0.8239\n",
            "Epoch 187/300\n",
            "7/7 [==============================] - 2s 254ms/step - loss: 0.2872 - accuracy: 0.9088 - val_loss: 0.6085 - val_accuracy: 0.8246\n",
            "Epoch 188/300\n",
            "7/7 [==============================] - 2s 255ms/step - loss: 0.2774 - accuracy: 0.9130 - val_loss: 0.6041 - val_accuracy: 0.8253\n",
            "Epoch 189/300\n",
            "7/7 [==============================] - 2s 271ms/step - loss: 0.2647 - accuracy: 0.9122 - val_loss: 0.6055 - val_accuracy: 0.8225\n",
            "Epoch 190/300\n",
            "7/7 [==============================] - 2s 256ms/step - loss: 0.2710 - accuracy: 0.9181 - val_loss: 0.6092 - val_accuracy: 0.8239\n",
            "Epoch 191/300\n",
            "7/7 [==============================] - 2s 256ms/step - loss: 0.2684 - accuracy: 0.9128 - val_loss: 0.6053 - val_accuracy: 0.8261\n",
            "Epoch 192/300\n",
            "7/7 [==============================] - 2s 256ms/step - loss: 0.2705 - accuracy: 0.9126 - val_loss: 0.6056 - val_accuracy: 0.8282\n",
            "Epoch 193/300\n",
            "7/7 [==============================] - 2s 257ms/step - loss: 0.2718 - accuracy: 0.9178 - val_loss: 0.6088 - val_accuracy: 0.8239\n",
            "Epoch 194/300\n",
            "7/7 [==============================] - 2s 255ms/step - loss: 0.2737 - accuracy: 0.9133 - val_loss: 0.6103 - val_accuracy: 0.8239\n",
            "Epoch 195/300\n",
            "7/7 [==============================] - 2s 255ms/step - loss: 0.2771 - accuracy: 0.9160 - val_loss: 0.6066 - val_accuracy: 0.8261\n",
            "Epoch 196/300\n",
            "7/7 [==============================] - 2s 253ms/step - loss: 0.2603 - accuracy: 0.9195 - val_loss: 0.6065 - val_accuracy: 0.8268\n",
            "Epoch 197/300\n",
            "7/7 [==============================] - 2s 259ms/step - loss: 0.2660 - accuracy: 0.9143 - val_loss: 0.6085 - val_accuracy: 0.8268\n",
            "Epoch 198/300\n",
            "7/7 [==============================] - 2s 256ms/step - loss: 0.2694 - accuracy: 0.9141 - val_loss: 0.6066 - val_accuracy: 0.8289\n",
            "Epoch 199/300\n",
            "7/7 [==============================] - 2s 257ms/step - loss: 0.2606 - accuracy: 0.9187 - val_loss: 0.6072 - val_accuracy: 0.8304\n",
            "Epoch 200/300\n",
            "7/7 [==============================] - 2s 258ms/step - loss: 0.2621 - accuracy: 0.9179 - val_loss: 0.6072 - val_accuracy: 0.8268\n",
            "Epoch 201/300\n",
            "7/7 [==============================] - 2s 257ms/step - loss: 0.2580 - accuracy: 0.9204 - val_loss: 0.6108 - val_accuracy: 0.8261\n",
            "Epoch 202/300\n",
            "7/7 [==============================] - 2s 260ms/step - loss: 0.2498 - accuracy: 0.9215 - val_loss: 0.6153 - val_accuracy: 0.8253\n",
            "Epoch 203/300\n",
            "7/7 [==============================] - 2s 253ms/step - loss: 0.2562 - accuracy: 0.9237 - val_loss: 0.6062 - val_accuracy: 0.8275\n",
            "Epoch 204/300\n",
            "7/7 [==============================] - 2s 259ms/step - loss: 0.2597 - accuracy: 0.9166 - val_loss: 0.6088 - val_accuracy: 0.8239\n",
            "Epoch 205/300\n",
            "7/7 [==============================] - 2s 254ms/step - loss: 0.2514 - accuracy: 0.9229 - val_loss: 0.6163 - val_accuracy: 0.8268\n",
            "Epoch 206/300\n",
            "7/7 [==============================] - 2s 257ms/step - loss: 0.2587 - accuracy: 0.9153 - val_loss: 0.6108 - val_accuracy: 0.8311\n",
            "Epoch 207/300\n",
            "7/7 [==============================] - 2s 256ms/step - loss: 0.2468 - accuracy: 0.9222 - val_loss: 0.6107 - val_accuracy: 0.8325\n",
            "Epoch 208/300\n",
            "7/7 [==============================] - 2s 257ms/step - loss: 0.2466 - accuracy: 0.9239 - val_loss: 0.6138 - val_accuracy: 0.8296\n",
            "Epoch 209/300\n",
            "7/7 [==============================] - 2s 255ms/step - loss: 0.2408 - accuracy: 0.9305 - val_loss: 0.6191 - val_accuracy: 0.8239\n",
            "Epoch 210/300\n",
            "7/7 [==============================] - 2s 254ms/step - loss: 0.2473 - accuracy: 0.9236 - val_loss: 0.6198 - val_accuracy: 0.8261\n",
            "Epoch 211/300\n",
            "7/7 [==============================] - 2s 257ms/step - loss: 0.2400 - accuracy: 0.9289 - val_loss: 0.6144 - val_accuracy: 0.8282\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.6026 - accuracy: 0.8239\n",
            "val_accuracy= [0.6025691032409668, 0.8239083886146545]\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 0.2603 - accuracy: 0.9189\n",
            "train accuracy= [0.2602928578853607, 0.9189438223838806]\n",
            "unlabeled remaining= 2591  labels added= 614\n",
            "labeled at start of iteration: 3  is  3687 and unlabeled is 2591\n",
            "Epoch 1/300\n",
            "8/8 [==============================] - 3s 277ms/step - loss: 2.2186 - accuracy: 0.2172 - val_loss: 1.9343 - val_accuracy: 0.3681\n",
            "Epoch 2/300\n",
            "8/8 [==============================] - 2s 254ms/step - loss: 1.9183 - accuracy: 0.3684 - val_loss: 1.7453 - val_accuracy: 0.4320\n",
            "Epoch 3/300\n",
            "8/8 [==============================] - 2s 254ms/step - loss: 1.7468 - accuracy: 0.4247 - val_loss: 1.6254 - val_accuracy: 0.4630\n",
            "Epoch 4/300\n",
            "8/8 [==============================] - 2s 256ms/step - loss: 1.6167 - accuracy: 0.4725 - val_loss: 1.5380 - val_accuracy: 0.5066\n",
            "Epoch 5/300\n",
            "8/8 [==============================] - 2s 255ms/step - loss: 1.4962 - accuracy: 0.5077 - val_loss: 1.4715 - val_accuracy: 0.5395\n",
            "Epoch 6/300\n",
            "8/8 [==============================] - 2s 256ms/step - loss: 1.4569 - accuracy: 0.5350 - val_loss: 1.4124 - val_accuracy: 0.5547\n",
            "Epoch 7/300\n",
            "8/8 [==============================] - 2s 256ms/step - loss: 1.3959 - accuracy: 0.5501 - val_loss: 1.3653 - val_accuracy: 0.5655\n",
            "Epoch 8/300\n",
            "8/8 [==============================] - 2s 256ms/step - loss: 1.3595 - accuracy: 0.5598 - val_loss: 1.3203 - val_accuracy: 0.5731\n",
            "Epoch 9/300\n",
            "8/8 [==============================] - 2s 253ms/step - loss: 1.3069 - accuracy: 0.5838 - val_loss: 1.2829 - val_accuracy: 0.6034\n",
            "Epoch 10/300\n",
            "8/8 [==============================] - 2s 255ms/step - loss: 1.2694 - accuracy: 0.5958 - val_loss: 1.2463 - val_accuracy: 0.6059\n",
            "Epoch 11/300\n",
            "8/8 [==============================] - 2s 255ms/step - loss: 1.2258 - accuracy: 0.6086 - val_loss: 1.2131 - val_accuracy: 0.6256\n",
            "Epoch 12/300\n",
            "8/8 [==============================] - 2s 251ms/step - loss: 1.2116 - accuracy: 0.6159 - val_loss: 1.1832 - val_accuracy: 0.6357\n",
            "Epoch 13/300\n",
            "8/8 [==============================] - 2s 256ms/step - loss: 1.1442 - accuracy: 0.6343 - val_loss: 1.1527 - val_accuracy: 0.6464\n",
            "Epoch 14/300\n",
            "8/8 [==============================] - 2s 253ms/step - loss: 1.1285 - accuracy: 0.6401 - val_loss: 1.1259 - val_accuracy: 0.6559\n",
            "Epoch 15/300\n",
            "8/8 [==============================] - 2s 251ms/step - loss: 1.0965 - accuracy: 0.6577 - val_loss: 1.0991 - val_accuracy: 0.6629\n",
            "Epoch 16/300\n",
            "8/8 [==============================] - 2s 255ms/step - loss: 1.0562 - accuracy: 0.6692 - val_loss: 1.0774 - val_accuracy: 0.6762\n",
            "Epoch 17/300\n",
            "8/8 [==============================] - 2s 254ms/step - loss: 1.0434 - accuracy: 0.6786 - val_loss: 1.0532 - val_accuracy: 0.6825\n",
            "Epoch 18/300\n",
            "8/8 [==============================] - 2s 258ms/step - loss: 1.0221 - accuracy: 0.6810 - val_loss: 1.0318 - val_accuracy: 0.6882\n",
            "Epoch 19/300\n",
            "8/8 [==============================] - 2s 254ms/step - loss: 0.9971 - accuracy: 0.6955 - val_loss: 1.0129 - val_accuracy: 0.6863\n",
            "Epoch 20/300\n",
            "8/8 [==============================] - 2s 256ms/step - loss: 0.9783 - accuracy: 0.7027 - val_loss: 0.9887 - val_accuracy: 0.6907\n",
            "Epoch 21/300\n",
            "8/8 [==============================] - 2s 253ms/step - loss: 0.9413 - accuracy: 0.7151 - val_loss: 0.9795 - val_accuracy: 0.6951\n",
            "Epoch 22/300\n",
            "8/8 [==============================] - 2s 256ms/step - loss: 0.9106 - accuracy: 0.7171 - val_loss: 0.9542 - val_accuracy: 0.7002\n",
            "Epoch 23/300\n",
            "8/8 [==============================] - 2s 253ms/step - loss: 0.8866 - accuracy: 0.7244 - val_loss: 0.9449 - val_accuracy: 0.7059\n",
            "Epoch 24/300\n",
            "8/8 [==============================] - 2s 251ms/step - loss: 0.8911 - accuracy: 0.7284 - val_loss: 0.9219 - val_accuracy: 0.7071\n",
            "Epoch 25/300\n",
            "8/8 [==============================] - 2s 258ms/step - loss: 0.8568 - accuracy: 0.7337 - val_loss: 0.9099 - val_accuracy: 0.7122\n",
            "Epoch 26/300\n",
            "8/8 [==============================] - 2s 257ms/step - loss: 0.8441 - accuracy: 0.7363 - val_loss: 0.8946 - val_accuracy: 0.7128\n",
            "Epoch 27/300\n",
            "8/8 [==============================] - 2s 253ms/step - loss: 0.8250 - accuracy: 0.7493 - val_loss: 0.8803 - val_accuracy: 0.7141\n",
            "Epoch 28/300\n",
            "8/8 [==============================] - 2s 256ms/step - loss: 0.8258 - accuracy: 0.7486 - val_loss: 0.8700 - val_accuracy: 0.7192\n",
            "Epoch 29/300\n",
            "8/8 [==============================] - 2s 254ms/step - loss: 0.8158 - accuracy: 0.7473 - val_loss: 0.8585 - val_accuracy: 0.7204\n",
            "Epoch 30/300\n",
            "8/8 [==============================] - 2s 255ms/step - loss: 0.7853 - accuracy: 0.7645 - val_loss: 0.8453 - val_accuracy: 0.7337\n",
            "Epoch 31/300\n",
            "8/8 [==============================] - 2s 254ms/step - loss: 0.7859 - accuracy: 0.7591 - val_loss: 0.8354 - val_accuracy: 0.7287\n",
            "Epoch 32/300\n",
            "8/8 [==============================] - 2s 258ms/step - loss: 0.7509 - accuracy: 0.7713 - val_loss: 0.8259 - val_accuracy: 0.7324\n",
            "Epoch 33/300\n",
            "8/8 [==============================] - 2s 254ms/step - loss: 0.7590 - accuracy: 0.7711 - val_loss: 0.8167 - val_accuracy: 0.7362\n",
            "Epoch 34/300\n",
            "8/8 [==============================] - 2s 254ms/step - loss: 0.7209 - accuracy: 0.7816 - val_loss: 0.8064 - val_accuracy: 0.7388\n",
            "Epoch 35/300\n",
            "8/8 [==============================] - 2s 255ms/step - loss: 0.7148 - accuracy: 0.7869 - val_loss: 0.7942 - val_accuracy: 0.7508\n",
            "Epoch 36/300\n",
            "8/8 [==============================] - 2s 260ms/step - loss: 0.7060 - accuracy: 0.7903 - val_loss: 0.7883 - val_accuracy: 0.7470\n",
            "Epoch 37/300\n",
            "8/8 [==============================] - 2s 258ms/step - loss: 0.7039 - accuracy: 0.7852 - val_loss: 0.7771 - val_accuracy: 0.7540\n",
            "Epoch 38/300\n",
            "8/8 [==============================] - 2s 257ms/step - loss: 0.6929 - accuracy: 0.7880 - val_loss: 0.7685 - val_accuracy: 0.7615\n",
            "Epoch 39/300\n",
            "8/8 [==============================] - 2s 254ms/step - loss: 0.6992 - accuracy: 0.7857 - val_loss: 0.7631 - val_accuracy: 0.7559\n",
            "Epoch 40/300\n",
            "8/8 [==============================] - 2s 254ms/step - loss: 0.6672 - accuracy: 0.7962 - val_loss: 0.7532 - val_accuracy: 0.7698\n",
            "Epoch 41/300\n",
            "8/8 [==============================] - 2s 256ms/step - loss: 0.6802 - accuracy: 0.7931 - val_loss: 0.7486 - val_accuracy: 0.7679\n",
            "Epoch 42/300\n",
            "8/8 [==============================] - 2s 257ms/step - loss: 0.6555 - accuracy: 0.8042 - val_loss: 0.7427 - val_accuracy: 0.7742\n",
            "Epoch 43/300\n",
            "8/8 [==============================] - 2s 252ms/step - loss: 0.6605 - accuracy: 0.8019 - val_loss: 0.7314 - val_accuracy: 0.7755\n",
            "Epoch 44/300\n",
            "8/8 [==============================] - 2s 257ms/step - loss: 0.6196 - accuracy: 0.8154 - val_loss: 0.7316 - val_accuracy: 0.7736\n",
            "Epoch 45/300\n",
            "8/8 [==============================] - 2s 259ms/step - loss: 0.6306 - accuracy: 0.8136 - val_loss: 0.7219 - val_accuracy: 0.7843\n",
            "Epoch 46/300\n",
            "8/8 [==============================] - 2s 254ms/step - loss: 0.6285 - accuracy: 0.8089 - val_loss: 0.7153 - val_accuracy: 0.7837\n",
            "Epoch 47/300\n",
            "8/8 [==============================] - 2s 256ms/step - loss: 0.6148 - accuracy: 0.8126 - val_loss: 0.7072 - val_accuracy: 0.7849\n",
            "Epoch 48/300\n",
            "8/8 [==============================] - 2s 253ms/step - loss: 0.5894 - accuracy: 0.8232 - val_loss: 0.7099 - val_accuracy: 0.7799\n",
            "Epoch 49/300\n",
            "8/8 [==============================] - 2s 261ms/step - loss: 0.5915 - accuracy: 0.8179 - val_loss: 0.6964 - val_accuracy: 0.7900\n",
            "Epoch 50/300\n",
            "8/8 [==============================] - 2s 260ms/step - loss: 0.5987 - accuracy: 0.8122 - val_loss: 0.6948 - val_accuracy: 0.7849\n",
            "Epoch 51/300\n",
            "8/8 [==============================] - 2s 255ms/step - loss: 0.5799 - accuracy: 0.8251 - val_loss: 0.6863 - val_accuracy: 0.7900\n",
            "Epoch 52/300\n",
            "8/8 [==============================] - 2s 258ms/step - loss: 0.5860 - accuracy: 0.8240 - val_loss: 0.6868 - val_accuracy: 0.7919\n",
            "Epoch 53/300\n",
            "8/8 [==============================] - 2s 255ms/step - loss: 0.5709 - accuracy: 0.8292 - val_loss: 0.6779 - val_accuracy: 0.7963\n",
            "Epoch 54/300\n",
            "8/8 [==============================] - 2s 255ms/step - loss: 0.5577 - accuracy: 0.8282 - val_loss: 0.6783 - val_accuracy: 0.7944\n",
            "Epoch 55/300\n",
            "8/8 [==============================] - 2s 251ms/step - loss: 0.5432 - accuracy: 0.8371 - val_loss: 0.6706 - val_accuracy: 0.8008\n",
            "Epoch 56/300\n",
            "8/8 [==============================] - 2s 253ms/step - loss: 0.5434 - accuracy: 0.8369 - val_loss: 0.6648 - val_accuracy: 0.7963\n",
            "Epoch 57/300\n",
            "8/8 [==============================] - 2s 254ms/step - loss: 0.5471 - accuracy: 0.8384 - val_loss: 0.6653 - val_accuracy: 0.7963\n",
            "Epoch 58/300\n",
            "8/8 [==============================] - 2s 256ms/step - loss: 0.5464 - accuracy: 0.8299 - val_loss: 0.6567 - val_accuracy: 0.7976\n",
            "Epoch 59/300\n",
            "8/8 [==============================] - 2s 258ms/step - loss: 0.5201 - accuracy: 0.8404 - val_loss: 0.6546 - val_accuracy: 0.8014\n",
            "Epoch 60/300\n",
            "8/8 [==============================] - 2s 256ms/step - loss: 0.5310 - accuracy: 0.8406 - val_loss: 0.6522 - val_accuracy: 0.7982\n",
            "Epoch 61/300\n",
            "8/8 [==============================] - 2s 256ms/step - loss: 0.5157 - accuracy: 0.8405 - val_loss: 0.6477 - val_accuracy: 0.7989\n",
            "Epoch 62/300\n",
            "8/8 [==============================] - 2s 254ms/step - loss: 0.5266 - accuracy: 0.8455 - val_loss: 0.6460 - val_accuracy: 0.7995\n",
            "Epoch 63/300\n",
            "8/8 [==============================] - 2s 256ms/step - loss: 0.5061 - accuracy: 0.8454 - val_loss: 0.6442 - val_accuracy: 0.7989\n",
            "Epoch 64/300\n",
            "8/8 [==============================] - 2s 255ms/step - loss: 0.5082 - accuracy: 0.8381 - val_loss: 0.6365 - val_accuracy: 0.8014\n",
            "Epoch 65/300\n",
            "8/8 [==============================] - 2s 255ms/step - loss: 0.5004 - accuracy: 0.8459 - val_loss: 0.6375 - val_accuracy: 0.8039\n",
            "Epoch 66/300\n",
            "8/8 [==============================] - 2s 256ms/step - loss: 0.5113 - accuracy: 0.8408 - val_loss: 0.6332 - val_accuracy: 0.8033\n",
            "Epoch 67/300\n",
            "8/8 [==============================] - 2s 254ms/step - loss: 0.4974 - accuracy: 0.8385 - val_loss: 0.6316 - val_accuracy: 0.8039\n",
            "Epoch 68/300\n",
            "8/8 [==============================] - 2s 257ms/step - loss: 0.5080 - accuracy: 0.8391 - val_loss: 0.6276 - val_accuracy: 0.8033\n",
            "Epoch 69/300\n",
            "8/8 [==============================] - 2s 255ms/step - loss: 0.4904 - accuracy: 0.8428 - val_loss: 0.6264 - val_accuracy: 0.8020\n",
            "Epoch 70/300\n",
            "8/8 [==============================] - 2s 258ms/step - loss: 0.4865 - accuracy: 0.8487 - val_loss: 0.6235 - val_accuracy: 0.8102\n",
            "Epoch 71/300\n",
            "8/8 [==============================] - 2s 255ms/step - loss: 0.5048 - accuracy: 0.8355 - val_loss: 0.6207 - val_accuracy: 0.8077\n",
            "Epoch 72/300\n",
            "8/8 [==============================] - 2s 253ms/step - loss: 0.4867 - accuracy: 0.8448 - val_loss: 0.6157 - val_accuracy: 0.8096\n",
            "Epoch 73/300\n",
            "8/8 [==============================] - 2s 259ms/step - loss: 0.4952 - accuracy: 0.8418 - val_loss: 0.6149 - val_accuracy: 0.8109\n",
            "Epoch 74/300\n",
            "8/8 [==============================] - 2s 259ms/step - loss: 0.4686 - accuracy: 0.8592 - val_loss: 0.6120 - val_accuracy: 0.8096\n",
            "Epoch 75/300\n",
            "8/8 [==============================] - 2s 260ms/step - loss: 0.4542 - accuracy: 0.8559 - val_loss: 0.6116 - val_accuracy: 0.8102\n",
            "Epoch 76/300\n",
            "8/8 [==============================] - 2s 257ms/step - loss: 0.4590 - accuracy: 0.8554 - val_loss: 0.6080 - val_accuracy: 0.8109\n",
            "Epoch 77/300\n",
            "8/8 [==============================] - 2s 258ms/step - loss: 0.4525 - accuracy: 0.8556 - val_loss: 0.6052 - val_accuracy: 0.8134\n",
            "Epoch 78/300\n",
            "8/8 [==============================] - 2s 258ms/step - loss: 0.4499 - accuracy: 0.8585 - val_loss: 0.6035 - val_accuracy: 0.8121\n",
            "Epoch 79/300\n",
            "8/8 [==============================] - 2s 256ms/step - loss: 0.4363 - accuracy: 0.8641 - val_loss: 0.6026 - val_accuracy: 0.8134\n",
            "Epoch 80/300\n",
            "8/8 [==============================] - 2s 255ms/step - loss: 0.4435 - accuracy: 0.8609 - val_loss: 0.6027 - val_accuracy: 0.8166\n",
            "Epoch 81/300\n",
            "8/8 [==============================] - 2s 254ms/step - loss: 0.4324 - accuracy: 0.8609 - val_loss: 0.5989 - val_accuracy: 0.8153\n",
            "Epoch 82/300\n",
            "8/8 [==============================] - 2s 255ms/step - loss: 0.4361 - accuracy: 0.8571 - val_loss: 0.6013 - val_accuracy: 0.8191\n",
            "Epoch 83/300\n",
            "8/8 [==============================] - 2s 253ms/step - loss: 0.4256 - accuracy: 0.8675 - val_loss: 0.5949 - val_accuracy: 0.8153\n",
            "Epoch 84/300\n",
            "8/8 [==============================] - 2s 253ms/step - loss: 0.4323 - accuracy: 0.8709 - val_loss: 0.5942 - val_accuracy: 0.8185\n",
            "Epoch 85/300\n",
            "8/8 [==============================] - 2s 257ms/step - loss: 0.4355 - accuracy: 0.8626 - val_loss: 0.5935 - val_accuracy: 0.8172\n",
            "Epoch 86/300\n",
            "8/8 [==============================] - 2s 256ms/step - loss: 0.4081 - accuracy: 0.8734 - val_loss: 0.5917 - val_accuracy: 0.8166\n",
            "Epoch 87/300\n",
            "8/8 [==============================] - 2s 256ms/step - loss: 0.4256 - accuracy: 0.8634 - val_loss: 0.5927 - val_accuracy: 0.8197\n",
            "Epoch 88/300\n",
            "8/8 [==============================] - 2s 258ms/step - loss: 0.4153 - accuracy: 0.8705 - val_loss: 0.5884 - val_accuracy: 0.8204\n",
            "Epoch 89/300\n",
            "8/8 [==============================] - 2s 259ms/step - loss: 0.4178 - accuracy: 0.8639 - val_loss: 0.5873 - val_accuracy: 0.8229\n",
            "Epoch 90/300\n",
            "8/8 [==============================] - 2s 254ms/step - loss: 0.4097 - accuracy: 0.8733 - val_loss: 0.5858 - val_accuracy: 0.8223\n",
            "Epoch 91/300\n",
            "8/8 [==============================] - 2s 256ms/step - loss: 0.4137 - accuracy: 0.8726 - val_loss: 0.5848 - val_accuracy: 0.8210\n",
            "Epoch 92/300\n",
            "8/8 [==============================] - 2s 255ms/step - loss: 0.4069 - accuracy: 0.8676 - val_loss: 0.5864 - val_accuracy: 0.8229\n",
            "Epoch 93/300\n",
            "8/8 [==============================] - 2s 259ms/step - loss: 0.4008 - accuracy: 0.8722 - val_loss: 0.5874 - val_accuracy: 0.8197\n",
            "Epoch 94/300\n",
            "8/8 [==============================] - 2s 257ms/step - loss: 0.3941 - accuracy: 0.8754 - val_loss: 0.5835 - val_accuracy: 0.8210\n",
            "Epoch 95/300\n",
            "8/8 [==============================] - 2s 255ms/step - loss: 0.3894 - accuracy: 0.8765 - val_loss: 0.5785 - val_accuracy: 0.8229\n",
            "Epoch 96/300\n",
            "8/8 [==============================] - 2s 255ms/step - loss: 0.3845 - accuracy: 0.8775 - val_loss: 0.5826 - val_accuracy: 0.8223\n",
            "Epoch 97/300\n",
            "8/8 [==============================] - 2s 256ms/step - loss: 0.3846 - accuracy: 0.8726 - val_loss: 0.5803 - val_accuracy: 0.8229\n",
            "Epoch 98/300\n",
            "8/8 [==============================] - 2s 256ms/step - loss: 0.3781 - accuracy: 0.8780 - val_loss: 0.5772 - val_accuracy: 0.8242\n",
            "Epoch 99/300\n",
            "8/8 [==============================] - 2s 256ms/step - loss: 0.3795 - accuracy: 0.8804 - val_loss: 0.5758 - val_accuracy: 0.8248\n",
            "Epoch 100/300\n",
            "8/8 [==============================] - 2s 256ms/step - loss: 0.3722 - accuracy: 0.8805 - val_loss: 0.5743 - val_accuracy: 0.8223\n",
            "Epoch 101/300\n",
            "8/8 [==============================] - 2s 258ms/step - loss: 0.3628 - accuracy: 0.8801 - val_loss: 0.5789 - val_accuracy: 0.8273\n",
            "Epoch 102/300\n",
            "8/8 [==============================] - 2s 256ms/step - loss: 0.3821 - accuracy: 0.8801 - val_loss: 0.5747 - val_accuracy: 0.8248\n",
            "Epoch 103/300\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 0.3712 - accuracy: 0.8874 - val_loss: 0.5741 - val_accuracy: 0.8216\n",
            "Epoch 104/300\n",
            "8/8 [==============================] - 2s 253ms/step - loss: 0.3750 - accuracy: 0.8822 - val_loss: 0.5774 - val_accuracy: 0.8242\n",
            "Epoch 105/300\n",
            "8/8 [==============================] - 2s 258ms/step - loss: 0.3699 - accuracy: 0.8808 - val_loss: 0.5745 - val_accuracy: 0.8235\n",
            "Epoch 106/300\n",
            "8/8 [==============================] - 2s 258ms/step - loss: 0.3662 - accuracy: 0.8800 - val_loss: 0.5742 - val_accuracy: 0.8280\n",
            "Epoch 107/300\n",
            "8/8 [==============================] - 2s 262ms/step - loss: 0.3653 - accuracy: 0.8836 - val_loss: 0.5706 - val_accuracy: 0.8248\n",
            "Epoch 108/300\n",
            "8/8 [==============================] - 2s 255ms/step - loss: 0.3672 - accuracy: 0.8858 - val_loss: 0.5691 - val_accuracy: 0.8229\n",
            "Epoch 109/300\n",
            "8/8 [==============================] - 2s 257ms/step - loss: 0.3579 - accuracy: 0.8835 - val_loss: 0.5753 - val_accuracy: 0.8242\n",
            "Epoch 110/300\n",
            "8/8 [==============================] - 2s 262ms/step - loss: 0.3536 - accuracy: 0.8873 - val_loss: 0.5666 - val_accuracy: 0.8280\n",
            "Epoch 111/300\n",
            "8/8 [==============================] - 2s 258ms/step - loss: 0.3584 - accuracy: 0.8836 - val_loss: 0.5692 - val_accuracy: 0.8286\n",
            "Epoch 112/300\n",
            "8/8 [==============================] - 2s 255ms/step - loss: 0.3452 - accuracy: 0.8884 - val_loss: 0.5681 - val_accuracy: 0.8267\n",
            "Epoch 113/300\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 0.3359 - accuracy: 0.8917 - val_loss: 0.5696 - val_accuracy: 0.8292\n",
            "Epoch 114/300\n",
            "8/8 [==============================] - 2s 256ms/step - loss: 0.3403 - accuracy: 0.8941 - val_loss: 0.5673 - val_accuracy: 0.8280\n",
            "Epoch 115/300\n",
            "8/8 [==============================] - 2s 255ms/step - loss: 0.3526 - accuracy: 0.8860 - val_loss: 0.5672 - val_accuracy: 0.8292\n",
            "Epoch 116/300\n",
            "8/8 [==============================] - 2s 255ms/step - loss: 0.3455 - accuracy: 0.8897 - val_loss: 0.5700 - val_accuracy: 0.8286\n",
            "Epoch 117/300\n",
            "8/8 [==============================] - 2s 255ms/step - loss: 0.3412 - accuracy: 0.8886 - val_loss: 0.5678 - val_accuracy: 0.8261\n",
            "Epoch 118/300\n",
            "8/8 [==============================] - 2s 253ms/step - loss: 0.3379 - accuracy: 0.8922 - val_loss: 0.5660 - val_accuracy: 0.8292\n",
            "Epoch 119/300\n",
            "8/8 [==============================] - 2s 256ms/step - loss: 0.3403 - accuracy: 0.8920 - val_loss: 0.5699 - val_accuracy: 0.8261\n",
            "Epoch 120/300\n",
            "8/8 [==============================] - 2s 255ms/step - loss: 0.3431 - accuracy: 0.8954 - val_loss: 0.5644 - val_accuracy: 0.8305\n",
            "Epoch 121/300\n",
            "8/8 [==============================] - 2s 257ms/step - loss: 0.3387 - accuracy: 0.8907 - val_loss: 0.5657 - val_accuracy: 0.8261\n",
            "Epoch 122/300\n",
            "8/8 [==============================] - 2s 259ms/step - loss: 0.3294 - accuracy: 0.8977 - val_loss: 0.5661 - val_accuracy: 0.8330\n",
            "Epoch 123/300\n",
            "8/8 [==============================] - 2s 262ms/step - loss: 0.3290 - accuracy: 0.8972 - val_loss: 0.5612 - val_accuracy: 0.8280\n",
            "Epoch 124/300\n",
            "8/8 [==============================] - 2s 256ms/step - loss: 0.3129 - accuracy: 0.9053 - val_loss: 0.5641 - val_accuracy: 0.8280\n",
            "Epoch 125/300\n",
            "8/8 [==============================] - 2s 257ms/step - loss: 0.3327 - accuracy: 0.8948 - val_loss: 0.5646 - val_accuracy: 0.8280\n",
            "Epoch 126/300\n",
            "8/8 [==============================] - 2s 266ms/step - loss: 0.3338 - accuracy: 0.8925 - val_loss: 0.5640 - val_accuracy: 0.8318\n",
            "Epoch 127/300\n",
            "8/8 [==============================] - 2s 255ms/step - loss: 0.3233 - accuracy: 0.8959 - val_loss: 0.5636 - val_accuracy: 0.8286\n",
            "Epoch 128/300\n",
            "8/8 [==============================] - 2s 258ms/step - loss: 0.3231 - accuracy: 0.8964 - val_loss: 0.5651 - val_accuracy: 0.8273\n",
            "Epoch 129/300\n",
            "8/8 [==============================] - 2s 260ms/step - loss: 0.3121 - accuracy: 0.9008 - val_loss: 0.5628 - val_accuracy: 0.8343\n",
            "Epoch 130/300\n",
            "8/8 [==============================] - 2s 257ms/step - loss: 0.3189 - accuracy: 0.8967 - val_loss: 0.5617 - val_accuracy: 0.8318\n",
            "Epoch 131/300\n",
            "8/8 [==============================] - 2s 256ms/step - loss: 0.3332 - accuracy: 0.8897 - val_loss: 0.5652 - val_accuracy: 0.8318\n",
            "Epoch 132/300\n",
            "8/8 [==============================] - 2s 259ms/step - loss: 0.3091 - accuracy: 0.9003 - val_loss: 0.5598 - val_accuracy: 0.8330\n",
            "Epoch 133/300\n",
            "8/8 [==============================] - 2s 259ms/step - loss: 0.3138 - accuracy: 0.9051 - val_loss: 0.5648 - val_accuracy: 0.8324\n",
            "Epoch 134/300\n",
            "8/8 [==============================] - 2s 259ms/step - loss: 0.3016 - accuracy: 0.9056 - val_loss: 0.5622 - val_accuracy: 0.8362\n",
            "Epoch 135/300\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 0.3071 - accuracy: 0.9015 - val_loss: 0.5653 - val_accuracy: 0.8355\n",
            "Epoch 136/300\n",
            "8/8 [==============================] - 2s 256ms/step - loss: 0.3013 - accuracy: 0.9052 - val_loss: 0.5662 - val_accuracy: 0.8311\n",
            "Epoch 137/300\n",
            "8/8 [==============================] - 2s 256ms/step - loss: 0.2988 - accuracy: 0.9002 - val_loss: 0.5586 - val_accuracy: 0.8393\n",
            "Epoch 138/300\n",
            "8/8 [==============================] - 2s 258ms/step - loss: 0.3238 - accuracy: 0.8966 - val_loss: 0.5721 - val_accuracy: 0.8343\n",
            "Epoch 139/300\n",
            "8/8 [==============================] - 2s 258ms/step - loss: 0.3128 - accuracy: 0.9025 - val_loss: 0.5610 - val_accuracy: 0.8368\n",
            "Epoch 140/300\n",
            "8/8 [==============================] - 2s 262ms/step - loss: 0.2981 - accuracy: 0.9063 - val_loss: 0.5609 - val_accuracy: 0.8368\n",
            "Epoch 141/300\n",
            "8/8 [==============================] - 2s 260ms/step - loss: 0.3066 - accuracy: 0.9015 - val_loss: 0.5676 - val_accuracy: 0.8311\n",
            "Epoch 142/300\n",
            "8/8 [==============================] - 2s 258ms/step - loss: 0.3196 - accuracy: 0.8960 - val_loss: 0.5623 - val_accuracy: 0.8400\n",
            "Epoch 143/300\n",
            "8/8 [==============================] - 2s 260ms/step - loss: 0.2909 - accuracy: 0.9088 - val_loss: 0.5665 - val_accuracy: 0.8349\n",
            "Epoch 144/300\n",
            "8/8 [==============================] - 2s 256ms/step - loss: 0.2959 - accuracy: 0.9046 - val_loss: 0.5620 - val_accuracy: 0.8374\n",
            "Epoch 145/300\n",
            "8/8 [==============================] - 2s 259ms/step - loss: 0.2861 - accuracy: 0.9053 - val_loss: 0.5602 - val_accuracy: 0.8349\n",
            "Epoch 146/300\n",
            "8/8 [==============================] - 2s 256ms/step - loss: 0.3016 - accuracy: 0.9062 - val_loss: 0.5649 - val_accuracy: 0.8381\n",
            "Epoch 147/300\n",
            "8/8 [==============================] - 2s 258ms/step - loss: 0.3010 - accuracy: 0.9016 - val_loss: 0.5632 - val_accuracy: 0.8349\n",
            "Epoch 148/300\n",
            "8/8 [==============================] - 2s 257ms/step - loss: 0.2877 - accuracy: 0.9076 - val_loss: 0.5633 - val_accuracy: 0.8368\n",
            "Epoch 149/300\n",
            "8/8 [==============================] - 2s 259ms/step - loss: 0.2996 - accuracy: 0.9039 - val_loss: 0.5657 - val_accuracy: 0.8381\n",
            "Epoch 150/300\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 0.2724 - accuracy: 0.9146 - val_loss: 0.5629 - val_accuracy: 0.8355\n",
            "Epoch 151/300\n",
            "8/8 [==============================] - 2s 257ms/step - loss: 0.2910 - accuracy: 0.9052 - val_loss: 0.5610 - val_accuracy: 0.8393\n",
            "Epoch 152/300\n",
            "8/8 [==============================] - 2s 258ms/step - loss: 0.2976 - accuracy: 0.9071 - val_loss: 0.5668 - val_accuracy: 0.8400\n",
            "Epoch 153/300\n",
            "8/8 [==============================] - 2s 258ms/step - loss: 0.2823 - accuracy: 0.9095 - val_loss: 0.5633 - val_accuracy: 0.8381\n",
            "Epoch 154/300\n",
            "8/8 [==============================] - 2s 256ms/step - loss: 0.2839 - accuracy: 0.9095 - val_loss: 0.5639 - val_accuracy: 0.8381\n",
            "Epoch 155/300\n",
            "8/8 [==============================] - 2s 256ms/step - loss: 0.2758 - accuracy: 0.9166 - val_loss: 0.5681 - val_accuracy: 0.8355\n",
            "Epoch 156/300\n",
            "8/8 [==============================] - 2s 257ms/step - loss: 0.2705 - accuracy: 0.9123 - val_loss: 0.5677 - val_accuracy: 0.8412\n",
            "Epoch 157/300\n",
            "8/8 [==============================] - 2s 258ms/step - loss: 0.2832 - accuracy: 0.9095 - val_loss: 0.5661 - val_accuracy: 0.8393\n",
            "Epoch 158/300\n",
            "8/8 [==============================] - 2s 259ms/step - loss: 0.2808 - accuracy: 0.9144 - val_loss: 0.5663 - val_accuracy: 0.8393\n",
            "Epoch 159/300\n",
            "8/8 [==============================] - 2s 261ms/step - loss: 0.2800 - accuracy: 0.9112 - val_loss: 0.5630 - val_accuracy: 0.8349\n",
            "Epoch 160/300\n",
            "8/8 [==============================] - 2s 257ms/step - loss: 0.2674 - accuracy: 0.9151 - val_loss: 0.5679 - val_accuracy: 0.8355\n",
            "Epoch 161/300\n",
            "8/8 [==============================] - 2s 257ms/step - loss: 0.2798 - accuracy: 0.9095 - val_loss: 0.5690 - val_accuracy: 0.8381\n",
            "Epoch 162/300\n",
            "8/8 [==============================] - 2s 255ms/step - loss: 0.2748 - accuracy: 0.9097 - val_loss: 0.5649 - val_accuracy: 0.8374\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 0.5586 - accuracy: 0.8393\n",
            "val_accuracy= [0.5585678815841675, 0.8393421769142151]\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 0.2890 - accuracy: 0.9113\n",
            "train accuracy= [0.2890380620956421, 0.9113100171089172]\n",
            "unlabeled remaining= 2445  labels added= 146\n",
            "labeled at start of iteration: 4  is  3789 and unlabeled is 2445\n",
            "Epoch 1/300\n",
            "8/8 [==============================] - 3s 290ms/step - loss: 2.2068 - accuracy: 0.1960 - val_loss: 1.9369 - val_accuracy: 0.3822\n",
            "Epoch 2/300\n",
            "8/8 [==============================] - 2s 266ms/step - loss: 1.8981 - accuracy: 0.3983 - val_loss: 1.7374 - val_accuracy: 0.4640\n",
            "Epoch 3/300\n",
            "8/8 [==============================] - 2s 263ms/step - loss: 1.7010 - accuracy: 0.4631 - val_loss: 1.6094 - val_accuracy: 0.4862\n",
            "Epoch 4/300\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 1.5951 - accuracy: 0.4874 - val_loss: 1.5240 - val_accuracy: 0.5138\n",
            "Epoch 5/300\n",
            "8/8 [==============================] - 2s 262ms/step - loss: 1.4950 - accuracy: 0.5203 - val_loss: 1.4582 - val_accuracy: 0.5360\n",
            "Epoch 6/300\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 1.4197 - accuracy: 0.5508 - val_loss: 1.4011 - val_accuracy: 0.5557\n",
            "Epoch 7/300\n",
            "8/8 [==============================] - 2s 269ms/step - loss: 1.3695 - accuracy: 0.5637 - val_loss: 1.3500 - val_accuracy: 0.5729\n",
            "Epoch 8/300\n",
            "8/8 [==============================] - 2s 262ms/step - loss: 1.3231 - accuracy: 0.5727 - val_loss: 1.3116 - val_accuracy: 0.5809\n",
            "Epoch 9/300\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 1.2727 - accuracy: 0.5963 - val_loss: 1.2681 - val_accuracy: 0.5957\n",
            "Epoch 10/300\n",
            "8/8 [==============================] - 2s 263ms/step - loss: 1.2328 - accuracy: 0.6009 - val_loss: 1.2378 - val_accuracy: 0.6031\n",
            "Epoch 11/300\n",
            "8/8 [==============================] - 2s 263ms/step - loss: 1.1956 - accuracy: 0.6265 - val_loss: 1.1998 - val_accuracy: 0.6154\n",
            "Epoch 12/300\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 1.1573 - accuracy: 0.6405 - val_loss: 1.1735 - val_accuracy: 0.6215\n",
            "Epoch 13/300\n",
            "8/8 [==============================] - 2s 265ms/step - loss: 1.1294 - accuracy: 0.6409 - val_loss: 1.1410 - val_accuracy: 0.6388\n",
            "Epoch 14/300\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 1.0867 - accuracy: 0.6679 - val_loss: 1.1161 - val_accuracy: 0.6492\n",
            "Epoch 15/300\n",
            "8/8 [==============================] - 2s 265ms/step - loss: 1.0773 - accuracy: 0.6637 - val_loss: 1.0889 - val_accuracy: 0.6523\n",
            "Epoch 16/300\n",
            "8/8 [==============================] - 2s 266ms/step - loss: 1.0411 - accuracy: 0.6753 - val_loss: 1.0618 - val_accuracy: 0.6615\n",
            "Epoch 17/300\n",
            "8/8 [==============================] - 2s 262ms/step - loss: 1.0131 - accuracy: 0.6831 - val_loss: 1.0395 - val_accuracy: 0.6708\n",
            "Epoch 18/300\n",
            "8/8 [==============================] - 2s 262ms/step - loss: 0.9934 - accuracy: 0.6860 - val_loss: 1.0161 - val_accuracy: 0.6757\n",
            "Epoch 19/300\n",
            "8/8 [==============================] - 2s 263ms/step - loss: 0.9594 - accuracy: 0.7065 - val_loss: 0.9965 - val_accuracy: 0.6868\n",
            "Epoch 20/300\n",
            "8/8 [==============================] - 2s 263ms/step - loss: 0.9441 - accuracy: 0.6998 - val_loss: 0.9743 - val_accuracy: 0.6960\n",
            "Epoch 21/300\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 0.9162 - accuracy: 0.7143 - val_loss: 0.9582 - val_accuracy: 0.6997\n",
            "Epoch 22/300\n",
            "8/8 [==============================] - 2s 265ms/step - loss: 0.8792 - accuracy: 0.7258 - val_loss: 0.9377 - val_accuracy: 0.7046\n",
            "Epoch 23/300\n",
            "8/8 [==============================] - 2s 265ms/step - loss: 0.8836 - accuracy: 0.7194 - val_loss: 0.9207 - val_accuracy: 0.7120\n",
            "Epoch 24/300\n",
            "8/8 [==============================] - 2s 267ms/step - loss: 0.8438 - accuracy: 0.7521 - val_loss: 0.9051 - val_accuracy: 0.7188\n",
            "Epoch 25/300\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 0.8419 - accuracy: 0.7450 - val_loss: 0.8896 - val_accuracy: 0.7255\n",
            "Epoch 26/300\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 0.8348 - accuracy: 0.7438 - val_loss: 0.8741 - val_accuracy: 0.7292\n",
            "Epoch 27/300\n",
            "8/8 [==============================] - 2s 266ms/step - loss: 0.8060 - accuracy: 0.7508 - val_loss: 0.8597 - val_accuracy: 0.7342\n",
            "Epoch 28/300\n",
            "8/8 [==============================] - 2s 271ms/step - loss: 0.7416 - accuracy: 0.7759 - val_loss: 0.8453 - val_accuracy: 0.7372\n",
            "Epoch 29/300\n",
            "8/8 [==============================] - 2s 266ms/step - loss: 0.7615 - accuracy: 0.7617 - val_loss: 0.8347 - val_accuracy: 0.7489\n",
            "Epoch 30/300\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 0.7456 - accuracy: 0.7736 - val_loss: 0.8242 - val_accuracy: 0.7422\n",
            "Epoch 31/300\n",
            "8/8 [==============================] - 2s 265ms/step - loss: 0.7226 - accuracy: 0.7785 - val_loss: 0.8091 - val_accuracy: 0.7551\n",
            "Epoch 32/300\n",
            "8/8 [==============================] - 2s 262ms/step - loss: 0.7323 - accuracy: 0.7803 - val_loss: 0.8001 - val_accuracy: 0.7545\n",
            "Epoch 33/300\n",
            "8/8 [==============================] - 2s 263ms/step - loss: 0.7370 - accuracy: 0.7761 - val_loss: 0.7881 - val_accuracy: 0.7655\n",
            "Epoch 34/300\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 0.6957 - accuracy: 0.7938 - val_loss: 0.7785 - val_accuracy: 0.7649\n",
            "Epoch 35/300\n",
            "8/8 [==============================] - 2s 266ms/step - loss: 0.7034 - accuracy: 0.7911 - val_loss: 0.7683 - val_accuracy: 0.7766\n",
            "Epoch 36/300\n",
            "8/8 [==============================] - 2s 263ms/step - loss: 0.6768 - accuracy: 0.7971 - val_loss: 0.7619 - val_accuracy: 0.7729\n",
            "Epoch 37/300\n",
            "8/8 [==============================] - 2s 262ms/step - loss: 0.6849 - accuracy: 0.7976 - val_loss: 0.7516 - val_accuracy: 0.7797\n",
            "Epoch 38/300\n",
            "8/8 [==============================] - 2s 267ms/step - loss: 0.6539 - accuracy: 0.7983 - val_loss: 0.7423 - val_accuracy: 0.7815\n",
            "Epoch 39/300\n",
            "8/8 [==============================] - 2s 263ms/step - loss: 0.6399 - accuracy: 0.8067 - val_loss: 0.7333 - val_accuracy: 0.7871\n",
            "Epoch 40/300\n",
            "8/8 [==============================] - 2s 268ms/step - loss: 0.6377 - accuracy: 0.8145 - val_loss: 0.7277 - val_accuracy: 0.7809\n",
            "Epoch 41/300\n",
            "8/8 [==============================] - 2s 265ms/step - loss: 0.6200 - accuracy: 0.8120 - val_loss: 0.7182 - val_accuracy: 0.7852\n",
            "Epoch 42/300\n",
            "8/8 [==============================] - 2s 265ms/step - loss: 0.6208 - accuracy: 0.8157 - val_loss: 0.7119 - val_accuracy: 0.7920\n",
            "Epoch 43/300\n",
            "8/8 [==============================] - 2s 266ms/step - loss: 0.6067 - accuracy: 0.8227 - val_loss: 0.7055 - val_accuracy: 0.7865\n",
            "Epoch 44/300\n",
            "8/8 [==============================] - 2s 265ms/step - loss: 0.6070 - accuracy: 0.8212 - val_loss: 0.6985 - val_accuracy: 0.7938\n",
            "Epoch 45/300\n",
            "8/8 [==============================] - 2s 267ms/step - loss: 0.5963 - accuracy: 0.8234 - val_loss: 0.6934 - val_accuracy: 0.7932\n",
            "Epoch 46/300\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 0.5898 - accuracy: 0.8259 - val_loss: 0.6868 - val_accuracy: 0.7957\n",
            "Epoch 47/300\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 0.6049 - accuracy: 0.8212 - val_loss: 0.6831 - val_accuracy: 0.7926\n",
            "Epoch 48/300\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 0.5872 - accuracy: 0.8245 - val_loss: 0.6774 - val_accuracy: 0.8031\n",
            "Epoch 49/300\n",
            "8/8 [==============================] - 2s 265ms/step - loss: 0.5748 - accuracy: 0.8265 - val_loss: 0.6723 - val_accuracy: 0.7994\n",
            "Epoch 50/300\n",
            "8/8 [==============================] - 2s 266ms/step - loss: 0.5655 - accuracy: 0.8340 - val_loss: 0.6685 - val_accuracy: 0.7994\n",
            "Epoch 51/300\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 0.5352 - accuracy: 0.8370 - val_loss: 0.6629 - val_accuracy: 0.8018\n",
            "Epoch 52/300\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 0.5373 - accuracy: 0.8394 - val_loss: 0.6577 - val_accuracy: 0.8062\n",
            "Epoch 53/300\n",
            "8/8 [==============================] - 2s 263ms/step - loss: 0.5479 - accuracy: 0.8355 - val_loss: 0.6538 - val_accuracy: 0.7994\n",
            "Epoch 54/300\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 0.5151 - accuracy: 0.8538 - val_loss: 0.6494 - val_accuracy: 0.8074\n",
            "Epoch 55/300\n",
            "8/8 [==============================] - 2s 267ms/step - loss: 0.5391 - accuracy: 0.8426 - val_loss: 0.6452 - val_accuracy: 0.8062\n",
            "Epoch 56/300\n",
            "8/8 [==============================] - 2s 268ms/step - loss: 0.5094 - accuracy: 0.8516 - val_loss: 0.6408 - val_accuracy: 0.8105\n",
            "Epoch 57/300\n",
            "8/8 [==============================] - 2s 266ms/step - loss: 0.5109 - accuracy: 0.8467 - val_loss: 0.6382 - val_accuracy: 0.8074\n",
            "Epoch 58/300\n",
            "8/8 [==============================] - 2s 265ms/step - loss: 0.5071 - accuracy: 0.8434 - val_loss: 0.6347 - val_accuracy: 0.8086\n",
            "Epoch 59/300\n",
            "8/8 [==============================] - 2s 267ms/step - loss: 0.4975 - accuracy: 0.8524 - val_loss: 0.6323 - val_accuracy: 0.8092\n",
            "Epoch 60/300\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 0.5041 - accuracy: 0.8525 - val_loss: 0.6282 - val_accuracy: 0.8092\n",
            "Epoch 61/300\n",
            "8/8 [==============================] - 2s 270ms/step - loss: 0.4830 - accuracy: 0.8687 - val_loss: 0.6240 - val_accuracy: 0.8098\n",
            "Epoch 62/300\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 0.4823 - accuracy: 0.8539 - val_loss: 0.6221 - val_accuracy: 0.8123\n",
            "Epoch 63/300\n",
            "8/8 [==============================] - 2s 265ms/step - loss: 0.4802 - accuracy: 0.8579 - val_loss: 0.6224 - val_accuracy: 0.8123\n",
            "Epoch 64/300\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 0.4739 - accuracy: 0.8592 - val_loss: 0.6201 - val_accuracy: 0.8098\n",
            "Epoch 65/300\n",
            "8/8 [==============================] - 2s 262ms/step - loss: 0.4577 - accuracy: 0.8644 - val_loss: 0.6167 - val_accuracy: 0.8129\n",
            "Epoch 66/300\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 0.4773 - accuracy: 0.8628 - val_loss: 0.6129 - val_accuracy: 0.8111\n",
            "Epoch 67/300\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 0.4678 - accuracy: 0.8624 - val_loss: 0.6094 - val_accuracy: 0.8160\n",
            "Epoch 68/300\n",
            "8/8 [==============================] - 2s 266ms/step - loss: 0.4678 - accuracy: 0.8607 - val_loss: 0.6091 - val_accuracy: 0.8142\n",
            "Epoch 69/300\n",
            "8/8 [==============================] - 2s 265ms/step - loss: 0.4560 - accuracy: 0.8565 - val_loss: 0.6071 - val_accuracy: 0.8154\n",
            "Epoch 70/300\n",
            "8/8 [==============================] - 2s 270ms/step - loss: 0.4560 - accuracy: 0.8547 - val_loss: 0.6047 - val_accuracy: 0.8148\n",
            "Epoch 71/300\n",
            "8/8 [==============================] - 2s 266ms/step - loss: 0.4536 - accuracy: 0.8636 - val_loss: 0.6038 - val_accuracy: 0.8178\n",
            "Epoch 72/300\n",
            "8/8 [==============================] - 2s 266ms/step - loss: 0.4445 - accuracy: 0.8655 - val_loss: 0.6011 - val_accuracy: 0.8185\n",
            "Epoch 73/300\n",
            "8/8 [==============================] - 2s 266ms/step - loss: 0.4422 - accuracy: 0.8622 - val_loss: 0.6008 - val_accuracy: 0.8191\n",
            "Epoch 74/300\n",
            "8/8 [==============================] - 2s 263ms/step - loss: 0.4487 - accuracy: 0.8577 - val_loss: 0.5985 - val_accuracy: 0.8166\n",
            "Epoch 75/300\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 0.4321 - accuracy: 0.8719 - val_loss: 0.5976 - val_accuracy: 0.8123\n",
            "Epoch 76/300\n",
            "8/8 [==============================] - 2s 263ms/step - loss: 0.4524 - accuracy: 0.8629 - val_loss: 0.5931 - val_accuracy: 0.8209\n",
            "Epoch 77/300\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 0.4312 - accuracy: 0.8626 - val_loss: 0.5922 - val_accuracy: 0.8154\n",
            "Epoch 78/300\n",
            "8/8 [==============================] - 2s 267ms/step - loss: 0.4248 - accuracy: 0.8709 - val_loss: 0.5925 - val_accuracy: 0.8129\n",
            "Epoch 79/300\n",
            "8/8 [==============================] - 2s 269ms/step - loss: 0.4240 - accuracy: 0.8706 - val_loss: 0.5916 - val_accuracy: 0.8154\n",
            "Epoch 80/300\n",
            "8/8 [==============================] - 2s 267ms/step - loss: 0.4321 - accuracy: 0.8636 - val_loss: 0.5889 - val_accuracy: 0.8197\n",
            "Epoch 81/300\n",
            "8/8 [==============================] - 2s 262ms/step - loss: 0.4273 - accuracy: 0.8647 - val_loss: 0.5883 - val_accuracy: 0.8191\n",
            "Epoch 82/300\n",
            "8/8 [==============================] - 2s 270ms/step - loss: 0.4211 - accuracy: 0.8703 - val_loss: 0.5869 - val_accuracy: 0.8185\n",
            "Epoch 83/300\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 0.4202 - accuracy: 0.8668 - val_loss: 0.5860 - val_accuracy: 0.8148\n",
            "Epoch 84/300\n",
            "8/8 [==============================] - 2s 269ms/step - loss: 0.4037 - accuracy: 0.8760 - val_loss: 0.5848 - val_accuracy: 0.8222\n",
            "Epoch 85/300\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 0.4003 - accuracy: 0.8750 - val_loss: 0.5839 - val_accuracy: 0.8160\n",
            "Epoch 86/300\n",
            "8/8 [==============================] - 2s 268ms/step - loss: 0.4008 - accuracy: 0.8751 - val_loss: 0.5829 - val_accuracy: 0.8172\n",
            "Epoch 87/300\n",
            "8/8 [==============================] - 2s 295ms/step - loss: 0.4138 - accuracy: 0.8727 - val_loss: 0.5816 - val_accuracy: 0.8191\n",
            "Epoch 88/300\n",
            "8/8 [==============================] - 2s 269ms/step - loss: 0.3926 - accuracy: 0.8752 - val_loss: 0.5817 - val_accuracy: 0.8172\n",
            "Epoch 89/300\n",
            "8/8 [==============================] - 2s 262ms/step - loss: 0.3919 - accuracy: 0.8823 - val_loss: 0.5797 - val_accuracy: 0.8148\n",
            "Epoch 90/300\n",
            "8/8 [==============================] - 2s 262ms/step - loss: 0.3908 - accuracy: 0.8853 - val_loss: 0.5780 - val_accuracy: 0.8197\n",
            "Epoch 91/300\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 0.3724 - accuracy: 0.8917 - val_loss: 0.5759 - val_accuracy: 0.8203\n",
            "Epoch 92/300\n",
            "8/8 [==============================] - 2s 262ms/step - loss: 0.3847 - accuracy: 0.8816 - val_loss: 0.5759 - val_accuracy: 0.8215\n",
            "Epoch 93/300\n",
            "8/8 [==============================] - 2s 268ms/step - loss: 0.3894 - accuracy: 0.8728 - val_loss: 0.5748 - val_accuracy: 0.8209\n",
            "Epoch 94/300\n",
            "8/8 [==============================] - 2s 265ms/step - loss: 0.3845 - accuracy: 0.8782 - val_loss: 0.5729 - val_accuracy: 0.8172\n",
            "Epoch 95/300\n",
            "8/8 [==============================] - 2s 265ms/step - loss: 0.3817 - accuracy: 0.8837 - val_loss: 0.5767 - val_accuracy: 0.8185\n",
            "Epoch 96/300\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 0.3700 - accuracy: 0.8835 - val_loss: 0.5719 - val_accuracy: 0.8234\n",
            "Epoch 97/300\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 0.3749 - accuracy: 0.8832 - val_loss: 0.5722 - val_accuracy: 0.8191\n",
            "Epoch 98/300\n",
            "8/8 [==============================] - 2s 267ms/step - loss: 0.3656 - accuracy: 0.8904 - val_loss: 0.5707 - val_accuracy: 0.8215\n",
            "Epoch 99/300\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 0.3684 - accuracy: 0.8843 - val_loss: 0.5689 - val_accuracy: 0.8191\n",
            "Epoch 100/300\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 0.3698 - accuracy: 0.8853 - val_loss: 0.5710 - val_accuracy: 0.8191\n",
            "Epoch 101/300\n",
            "8/8 [==============================] - 2s 266ms/step - loss: 0.3717 - accuracy: 0.8916 - val_loss: 0.5683 - val_accuracy: 0.8228\n",
            "Epoch 102/300\n",
            "8/8 [==============================] - 2s 267ms/step - loss: 0.3508 - accuracy: 0.8861 - val_loss: 0.5674 - val_accuracy: 0.8240\n",
            "Epoch 103/300\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 0.3686 - accuracy: 0.8876 - val_loss: 0.5703 - val_accuracy: 0.8234\n",
            "Epoch 104/300\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 0.3606 - accuracy: 0.8890 - val_loss: 0.5672 - val_accuracy: 0.8265\n",
            "Epoch 105/300\n",
            "8/8 [==============================] - 2s 266ms/step - loss: 0.3541 - accuracy: 0.8903 - val_loss: 0.5684 - val_accuracy: 0.8234\n",
            "Epoch 106/300\n",
            "8/8 [==============================] - 2s 263ms/step - loss: 0.3621 - accuracy: 0.8874 - val_loss: 0.5677 - val_accuracy: 0.8234\n",
            "Epoch 107/300\n",
            "8/8 [==============================] - 2s 270ms/step - loss: 0.3511 - accuracy: 0.8925 - val_loss: 0.5651 - val_accuracy: 0.8252\n",
            "Epoch 108/300\n",
            "8/8 [==============================] - 2s 263ms/step - loss: 0.3428 - accuracy: 0.8945 - val_loss: 0.5654 - val_accuracy: 0.8265\n",
            "Epoch 109/300\n",
            "8/8 [==============================] - 2s 265ms/step - loss: 0.3592 - accuracy: 0.8942 - val_loss: 0.5645 - val_accuracy: 0.8240\n",
            "Epoch 110/300\n",
            "8/8 [==============================] - 2s 273ms/step - loss: 0.3366 - accuracy: 0.8985 - val_loss: 0.5640 - val_accuracy: 0.8283\n",
            "Epoch 111/300\n",
            "8/8 [==============================] - 2s 268ms/step - loss: 0.3430 - accuracy: 0.8931 - val_loss: 0.5635 - val_accuracy: 0.8289\n",
            "Epoch 112/300\n",
            "8/8 [==============================] - 2s 267ms/step - loss: 0.3601 - accuracy: 0.8887 - val_loss: 0.5631 - val_accuracy: 0.8252\n",
            "Epoch 113/300\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 0.3457 - accuracy: 0.8925 - val_loss: 0.5615 - val_accuracy: 0.8314\n",
            "Epoch 114/300\n",
            "8/8 [==============================] - 2s 267ms/step - loss: 0.3350 - accuracy: 0.8994 - val_loss: 0.5647 - val_accuracy: 0.8302\n",
            "Epoch 115/300\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 0.3371 - accuracy: 0.8967 - val_loss: 0.5624 - val_accuracy: 0.8320\n",
            "Epoch 116/300\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 0.3279 - accuracy: 0.9016 - val_loss: 0.5621 - val_accuracy: 0.8283\n",
            "Epoch 117/300\n",
            "8/8 [==============================] - 2s 272ms/step - loss: 0.3226 - accuracy: 0.9020 - val_loss: 0.5619 - val_accuracy: 0.8314\n",
            "Epoch 118/300\n",
            "8/8 [==============================] - 2s 267ms/step - loss: 0.3269 - accuracy: 0.9019 - val_loss: 0.5615 - val_accuracy: 0.8302\n",
            "Epoch 119/300\n",
            "8/8 [==============================] - 2s 266ms/step - loss: 0.3202 - accuracy: 0.9029 - val_loss: 0.5603 - val_accuracy: 0.8332\n",
            "Epoch 120/300\n",
            "8/8 [==============================] - 2s 265ms/step - loss: 0.3221 - accuracy: 0.9007 - val_loss: 0.5625 - val_accuracy: 0.8320\n",
            "Epoch 121/300\n",
            "8/8 [==============================] - 2s 265ms/step - loss: 0.3165 - accuracy: 0.9047 - val_loss: 0.5611 - val_accuracy: 0.8314\n",
            "Epoch 122/300\n",
            "8/8 [==============================] - 2s 265ms/step - loss: 0.3336 - accuracy: 0.8953 - val_loss: 0.5612 - val_accuracy: 0.8338\n",
            "Epoch 123/300\n",
            "8/8 [==============================] - 2s 275ms/step - loss: 0.3062 - accuracy: 0.9047 - val_loss: 0.5602 - val_accuracy: 0.8314\n",
            "Epoch 124/300\n",
            "8/8 [==============================] - 2s 267ms/step - loss: 0.3160 - accuracy: 0.9045 - val_loss: 0.5599 - val_accuracy: 0.8326\n",
            "Epoch 125/300\n",
            "8/8 [==============================] - 2s 262ms/step - loss: 0.3134 - accuracy: 0.9046 - val_loss: 0.5596 - val_accuracy: 0.8338\n",
            "Epoch 126/300\n",
            "8/8 [==============================] - 2s 266ms/step - loss: 0.3123 - accuracy: 0.9051 - val_loss: 0.5624 - val_accuracy: 0.8345\n",
            "Epoch 127/300\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 0.3173 - accuracy: 0.9029 - val_loss: 0.5616 - val_accuracy: 0.8357\n",
            "Epoch 128/300\n",
            "8/8 [==============================] - 2s 274ms/step - loss: 0.3285 - accuracy: 0.9018 - val_loss: 0.5617 - val_accuracy: 0.8351\n",
            "Epoch 129/300\n",
            "8/8 [==============================] - 2s 265ms/step - loss: 0.3103 - accuracy: 0.9064 - val_loss: 0.5593 - val_accuracy: 0.8357\n",
            "Epoch 130/300\n",
            "8/8 [==============================] - 2s 263ms/step - loss: 0.3066 - accuracy: 0.9115 - val_loss: 0.5600 - val_accuracy: 0.8369\n",
            "Epoch 131/300\n",
            "8/8 [==============================] - 2s 263ms/step - loss: 0.3108 - accuracy: 0.9056 - val_loss: 0.5583 - val_accuracy: 0.8357\n",
            "Epoch 132/300\n",
            "8/8 [==============================] - 2s 266ms/step - loss: 0.3105 - accuracy: 0.9098 - val_loss: 0.5594 - val_accuracy: 0.8326\n",
            "Epoch 133/300\n",
            "8/8 [==============================] - 2s 266ms/step - loss: 0.3083 - accuracy: 0.9083 - val_loss: 0.5575 - val_accuracy: 0.8375\n",
            "Epoch 134/300\n",
            "8/8 [==============================] - 2s 262ms/step - loss: 0.3051 - accuracy: 0.9036 - val_loss: 0.5589 - val_accuracy: 0.8338\n",
            "Epoch 135/300\n",
            "8/8 [==============================] - 2s 262ms/step - loss: 0.2878 - accuracy: 0.9154 - val_loss: 0.5585 - val_accuracy: 0.8388\n",
            "Epoch 136/300\n",
            "8/8 [==============================] - 2s 262ms/step - loss: 0.3091 - accuracy: 0.9052 - val_loss: 0.5583 - val_accuracy: 0.8375\n",
            "Epoch 137/300\n",
            "8/8 [==============================] - 2s 267ms/step - loss: 0.2879 - accuracy: 0.9129 - val_loss: 0.5579 - val_accuracy: 0.8363\n",
            "Epoch 138/300\n",
            "8/8 [==============================] - 2s 268ms/step - loss: 0.3086 - accuracy: 0.9059 - val_loss: 0.5571 - val_accuracy: 0.8357\n",
            "Epoch 139/300\n",
            "8/8 [==============================] - 2s 267ms/step - loss: 0.3035 - accuracy: 0.9051 - val_loss: 0.5566 - val_accuracy: 0.8363\n",
            "Epoch 140/300\n",
            "8/8 [==============================] - 2s 265ms/step - loss: 0.2962 - accuracy: 0.9105 - val_loss: 0.5572 - val_accuracy: 0.8375\n",
            "Epoch 141/300\n",
            "8/8 [==============================] - 2s 267ms/step - loss: 0.2872 - accuracy: 0.9110 - val_loss: 0.5576 - val_accuracy: 0.8357\n",
            "Epoch 142/300\n",
            "8/8 [==============================] - 2s 262ms/step - loss: 0.2977 - accuracy: 0.9077 - val_loss: 0.5580 - val_accuracy: 0.8363\n",
            "Epoch 143/300\n",
            "8/8 [==============================] - 2s 269ms/step - loss: 0.2927 - accuracy: 0.9094 - val_loss: 0.5592 - val_accuracy: 0.8363\n",
            "Epoch 144/300\n",
            "8/8 [==============================] - 2s 265ms/step - loss: 0.2860 - accuracy: 0.9186 - val_loss: 0.5610 - val_accuracy: 0.8369\n",
            "Epoch 145/300\n",
            "8/8 [==============================] - 2s 263ms/step - loss: 0.2952 - accuracy: 0.9099 - val_loss: 0.5622 - val_accuracy: 0.8369\n",
            "Epoch 146/300\n",
            "8/8 [==============================] - 2s 262ms/step - loss: 0.2877 - accuracy: 0.9159 - val_loss: 0.5626 - val_accuracy: 0.8351\n",
            "Epoch 147/300\n",
            "8/8 [==============================] - 2s 266ms/step - loss: 0.2888 - accuracy: 0.9128 - val_loss: 0.5607 - val_accuracy: 0.8369\n",
            "Epoch 148/300\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 0.2855 - accuracy: 0.9172 - val_loss: 0.5597 - val_accuracy: 0.8375\n",
            "Epoch 149/300\n",
            "8/8 [==============================] - 2s 263ms/step - loss: 0.2856 - accuracy: 0.9079 - val_loss: 0.5623 - val_accuracy: 0.8382\n",
            "Epoch 150/300\n",
            "8/8 [==============================] - 2s 261ms/step - loss: 0.2804 - accuracy: 0.9124 - val_loss: 0.5605 - val_accuracy: 0.8369\n",
            "Epoch 151/300\n",
            "8/8 [==============================] - 2s 261ms/step - loss: 0.2795 - accuracy: 0.9144 - val_loss: 0.5605 - val_accuracy: 0.8418\n",
            "Epoch 152/300\n",
            "8/8 [==============================] - 2s 271ms/step - loss: 0.2804 - accuracy: 0.9161 - val_loss: 0.5586 - val_accuracy: 0.8394\n",
            "Epoch 153/300\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 0.2751 - accuracy: 0.9140 - val_loss: 0.5613 - val_accuracy: 0.8382\n",
            "Epoch 154/300\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 0.2847 - accuracy: 0.9110 - val_loss: 0.5635 - val_accuracy: 0.8400\n",
            "Epoch 155/300\n",
            "8/8 [==============================] - 2s 263ms/step - loss: 0.2694 - accuracy: 0.9209 - val_loss: 0.5634 - val_accuracy: 0.8382\n",
            "Epoch 156/300\n",
            "8/8 [==============================] - 2s 265ms/step - loss: 0.2697 - accuracy: 0.9118 - val_loss: 0.5627 - val_accuracy: 0.8406\n",
            "Epoch 157/300\n",
            "8/8 [==============================] - 2s 265ms/step - loss: 0.2650 - accuracy: 0.9194 - val_loss: 0.5622 - val_accuracy: 0.8394\n",
            "Epoch 158/300\n",
            "8/8 [==============================] - 2s 265ms/step - loss: 0.2735 - accuracy: 0.9145 - val_loss: 0.5629 - val_accuracy: 0.8418\n",
            "Epoch 159/300\n",
            "8/8 [==============================] - 2s 265ms/step - loss: 0.2670 - accuracy: 0.9212 - val_loss: 0.5654 - val_accuracy: 0.8406\n",
            "Epoch 160/300\n",
            "8/8 [==============================] - 2s 261ms/step - loss: 0.2663 - accuracy: 0.9247 - val_loss: 0.5608 - val_accuracy: 0.8437\n",
            "Epoch 161/300\n",
            "8/8 [==============================] - 2s 263ms/step - loss: 0.2655 - accuracy: 0.9203 - val_loss: 0.5619 - val_accuracy: 0.8425\n",
            "Epoch 162/300\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 0.2715 - accuracy: 0.9176 - val_loss: 0.5608 - val_accuracy: 0.8418\n",
            "Epoch 163/300\n",
            "8/8 [==============================] - 2s 265ms/step - loss: 0.2628 - accuracy: 0.9224 - val_loss: 0.5632 - val_accuracy: 0.8400\n",
            "Epoch 164/300\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 0.2632 - accuracy: 0.9195 - val_loss: 0.5640 - val_accuracy: 0.8394\n",
            "51/51 [==============================] - 0s 9ms/step - loss: 0.5566 - accuracy: 0.8363\n",
            "val_accuracy= [0.5566339492797852, 0.8363077044487]\n",
            "119/119 [==============================] - 1s 8ms/step - loss: 0.2800 - accuracy: 0.9150\n",
            "train accuracy= [0.28004366159439087, 0.9150171279907227]\n",
            "unlabeled remaining= 2322  labels added= 123\n",
            "labeled at start of iteration: 5  is  3875 and unlabeled is 2322\n",
            "Epoch 1/300\n",
            "8/8 [==============================] - 3s 296ms/step - loss: 2.1833 - accuracy: 0.2213 - val_loss: 1.9487 - val_accuracy: 0.3917\n",
            "Epoch 2/300\n",
            "8/8 [==============================] - 2s 273ms/step - loss: 1.8853 - accuracy: 0.4087 - val_loss: 1.7418 - val_accuracy: 0.4519\n",
            "Epoch 3/300\n",
            "8/8 [==============================] - 2s 272ms/step - loss: 1.6974 - accuracy: 0.4625 - val_loss: 1.6087 - val_accuracy: 0.4819\n",
            "Epoch 4/300\n",
            "8/8 [==============================] - 2s 270ms/step - loss: 1.5919 - accuracy: 0.4908 - val_loss: 1.5122 - val_accuracy: 0.5247\n",
            "Epoch 5/300\n",
            "8/8 [==============================] - 2s 269ms/step - loss: 1.4951 - accuracy: 0.5136 - val_loss: 1.4439 - val_accuracy: 0.5355\n",
            "Epoch 6/300\n",
            "8/8 [==============================] - 2s 278ms/step - loss: 1.4389 - accuracy: 0.5511 - val_loss: 1.3865 - val_accuracy: 0.5542\n",
            "Epoch 7/300\n",
            "8/8 [==============================] - 2s 271ms/step - loss: 1.3831 - accuracy: 0.5537 - val_loss: 1.3394 - val_accuracy: 0.5650\n",
            "Epoch 8/300\n",
            "8/8 [==============================] - 2s 275ms/step - loss: 1.3281 - accuracy: 0.5689 - val_loss: 1.2951 - val_accuracy: 0.5770\n",
            "Epoch 9/300\n",
            "8/8 [==============================] - 2s 272ms/step - loss: 1.2841 - accuracy: 0.5867 - val_loss: 1.2597 - val_accuracy: 0.5806\n",
            "Epoch 10/300\n",
            "8/8 [==============================] - 2s 271ms/step - loss: 1.2406 - accuracy: 0.6087 - val_loss: 1.2223 - val_accuracy: 0.6023\n",
            "Epoch 11/300\n",
            "8/8 [==============================] - 2s 271ms/step - loss: 1.1872 - accuracy: 0.6330 - val_loss: 1.1885 - val_accuracy: 0.6131\n",
            "Epoch 12/300\n",
            "8/8 [==============================] - 2s 272ms/step - loss: 1.1696 - accuracy: 0.6354 - val_loss: 1.1563 - val_accuracy: 0.6245\n",
            "Epoch 13/300\n",
            "8/8 [==============================] - 2s 276ms/step - loss: 1.1508 - accuracy: 0.6444 - val_loss: 1.1275 - val_accuracy: 0.6396\n",
            "Epoch 14/300\n",
            "8/8 [==============================] - 2s 276ms/step - loss: 1.0976 - accuracy: 0.6739 - val_loss: 1.0984 - val_accuracy: 0.6516\n",
            "Epoch 15/300\n",
            "8/8 [==============================] - 2s 272ms/step - loss: 1.0797 - accuracy: 0.6696 - val_loss: 1.0717 - val_accuracy: 0.6619\n",
            "Epoch 16/300\n",
            "8/8 [==============================] - 2s 271ms/step - loss: 1.0389 - accuracy: 0.6815 - val_loss: 1.0475 - val_accuracy: 0.6661\n",
            "Epoch 17/300\n",
            "8/8 [==============================] - 2s 275ms/step - loss: 0.9970 - accuracy: 0.7006 - val_loss: 1.0223 - val_accuracy: 0.6733\n",
            "Epoch 18/300\n",
            "8/8 [==============================] - 2s 272ms/step - loss: 0.9859 - accuracy: 0.7010 - val_loss: 0.9976 - val_accuracy: 0.6823\n",
            "Epoch 19/300\n",
            "8/8 [==============================] - 2s 276ms/step - loss: 0.9782 - accuracy: 0.6967 - val_loss: 0.9766 - val_accuracy: 0.6841\n",
            "Epoch 20/300\n",
            "8/8 [==============================] - 2s 275ms/step - loss: 0.9479 - accuracy: 0.7026 - val_loss: 0.9548 - val_accuracy: 0.6943\n",
            "Epoch 21/300\n",
            "8/8 [==============================] - 2s 271ms/step - loss: 0.8975 - accuracy: 0.7186 - val_loss: 0.9355 - val_accuracy: 0.7022\n",
            "Epoch 22/300\n",
            "8/8 [==============================] - 2s 270ms/step - loss: 0.9000 - accuracy: 0.7254 - val_loss: 0.9176 - val_accuracy: 0.7082\n",
            "Epoch 23/300\n",
            "8/8 [==============================] - 2s 270ms/step - loss: 0.8685 - accuracy: 0.7294 - val_loss: 0.8989 - val_accuracy: 0.7100\n",
            "Epoch 24/300\n",
            "8/8 [==============================] - 2s 272ms/step - loss: 0.8589 - accuracy: 0.7360 - val_loss: 0.8845 - val_accuracy: 0.7184\n",
            "Epoch 25/300\n",
            "8/8 [==============================] - 2s 266ms/step - loss: 0.8040 - accuracy: 0.7496 - val_loss: 0.8679 - val_accuracy: 0.7256\n",
            "Epoch 26/300\n",
            "8/8 [==============================] - 2s 270ms/step - loss: 0.8236 - accuracy: 0.7437 - val_loss: 0.8534 - val_accuracy: 0.7310\n",
            "Epoch 27/300\n",
            "8/8 [==============================] - 2s 272ms/step - loss: 0.8115 - accuracy: 0.7504 - val_loss: 0.8376 - val_accuracy: 0.7323\n",
            "Epoch 28/300\n",
            "8/8 [==============================] - 2s 270ms/step - loss: 0.7916 - accuracy: 0.7629 - val_loss: 0.8233 - val_accuracy: 0.7371\n",
            "Epoch 29/300\n",
            "8/8 [==============================] - 2s 271ms/step - loss: 0.7704 - accuracy: 0.7751 - val_loss: 0.8130 - val_accuracy: 0.7431\n",
            "Epoch 30/300\n",
            "8/8 [==============================] - 2s 269ms/step - loss: 0.7478 - accuracy: 0.7752 - val_loss: 0.7973 - val_accuracy: 0.7503\n",
            "Epoch 31/300\n",
            "8/8 [==============================] - 2s 269ms/step - loss: 0.7518 - accuracy: 0.7733 - val_loss: 0.7892 - val_accuracy: 0.7527\n",
            "Epoch 32/300\n",
            "8/8 [==============================] - 2s 267ms/step - loss: 0.7434 - accuracy: 0.7817 - val_loss: 0.7795 - val_accuracy: 0.7563\n",
            "Epoch 33/300\n",
            "8/8 [==============================] - 2s 271ms/step - loss: 0.6927 - accuracy: 0.7937 - val_loss: 0.7673 - val_accuracy: 0.7617\n",
            "Epoch 34/300\n",
            "8/8 [==============================] - 2s 269ms/step - loss: 0.7081 - accuracy: 0.7918 - val_loss: 0.7567 - val_accuracy: 0.7690\n",
            "Epoch 35/300\n",
            "8/8 [==============================] - 2s 273ms/step - loss: 0.6865 - accuracy: 0.8016 - val_loss: 0.7493 - val_accuracy: 0.7756\n",
            "Epoch 36/300\n",
            "8/8 [==============================] - 2s 270ms/step - loss: 0.6716 - accuracy: 0.8028 - val_loss: 0.7391 - val_accuracy: 0.7756\n",
            "Epoch 37/300\n",
            "8/8 [==============================] - 2s 272ms/step - loss: 0.6643 - accuracy: 0.8022 - val_loss: 0.7293 - val_accuracy: 0.7792\n",
            "Epoch 38/300\n",
            "8/8 [==============================] - 2s 273ms/step - loss: 0.6690 - accuracy: 0.8037 - val_loss: 0.7220 - val_accuracy: 0.7804\n",
            "Epoch 39/300\n",
            "8/8 [==============================] - 2s 271ms/step - loss: 0.6351 - accuracy: 0.8174 - val_loss: 0.7124 - val_accuracy: 0.7834\n",
            "Epoch 40/300\n",
            "8/8 [==============================] - 2s 273ms/step - loss: 0.6263 - accuracy: 0.8261 - val_loss: 0.7057 - val_accuracy: 0.7834\n",
            "Epoch 41/300\n",
            "8/8 [==============================] - 2s 273ms/step - loss: 0.6553 - accuracy: 0.8031 - val_loss: 0.6988 - val_accuracy: 0.7870\n",
            "Epoch 42/300\n",
            "8/8 [==============================] - 2s 272ms/step - loss: 0.6158 - accuracy: 0.8223 - val_loss: 0.6949 - val_accuracy: 0.7864\n",
            "Epoch 43/300\n",
            "8/8 [==============================] - 2s 276ms/step - loss: 0.5805 - accuracy: 0.8357 - val_loss: 0.6855 - val_accuracy: 0.7846\n",
            "Epoch 44/300\n",
            "8/8 [==============================] - 2s 273ms/step - loss: 0.6017 - accuracy: 0.8248 - val_loss: 0.6786 - val_accuracy: 0.7906\n",
            "Epoch 45/300\n",
            "8/8 [==============================] - 2s 271ms/step - loss: 0.5734 - accuracy: 0.8404 - val_loss: 0.6750 - val_accuracy: 0.7918\n",
            "Epoch 46/300\n",
            "8/8 [==============================] - 2s 274ms/step - loss: 0.5800 - accuracy: 0.8258 - val_loss: 0.6694 - val_accuracy: 0.7870\n",
            "Epoch 47/300\n",
            "8/8 [==============================] - 2s 270ms/step - loss: 0.5936 - accuracy: 0.8257 - val_loss: 0.6637 - val_accuracy: 0.7936\n",
            "Epoch 48/300\n",
            "8/8 [==============================] - 2s 272ms/step - loss: 0.5938 - accuracy: 0.8284 - val_loss: 0.6589 - val_accuracy: 0.7930\n",
            "Epoch 49/300\n",
            "8/8 [==============================] - 2s 272ms/step - loss: 0.5627 - accuracy: 0.8341 - val_loss: 0.6534 - val_accuracy: 0.7966\n",
            "Epoch 50/300\n",
            "8/8 [==============================] - 2s 274ms/step - loss: 0.5695 - accuracy: 0.8271 - val_loss: 0.6480 - val_accuracy: 0.7990\n",
            "Epoch 51/300\n",
            "8/8 [==============================] - 2s 272ms/step - loss: 0.5528 - accuracy: 0.8427 - val_loss: 0.6439 - val_accuracy: 0.7972\n",
            "Epoch 52/300\n",
            "8/8 [==============================] - 2s 271ms/step - loss: 0.5362 - accuracy: 0.8422 - val_loss: 0.6403 - val_accuracy: 0.7996\n",
            "Epoch 53/300\n",
            "8/8 [==============================] - 2s 278ms/step - loss: 0.5246 - accuracy: 0.8481 - val_loss: 0.6386 - val_accuracy: 0.7984\n",
            "Epoch 54/300\n",
            "8/8 [==============================] - 2s 275ms/step - loss: 0.5297 - accuracy: 0.8382 - val_loss: 0.6340 - val_accuracy: 0.8014\n",
            "Epoch 55/300\n",
            "8/8 [==============================] - 2s 275ms/step - loss: 0.5252 - accuracy: 0.8402 - val_loss: 0.6298 - val_accuracy: 0.7978\n",
            "Epoch 56/300\n",
            "8/8 [==============================] - 2s 272ms/step - loss: 0.5298 - accuracy: 0.8394 - val_loss: 0.6252 - val_accuracy: 0.8014\n",
            "Epoch 57/300\n",
            "8/8 [==============================] - 2s 273ms/step - loss: 0.5110 - accuracy: 0.8469 - val_loss: 0.6220 - val_accuracy: 0.8008\n",
            "Epoch 58/300\n",
            "8/8 [==============================] - 2s 276ms/step - loss: 0.5037 - accuracy: 0.8497 - val_loss: 0.6180 - val_accuracy: 0.8026\n",
            "Epoch 59/300\n",
            "8/8 [==============================] - 2s 272ms/step - loss: 0.4927 - accuracy: 0.8584 - val_loss: 0.6150 - val_accuracy: 0.8008\n",
            "Epoch 60/300\n",
            "8/8 [==============================] - 2s 273ms/step - loss: 0.4990 - accuracy: 0.8436 - val_loss: 0.6101 - val_accuracy: 0.8051\n",
            "Epoch 61/300\n",
            "8/8 [==============================] - 2s 275ms/step - loss: 0.4903 - accuracy: 0.8476 - val_loss: 0.6089 - val_accuracy: 0.8069\n",
            "Epoch 62/300\n",
            "8/8 [==============================] - 2s 276ms/step - loss: 0.4969 - accuracy: 0.8507 - val_loss: 0.6051 - val_accuracy: 0.8039\n",
            "Epoch 63/300\n",
            "8/8 [==============================] - 2s 275ms/step - loss: 0.4935 - accuracy: 0.8476 - val_loss: 0.6054 - val_accuracy: 0.8063\n",
            "Epoch 64/300\n",
            "8/8 [==============================] - 2s 276ms/step - loss: 0.4969 - accuracy: 0.8464 - val_loss: 0.5999 - val_accuracy: 0.8075\n",
            "Epoch 65/300\n",
            "8/8 [==============================] - 2s 272ms/step - loss: 0.4763 - accuracy: 0.8537 - val_loss: 0.5968 - val_accuracy: 0.8117\n",
            "Epoch 66/300\n",
            "8/8 [==============================] - 2s 273ms/step - loss: 0.4528 - accuracy: 0.8614 - val_loss: 0.5952 - val_accuracy: 0.8051\n",
            "Epoch 67/300\n",
            "8/8 [==============================] - 2s 271ms/step - loss: 0.4735 - accuracy: 0.8560 - val_loss: 0.5938 - val_accuracy: 0.8099\n",
            "Epoch 68/300\n",
            "8/8 [==============================] - 2s 274ms/step - loss: 0.4660 - accuracy: 0.8573 - val_loss: 0.5913 - val_accuracy: 0.8117\n",
            "Epoch 69/300\n",
            "8/8 [==============================] - 2s 273ms/step - loss: 0.4629 - accuracy: 0.8579 - val_loss: 0.5868 - val_accuracy: 0.8111\n",
            "Epoch 70/300\n",
            "8/8 [==============================] - 2s 271ms/step - loss: 0.4523 - accuracy: 0.8576 - val_loss: 0.5900 - val_accuracy: 0.8135\n",
            "Epoch 71/300\n",
            "8/8 [==============================] - 2s 273ms/step - loss: 0.4566 - accuracy: 0.8611 - val_loss: 0.5827 - val_accuracy: 0.8159\n",
            "Epoch 72/300\n",
            "8/8 [==============================] - 2s 272ms/step - loss: 0.4616 - accuracy: 0.8597 - val_loss: 0.5833 - val_accuracy: 0.8087\n",
            "Epoch 73/300\n",
            "8/8 [==============================] - 2s 273ms/step - loss: 0.4402 - accuracy: 0.8604 - val_loss: 0.5788 - val_accuracy: 0.8165\n",
            "Epoch 74/300\n",
            "8/8 [==============================] - 2s 271ms/step - loss: 0.4677 - accuracy: 0.8571 - val_loss: 0.5773 - val_accuracy: 0.8141\n",
            "Epoch 75/300\n",
            "8/8 [==============================] - 2s 271ms/step - loss: 0.4380 - accuracy: 0.8660 - val_loss: 0.5756 - val_accuracy: 0.8159\n",
            "Epoch 76/300\n",
            "8/8 [==============================] - 2s 272ms/step - loss: 0.4496 - accuracy: 0.8583 - val_loss: 0.5724 - val_accuracy: 0.8219\n",
            "Epoch 77/300\n",
            "8/8 [==============================] - 2s 274ms/step - loss: 0.4367 - accuracy: 0.8648 - val_loss: 0.5713 - val_accuracy: 0.8219\n",
            "Epoch 78/300\n",
            "8/8 [==============================] - 2s 272ms/step - loss: 0.4335 - accuracy: 0.8603 - val_loss: 0.5706 - val_accuracy: 0.8243\n",
            "Epoch 79/300\n",
            "8/8 [==============================] - 2s 272ms/step - loss: 0.4320 - accuracy: 0.8620 - val_loss: 0.5674 - val_accuracy: 0.8201\n",
            "Epoch 80/300\n",
            "8/8 [==============================] - 2s 274ms/step - loss: 0.4125 - accuracy: 0.8763 - val_loss: 0.5661 - val_accuracy: 0.8219\n",
            "Epoch 81/300\n",
            "8/8 [==============================] - 2s 275ms/step - loss: 0.4008 - accuracy: 0.8797 - val_loss: 0.5648 - val_accuracy: 0.8267\n",
            "Epoch 82/300\n",
            "8/8 [==============================] - 2s 273ms/step - loss: 0.4180 - accuracy: 0.8708 - val_loss: 0.5645 - val_accuracy: 0.8237\n",
            "Epoch 83/300\n",
            "8/8 [==============================] - 2s 272ms/step - loss: 0.4216 - accuracy: 0.8665 - val_loss: 0.5608 - val_accuracy: 0.8225\n",
            "Epoch 84/300\n",
            "8/8 [==============================] - 2s 271ms/step - loss: 0.4072 - accuracy: 0.8726 - val_loss: 0.5615 - val_accuracy: 0.8255\n",
            "Epoch 85/300\n",
            "8/8 [==============================] - 2s 272ms/step - loss: 0.4001 - accuracy: 0.8756 - val_loss: 0.5621 - val_accuracy: 0.8231\n",
            "Epoch 86/300\n",
            "8/8 [==============================] - 2s 274ms/step - loss: 0.4195 - accuracy: 0.8699 - val_loss: 0.5569 - val_accuracy: 0.8243\n",
            "Epoch 87/300\n",
            "8/8 [==============================] - 2s 276ms/step - loss: 0.4172 - accuracy: 0.8686 - val_loss: 0.5557 - val_accuracy: 0.8291\n",
            "Epoch 88/300\n",
            "8/8 [==============================] - 2s 273ms/step - loss: 0.3930 - accuracy: 0.8758 - val_loss: 0.5547 - val_accuracy: 0.8279\n",
            "Epoch 89/300\n",
            "8/8 [==============================] - 2s 274ms/step - loss: 0.3902 - accuracy: 0.8775 - val_loss: 0.5539 - val_accuracy: 0.8273\n",
            "Epoch 90/300\n",
            "8/8 [==============================] - 2s 270ms/step - loss: 0.3986 - accuracy: 0.8719 - val_loss: 0.5534 - val_accuracy: 0.8303\n",
            "Epoch 91/300\n",
            "8/8 [==============================] - 2s 272ms/step - loss: 0.3786 - accuracy: 0.8798 - val_loss: 0.5512 - val_accuracy: 0.8261\n",
            "Epoch 92/300\n",
            "8/8 [==============================] - 2s 271ms/step - loss: 0.3868 - accuracy: 0.8751 - val_loss: 0.5515 - val_accuracy: 0.8291\n",
            "Epoch 93/300\n",
            "8/8 [==============================] - 2s 273ms/step - loss: 0.3801 - accuracy: 0.8798 - val_loss: 0.5495 - val_accuracy: 0.8297\n",
            "Epoch 94/300\n",
            "8/8 [==============================] - 2s 272ms/step - loss: 0.3801 - accuracy: 0.8809 - val_loss: 0.5517 - val_accuracy: 0.8309\n",
            "Epoch 95/300\n",
            "8/8 [==============================] - 2s 270ms/step - loss: 0.3723 - accuracy: 0.8798 - val_loss: 0.5474 - val_accuracy: 0.8309\n",
            "Epoch 96/300\n",
            "8/8 [==============================] - 2s 274ms/step - loss: 0.3787 - accuracy: 0.8823 - val_loss: 0.5490 - val_accuracy: 0.8285\n",
            "Epoch 97/300\n",
            "8/8 [==============================] - 2s 273ms/step - loss: 0.3747 - accuracy: 0.8818 - val_loss: 0.5474 - val_accuracy: 0.8333\n",
            "Epoch 98/300\n",
            "8/8 [==============================] - 2s 275ms/step - loss: 0.3735 - accuracy: 0.8803 - val_loss: 0.5455 - val_accuracy: 0.8291\n",
            "Epoch 99/300\n",
            "8/8 [==============================] - 2s 273ms/step - loss: 0.3649 - accuracy: 0.8842 - val_loss: 0.5449 - val_accuracy: 0.8357\n",
            "Epoch 100/300\n",
            "8/8 [==============================] - 2s 270ms/step - loss: 0.3568 - accuracy: 0.8907 - val_loss: 0.5467 - val_accuracy: 0.8333\n",
            "Epoch 101/300\n",
            "8/8 [==============================] - 2s 270ms/step - loss: 0.3739 - accuracy: 0.8786 - val_loss: 0.5429 - val_accuracy: 0.8333\n",
            "Epoch 102/300\n",
            "8/8 [==============================] - 2s 271ms/step - loss: 0.3678 - accuracy: 0.8832 - val_loss: 0.5429 - val_accuracy: 0.8309\n",
            "Epoch 103/300\n",
            "8/8 [==============================] - 2s 272ms/step - loss: 0.3572 - accuracy: 0.8886 - val_loss: 0.5398 - val_accuracy: 0.8363\n",
            "Epoch 104/300\n",
            "8/8 [==============================] - 2s 273ms/step - loss: 0.3579 - accuracy: 0.8870 - val_loss: 0.5400 - val_accuracy: 0.8345\n",
            "Epoch 105/300\n",
            "8/8 [==============================] - 2s 275ms/step - loss: 0.3500 - accuracy: 0.8896 - val_loss: 0.5415 - val_accuracy: 0.8339\n",
            "Epoch 106/300\n",
            "8/8 [==============================] - 2s 270ms/step - loss: 0.3515 - accuracy: 0.8922 - val_loss: 0.5385 - val_accuracy: 0.8357\n",
            "Epoch 107/300\n",
            "8/8 [==============================] - 2s 273ms/step - loss: 0.3758 - accuracy: 0.8807 - val_loss: 0.5404 - val_accuracy: 0.8387\n",
            "Epoch 108/300\n",
            "8/8 [==============================] - 2s 275ms/step - loss: 0.3454 - accuracy: 0.8900 - val_loss: 0.5395 - val_accuracy: 0.8333\n",
            "Epoch 109/300\n",
            "8/8 [==============================] - 2s 278ms/step - loss: 0.3462 - accuracy: 0.8870 - val_loss: 0.5362 - val_accuracy: 0.8387\n",
            "Epoch 110/300\n",
            "8/8 [==============================] - 2s 271ms/step - loss: 0.3439 - accuracy: 0.8916 - val_loss: 0.5385 - val_accuracy: 0.8357\n",
            "Epoch 111/300\n",
            "8/8 [==============================] - 2s 274ms/step - loss: 0.3609 - accuracy: 0.8848 - val_loss: 0.5361 - val_accuracy: 0.8381\n",
            "Epoch 112/300\n",
            "8/8 [==============================] - 2s 272ms/step - loss: 0.3500 - accuracy: 0.8903 - val_loss: 0.5361 - val_accuracy: 0.8345\n",
            "Epoch 113/300\n",
            "8/8 [==============================] - 2s 269ms/step - loss: 0.3417 - accuracy: 0.8934 - val_loss: 0.5343 - val_accuracy: 0.8394\n",
            "Epoch 114/300\n",
            "8/8 [==============================] - 2s 273ms/step - loss: 0.3230 - accuracy: 0.8978 - val_loss: 0.5343 - val_accuracy: 0.8363\n",
            "Epoch 115/300\n",
            "8/8 [==============================] - 2s 273ms/step - loss: 0.3388 - accuracy: 0.8878 - val_loss: 0.5306 - val_accuracy: 0.8375\n",
            "Epoch 116/300\n",
            "8/8 [==============================] - 2s 273ms/step - loss: 0.3202 - accuracy: 0.9006 - val_loss: 0.5306 - val_accuracy: 0.8394\n",
            "Epoch 117/300\n",
            "8/8 [==============================] - 2s 273ms/step - loss: 0.3149 - accuracy: 0.9066 - val_loss: 0.5361 - val_accuracy: 0.8381\n",
            "Epoch 118/300\n",
            "8/8 [==============================] - 2s 271ms/step - loss: 0.3197 - accuracy: 0.8944 - val_loss: 0.5320 - val_accuracy: 0.8345\n",
            "Epoch 119/300\n",
            "8/8 [==============================] - 2s 276ms/step - loss: 0.3306 - accuracy: 0.8929 - val_loss: 0.5337 - val_accuracy: 0.8369\n",
            "Epoch 120/300\n",
            "8/8 [==============================] - 2s 273ms/step - loss: 0.3306 - accuracy: 0.8969 - val_loss: 0.5298 - val_accuracy: 0.8369\n",
            "Epoch 121/300\n",
            "8/8 [==============================] - 2s 275ms/step - loss: 0.3146 - accuracy: 0.9027 - val_loss: 0.5348 - val_accuracy: 0.8357\n",
            "Epoch 122/300\n",
            "8/8 [==============================] - 2s 275ms/step - loss: 0.3185 - accuracy: 0.8968 - val_loss: 0.5268 - val_accuracy: 0.8394\n",
            "Epoch 123/300\n",
            "8/8 [==============================] - 2s 271ms/step - loss: 0.3219 - accuracy: 0.8944 - val_loss: 0.5337 - val_accuracy: 0.8333\n",
            "Epoch 124/300\n",
            "8/8 [==============================] - 2s 271ms/step - loss: 0.3188 - accuracy: 0.9015 - val_loss: 0.5292 - val_accuracy: 0.8351\n",
            "Epoch 125/300\n",
            "8/8 [==============================] - 2s 278ms/step - loss: 0.3208 - accuracy: 0.8999 - val_loss: 0.5319 - val_accuracy: 0.8400\n",
            "Epoch 126/300\n",
            "8/8 [==============================] - 2s 271ms/step - loss: 0.3084 - accuracy: 0.9008 - val_loss: 0.5308 - val_accuracy: 0.8394\n",
            "Epoch 127/300\n",
            "8/8 [==============================] - 2s 272ms/step - loss: 0.3070 - accuracy: 0.9035 - val_loss: 0.5306 - val_accuracy: 0.8375\n",
            "Epoch 128/300\n",
            "8/8 [==============================] - 2s 273ms/step - loss: 0.3109 - accuracy: 0.9023 - val_loss: 0.5313 - val_accuracy: 0.8369\n",
            "Epoch 129/300\n",
            "8/8 [==============================] - 2s 272ms/step - loss: 0.2997 - accuracy: 0.9083 - val_loss: 0.5285 - val_accuracy: 0.8394\n",
            "Epoch 130/300\n",
            "8/8 [==============================] - 2s 274ms/step - loss: 0.2957 - accuracy: 0.9041 - val_loss: 0.5295 - val_accuracy: 0.8400\n",
            "Epoch 131/300\n",
            "8/8 [==============================] - 2s 271ms/step - loss: 0.3010 - accuracy: 0.9021 - val_loss: 0.5277 - val_accuracy: 0.8381\n",
            "Epoch 132/300\n",
            "8/8 [==============================] - 2s 276ms/step - loss: 0.2878 - accuracy: 0.9068 - val_loss: 0.5298 - val_accuracy: 0.8381\n",
            "Epoch 133/300\n",
            "8/8 [==============================] - 2s 272ms/step - loss: 0.3049 - accuracy: 0.9045 - val_loss: 0.5257 - val_accuracy: 0.8369\n",
            "Epoch 134/300\n",
            "8/8 [==============================] - 2s 273ms/step - loss: 0.2951 - accuracy: 0.9092 - val_loss: 0.5277 - val_accuracy: 0.8381\n",
            "Epoch 135/300\n",
            "8/8 [==============================] - 2s 273ms/step - loss: 0.2919 - accuracy: 0.9061 - val_loss: 0.5284 - val_accuracy: 0.8369\n",
            "Epoch 136/300\n",
            "8/8 [==============================] - 2s 278ms/step - loss: 0.2869 - accuracy: 0.9108 - val_loss: 0.5279 - val_accuracy: 0.8412\n",
            "Epoch 137/300\n",
            "8/8 [==============================] - 2s 276ms/step - loss: 0.2825 - accuracy: 0.9134 - val_loss: 0.5271 - val_accuracy: 0.8387\n",
            "Epoch 138/300\n",
            "8/8 [==============================] - 2s 274ms/step - loss: 0.2952 - accuracy: 0.9093 - val_loss: 0.5277 - val_accuracy: 0.8375\n",
            "Epoch 139/300\n",
            "8/8 [==============================] - 2s 271ms/step - loss: 0.2901 - accuracy: 0.9074 - val_loss: 0.5280 - val_accuracy: 0.8400\n",
            "Epoch 140/300\n",
            "8/8 [==============================] - 2s 270ms/step - loss: 0.2778 - accuracy: 0.9126 - val_loss: 0.5242 - val_accuracy: 0.8400\n",
            "Epoch 141/300\n",
            "8/8 [==============================] - 2s 274ms/step - loss: 0.2810 - accuracy: 0.9139 - val_loss: 0.5251 - val_accuracy: 0.8406\n",
            "Epoch 142/300\n",
            "8/8 [==============================] - 2s 277ms/step - loss: 0.2825 - accuracy: 0.9139 - val_loss: 0.5232 - val_accuracy: 0.8424\n",
            "Epoch 143/300\n",
            "8/8 [==============================] - 2s 275ms/step - loss: 0.2908 - accuracy: 0.9047 - val_loss: 0.5311 - val_accuracy: 0.8394\n",
            "Epoch 144/300\n",
            "8/8 [==============================] - 2s 271ms/step - loss: 0.2767 - accuracy: 0.9132 - val_loss: 0.5266 - val_accuracy: 0.8375\n",
            "Epoch 145/300\n",
            "8/8 [==============================] - 2s 282ms/step - loss: 0.2885 - accuracy: 0.9108 - val_loss: 0.5277 - val_accuracy: 0.8400\n",
            "Epoch 146/300\n",
            "8/8 [==============================] - 2s 275ms/step - loss: 0.2761 - accuracy: 0.9122 - val_loss: 0.5248 - val_accuracy: 0.8394\n",
            "Epoch 147/300\n",
            "8/8 [==============================] - 2s 274ms/step - loss: 0.2716 - accuracy: 0.9137 - val_loss: 0.5253 - val_accuracy: 0.8418\n",
            "Epoch 148/300\n",
            "8/8 [==============================] - 2s 276ms/step - loss: 0.2882 - accuracy: 0.9090 - val_loss: 0.5265 - val_accuracy: 0.8436\n",
            "Epoch 149/300\n",
            "8/8 [==============================] - 2s 276ms/step - loss: 0.2711 - accuracy: 0.9099 - val_loss: 0.5273 - val_accuracy: 0.8418\n",
            "Epoch 150/300\n",
            "8/8 [==============================] - 2s 276ms/step - loss: 0.2688 - accuracy: 0.9162 - val_loss: 0.5249 - val_accuracy: 0.8424\n",
            "Epoch 151/300\n",
            "8/8 [==============================] - 2s 274ms/step - loss: 0.2794 - accuracy: 0.9093 - val_loss: 0.5249 - val_accuracy: 0.8448\n",
            "Epoch 152/300\n",
            "8/8 [==============================] - 2s 275ms/step - loss: 0.2759 - accuracy: 0.9167 - val_loss: 0.5266 - val_accuracy: 0.8430\n",
            "Epoch 153/300\n",
            "8/8 [==============================] - 2s 278ms/step - loss: 0.2742 - accuracy: 0.9131 - val_loss: 0.5264 - val_accuracy: 0.8442\n",
            "Epoch 154/300\n",
            "8/8 [==============================] - 2s 275ms/step - loss: 0.2704 - accuracy: 0.9176 - val_loss: 0.5249 - val_accuracy: 0.8472\n",
            "Epoch 155/300\n",
            "8/8 [==============================] - 2s 276ms/step - loss: 0.2798 - accuracy: 0.9115 - val_loss: 0.5260 - val_accuracy: 0.8418\n",
            "Epoch 156/300\n",
            "8/8 [==============================] - 2s 276ms/step - loss: 0.2554 - accuracy: 0.9178 - val_loss: 0.5249 - val_accuracy: 0.8394\n",
            "Epoch 157/300\n",
            "8/8 [==============================] - 2s 277ms/step - loss: 0.2742 - accuracy: 0.9148 - val_loss: 0.5258 - val_accuracy: 0.8381\n",
            "Epoch 158/300\n",
            "8/8 [==============================] - 2s 275ms/step - loss: 0.2675 - accuracy: 0.9184 - val_loss: 0.5266 - val_accuracy: 0.8381\n",
            "Epoch 159/300\n",
            "8/8 [==============================] - 2s 273ms/step - loss: 0.2590 - accuracy: 0.9205 - val_loss: 0.5248 - val_accuracy: 0.8448\n",
            "Epoch 160/300\n",
            "8/8 [==============================] - 2s 274ms/step - loss: 0.2584 - accuracy: 0.9200 - val_loss: 0.5266 - val_accuracy: 0.8448\n",
            "Epoch 161/300\n",
            "8/8 [==============================] - 2s 278ms/step - loss: 0.2616 - accuracy: 0.9160 - val_loss: 0.5235 - val_accuracy: 0.8448\n",
            "Epoch 162/300\n",
            "8/8 [==============================] - 2s 276ms/step - loss: 0.2489 - accuracy: 0.9252 - val_loss: 0.5281 - val_accuracy: 0.8442\n",
            "Epoch 163/300\n",
            "8/8 [==============================] - 2s 273ms/step - loss: 0.2511 - accuracy: 0.9215 - val_loss: 0.5264 - val_accuracy: 0.8448\n",
            "Epoch 164/300\n",
            "8/8 [==============================] - 2s 273ms/step - loss: 0.2452 - accuracy: 0.9234 - val_loss: 0.5250 - val_accuracy: 0.8466\n",
            "Epoch 165/300\n",
            "8/8 [==============================] - 2s 279ms/step - loss: 0.2512 - accuracy: 0.9224 - val_loss: 0.5253 - val_accuracy: 0.8436\n",
            "Epoch 166/300\n",
            "8/8 [==============================] - 2s 273ms/step - loss: 0.2592 - accuracy: 0.9171 - val_loss: 0.5281 - val_accuracy: 0.8448\n",
            "Epoch 167/300\n",
            "8/8 [==============================] - 2s 277ms/step - loss: 0.2464 - accuracy: 0.9238 - val_loss: 0.5221 - val_accuracy: 0.8418\n",
            "Epoch 168/300\n",
            "8/8 [==============================] - 2s 276ms/step - loss: 0.2550 - accuracy: 0.9191 - val_loss: 0.5306 - val_accuracy: 0.8448\n",
            "Epoch 169/300\n",
            "8/8 [==============================] - 2s 273ms/step - loss: 0.2513 - accuracy: 0.9200 - val_loss: 0.5231 - val_accuracy: 0.8448\n",
            "Epoch 170/300\n",
            "8/8 [==============================] - 2s 280ms/step - loss: 0.2614 - accuracy: 0.9142 - val_loss: 0.5253 - val_accuracy: 0.8448\n",
            "Epoch 171/300\n",
            "8/8 [==============================] - 2s 275ms/step - loss: 0.2518 - accuracy: 0.9190 - val_loss: 0.5240 - val_accuracy: 0.8460\n",
            "Epoch 172/300\n",
            "8/8 [==============================] - 2s 274ms/step - loss: 0.2469 - accuracy: 0.9236 - val_loss: 0.5273 - val_accuracy: 0.8484\n",
            "Epoch 173/300\n",
            "8/8 [==============================] - 2s 274ms/step - loss: 0.2441 - accuracy: 0.9229 - val_loss: 0.5323 - val_accuracy: 0.8430\n",
            "Epoch 174/300\n",
            "8/8 [==============================] - 2s 274ms/step - loss: 0.2326 - accuracy: 0.9321 - val_loss: 0.5291 - val_accuracy: 0.8460\n",
            "Epoch 175/300\n",
            "8/8 [==============================] - 2s 273ms/step - loss: 0.2352 - accuracy: 0.9328 - val_loss: 0.5321 - val_accuracy: 0.8460\n",
            "Epoch 176/300\n",
            "8/8 [==============================] - 2s 277ms/step - loss: 0.2397 - accuracy: 0.9230 - val_loss: 0.5306 - val_accuracy: 0.8454\n",
            "Epoch 177/300\n",
            "8/8 [==============================] - 2s 272ms/step - loss: 0.2384 - accuracy: 0.9237 - val_loss: 0.5272 - val_accuracy: 0.8484\n",
            "Epoch 178/300\n",
            "8/8 [==============================] - 2s 272ms/step - loss: 0.2437 - accuracy: 0.9262 - val_loss: 0.5278 - val_accuracy: 0.8460\n",
            "Epoch 179/300\n",
            "8/8 [==============================] - 2s 278ms/step - loss: 0.2357 - accuracy: 0.9277 - val_loss: 0.5325 - val_accuracy: 0.8436\n",
            "Epoch 180/300\n",
            "8/8 [==============================] - 2s 276ms/step - loss: 0.2447 - accuracy: 0.9192 - val_loss: 0.5273 - val_accuracy: 0.8478\n",
            "Epoch 181/300\n",
            "8/8 [==============================] - 2s 274ms/step - loss: 0.2500 - accuracy: 0.9228 - val_loss: 0.5341 - val_accuracy: 0.8484\n",
            "Epoch 182/300\n",
            "8/8 [==============================] - 2s 275ms/step - loss: 0.2304 - accuracy: 0.9258 - val_loss: 0.5316 - val_accuracy: 0.8460\n",
            "Epoch 183/300\n",
            "8/8 [==============================] - 2s 273ms/step - loss: 0.2349 - accuracy: 0.9273 - val_loss: 0.5278 - val_accuracy: 0.8490\n",
            "Epoch 184/300\n",
            "8/8 [==============================] - 2s 271ms/step - loss: 0.2267 - accuracy: 0.9287 - val_loss: 0.5290 - val_accuracy: 0.8466\n",
            "Epoch 185/300\n",
            "8/8 [==============================] - 2s 273ms/step - loss: 0.2423 - accuracy: 0.9229 - val_loss: 0.5286 - val_accuracy: 0.8502\n",
            "Epoch 186/300\n",
            "8/8 [==============================] - 2s 273ms/step - loss: 0.2388 - accuracy: 0.9242 - val_loss: 0.5305 - val_accuracy: 0.8490\n",
            "Epoch 187/300\n",
            "8/8 [==============================] - 2s 276ms/step - loss: 0.2329 - accuracy: 0.9314 - val_loss: 0.5337 - val_accuracy: 0.8448\n",
            "Epoch 188/300\n",
            "8/8 [==============================] - 2s 275ms/step - loss: 0.2292 - accuracy: 0.9286 - val_loss: 0.5313 - val_accuracy: 0.8430\n",
            "Epoch 189/300\n",
            "8/8 [==============================] - 2s 277ms/step - loss: 0.2321 - accuracy: 0.9276 - val_loss: 0.5311 - val_accuracy: 0.8436\n",
            "Epoch 190/300\n",
            "8/8 [==============================] - 2s 277ms/step - loss: 0.2260 - accuracy: 0.9286 - val_loss: 0.5328 - val_accuracy: 0.8460\n",
            "Epoch 191/300\n",
            "8/8 [==============================] - 2s 273ms/step - loss: 0.2290 - accuracy: 0.9291 - val_loss: 0.5326 - val_accuracy: 0.8466\n",
            "Epoch 192/300\n",
            "8/8 [==============================] - 2s 272ms/step - loss: 0.2274 - accuracy: 0.9290 - val_loss: 0.5334 - val_accuracy: 0.8448\n",
            "52/52 [==============================] - 1s 9ms/step - loss: 0.5221 - accuracy: 0.8418\n",
            "val_accuracy= [0.5221223831176758, 0.8417569398880005]\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.2371 - accuracy: 0.9280\n",
            "train accuracy= [0.23710274696350098, 0.9279999732971191]\n",
            "unlabeled remaining= 2199  labels added= 123\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h73-oZONxBoJ"
      },
      "source": [
        "s['Iteration']=iter\n",
        "s['Training samples']=labeled\n",
        "s['Unlabeled']=unlabeled\n",
        "s['Train Accuracy']=train_acc\n",
        "s['Validation Accuracy']=val_acc\n",
        "s['labels>0.9']=labels_tobe_added"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOiUZwUjLgJi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "e83b7008-c237-4ed8-f881-c4d351c48e34"
      },
      "source": [
        "s"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Iteration</th>\n",
              "      <th>Training samples</th>\n",
              "      <th>Unlabeled</th>\n",
              "      <th>Train Accuracy</th>\n",
              "      <th>Validation Accuracy</th>\n",
              "      <th>labels&gt;0.9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2619</td>\n",
              "      <td>5240</td>\n",
              "      <td>83.196944</td>\n",
              "      <td>68.575066</td>\n",
              "      <td>2035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>4654</td>\n",
              "      <td>3205</td>\n",
              "      <td>91.894382</td>\n",
              "      <td>82.390839</td>\n",
              "      <td>614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>5268</td>\n",
              "      <td>2591</td>\n",
              "      <td>91.131002</td>\n",
              "      <td>83.934218</td>\n",
              "      <td>146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>5414</td>\n",
              "      <td>2445</td>\n",
              "      <td>91.501713</td>\n",
              "      <td>83.630770</td>\n",
              "      <td>123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>5537</td>\n",
              "      <td>2322</td>\n",
              "      <td>92.799997</td>\n",
              "      <td>84.175694</td>\n",
              "      <td>123</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Iteration  Training samples  ...  Validation Accuracy  labels>0.9\n",
              "0          1              2619  ...            68.575066        2035\n",
              "1          2              4654  ...            82.390839         614\n",
              "2          3              5268  ...            83.934218         146\n",
              "3          4              5414  ...            83.630770         123\n",
              "4          5              5537  ...            84.175694         123\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRqWJNmZarpp"
      },
      "source": [
        "s.to_csv('/content/drive/MyDrive/ML_S/self_CNN_0.9.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "BJrjMI0owzIJ",
        "outputId": "6c04bf52-0c3c-438f-c752-5c6702c1f18e"
      },
      "source": [
        "s"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Iteration</th>\n",
              "      <th>Training samples</th>\n",
              "      <th>Unlabeled</th>\n",
              "      <th>Train Accuracy</th>\n",
              "      <th>Validation Accuracy</th>\n",
              "      <th>labels&gt;0.99</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2619</td>\n",
              "      <td>5240</td>\n",
              "      <td>85.706490</td>\n",
              "      <td>66.412216</td>\n",
              "      <td>972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>3591</td>\n",
              "      <td>4268</td>\n",
              "      <td>84.958220</td>\n",
              "      <td>75.046384</td>\n",
              "      <td>156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>3747</td>\n",
              "      <td>4112</td>\n",
              "      <td>89.664376</td>\n",
              "      <td>78.933334</td>\n",
              "      <td>265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>4012</td>\n",
              "      <td>3847</td>\n",
              "      <td>89.707977</td>\n",
              "      <td>80.149502</td>\n",
              "      <td>101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>4113</td>\n",
              "      <td>3746</td>\n",
              "      <td>88.537687</td>\n",
              "      <td>80.145866</td>\n",
              "      <td>58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>4171</td>\n",
              "      <td>3688</td>\n",
              "      <td>90.681738</td>\n",
              "      <td>81.230032</td>\n",
              "      <td>108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>4279</td>\n",
              "      <td>3580</td>\n",
              "      <td>88.981634</td>\n",
              "      <td>79.750776</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>4308</td>\n",
              "      <td>3551</td>\n",
              "      <td>86.633497</td>\n",
              "      <td>79.273009</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>4326</td>\n",
              "      <td>3533</td>\n",
              "      <td>88.342142</td>\n",
              "      <td>80.893683</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Iteration  Training samples  ...  Validation Accuracy  labels>0.99\n",
              "0          1              2619  ...            66.412216          972\n",
              "1          2              3591  ...            75.046384          156\n",
              "2          3              3747  ...            78.933334          265\n",
              "3          4              4012  ...            80.149502          101\n",
              "4          5              4113  ...            80.145866           58\n",
              "5          6              4171  ...            81.230032          108\n",
              "6          7              4279  ...            79.750776           29\n",
              "7          8              4308  ...            79.273009           18\n",
              "8          9              4326  ...            80.893683           31\n",
              "\n",
              "[9 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7HvVeNUwzwn"
      },
      "source": [
        "s.to_csv('/content/drive/MyDrive/ML_S/self_CNN_0.9.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vg9bPhPhxbt8"
      },
      "source": [
        "### Evaluating the self trained CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sm5s--Www_7o",
        "outputId": "68f604d9-57af-4fa7-a46a-8fdae1ef0fb8"
      },
      "source": [
        "model=keras.models.load_model(\"/content/drive/MyDrive/ML_S/CNN_self_train.h5\")\n",
        "accuracy=model.evaluate(X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "28/28 [==============================] - 0s 8ms/step - loss: 1.0209 - accuracy: 0.7022\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeWnhj-yxpqT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ad75bfc-1520-4aa2-fe46-80fd1f070356"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "print(y_pred.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(873, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJiB8bK2INPx"
      },
      "source": [
        "print(np.argmax(y_test, axis=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4c3VOAAH6bw"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "label=[ 'air_conditioner', 'car_horn', 'children_playing','dog_bark', 'drilling', 'engine_idling', 'gun_shot','jackhammer', 'siren', 'street_music']\n",
        "cm = confusion_matrix(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1), labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wqlwW6AJDC3"
      },
      "source": [
        "def plot_confusion_matrix(cm, target_names, title='Confusion matrix of CNN', cmap=None, normalize=True):\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "    import itertools\n",
        "\n",
        "    accuracy = np.trace(cm) / np.sum(cm).astype('float')\n",
        "    misclass = 1 - accuracy\n",
        "\n",
        "    if cmap is None:\n",
        "        cmap = plt.get_cmap('Blues')\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "\n",
        "    if target_names is not None:\n",
        "        tick_marks = np.arange(len(target_names))\n",
        "        plt.xticks(tick_marks, target_names, rotation=45)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "\n",
        "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        if normalize:\n",
        "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        else:\n",
        "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
        "    plt.savefig('/content/drive/MyDrive/ML_A/CNN.png')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "6YFb9B4sJFL7",
        "outputId": "58038342-0371-4574-f75e-9c22aa2e9391"
      },
      "source": [
        "plot_confusion_matrix(cm, label, normalize=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2StWtQR7Qmki"
      },
      "source": [
        "from scipy import stats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQocta6TQsxP"
      },
      "source": [
        "print(stat.mode(np.argmax(y_test, axis=1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mTpUHusRepU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}